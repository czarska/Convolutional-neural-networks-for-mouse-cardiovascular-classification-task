{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx2ATD-Boty-"
      },
      "source": [
        "# Common\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY1I1gAWbvqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bef1fc-f59f-48f0-ec86-efcbe849538e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.4.5.tar.gz (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 7.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.12.1+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from grad-cam) (3.2.2)\n",
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from grad-cam) (7.1.2)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.1->grad-cam) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.2->grad-cam) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->grad-cam) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->grad-cam) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->grad-cam) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->grad-cam) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->grad-cam) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->grad-cam) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->grad-cam) (1.7.3)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.4.5-py3-none-any.whl size=37027 sha256=12c2bfba52a3fa81f30dd992f355819e136d93c954a6887387a18abe7a37f78d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/c1/fd/59384047f1fab2f99d96b224bdfd0d2b198f896bdb107d66fd\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.4.5 ttach-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install grad-cam\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flH6DevqH9aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0033c3d6-2b4a-44c8-e6ea-b2cbecd264b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Collecting gspread\n",
            "  Downloading gspread-5.5.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from gspread) (0.4.6)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gspread) (1.35.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread) (4.2.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.0.4)\n",
            "Installing collected packages: gspread\n",
            "  Attempting uninstall: gspread\n",
            "    Found existing installation: gspread 3.4.2\n",
            "    Uninstalling gspread-3.4.2:\n",
            "      Successfully uninstalled gspread-3.4.2\n",
            "Successfully installed gspread-5.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gspread #default version contains a bug https://stackoverflow.com/questions/68218090/copy-still-throwing-errors-with-parameter-folder-id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKDYEKnx7-zR"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "from google.colab import drive, auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import os\n",
        "import itertools\n",
        "import random\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision\n",
        "\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from torchvision import transforms\n",
        "import albumentations\n",
        "import albumentations.pytorch\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, SubsetRandomSampler, ConcatDataset, Subset\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICnup0YUIYRn",
        "outputId": "d46d17e1-d0be-45f5-96fa-61d861aebec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.5.0\n"
          ]
        }
      ],
      "source": [
        "print(gspread.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bt8PB9N97ef",
        "outputId": "49c7743f-e875-4dbb-9b65-ddd82d8dd19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "HeartMasks\t\tHighFatDiett  Version0\tVersion2\n",
            "HFD2tyg_N01_T1maps.mat\tKontrolaa     Version1\n"
          ]
        }
      ],
      "source": [
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/magisterka22/dane\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAnEBgbSJGMI"
      },
      "outputs": [],
      "source": [
        "#Auth for spreedsheets\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrz--LlRi_UU"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/drive/My Drive/magisterka22/dane/Version1/Train/'\n",
        "HEART_DATA_DIR = '/content/drive/My Drive/magisterka22/dane/Version2/Train/'\n",
        "\n",
        "FAT_DIR0 = DATA_DIR + 'Square/HighFatDiet'\n",
        "HEALTHY_DIR0 = DATA_DIR + 'Square/Kontrola'\n",
        "FAT_DIR1 = DATA_DIR + 'Rectangle/HighFatDiet'\n",
        "HEALTHY_DIR1 = DATA_DIR + 'Rectangle/Kontrola'\n",
        "\n",
        "HEART_FAT_DIR0 = HEART_DATA_DIR + 'Square/HighFatDiet'\n",
        "HEART_HEALTHY_DIR0 = HEART_DATA_DIR + 'Square/Kontrola'\n",
        "HEART_FAT_DIR1 = HEART_DATA_DIR + 'Rectangle/HighFatDiet'\n",
        "HEART_HEALTHY_DIR1 = HEART_DATA_DIR + 'Rectangle/Kontrola'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stlitZO26SAt"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v65Jmq7wg5q2"
      },
      "outputs": [],
      "source": [
        "def fix_image(im, min_size=192): #it shold be do one and decide the dirrection\n",
        "  (x, y) = im.shape\n",
        "  #print(\"before fix x:\",x,\" y:\", y)\n",
        "  if x < min_size:\n",
        "    im = np.concatenate((im, np.zeros((min_size-x, y))))\n",
        "  (x, y) = im.shape\n",
        "  #print(\"after first fix x:\",x,\" y:\", y)\n",
        "  if y < min_size:\n",
        "    im = np.concatenate((im, np.zeros((x, min_size-y))), axis=1)\n",
        "  return im\n",
        "\n",
        "def load_image(filepath, label, shape, pre = False, rgb = False):\n",
        "  maps = scipy.io.loadmat(filepath)\n",
        "  #print(maps.keys())\n",
        "  img_pre = np.array(maps['preT1map'], np.double)\n",
        "  img_pre = fix_image(img_pre)\n",
        "  img_post = np.array(maps['postT1map'], np.double)\n",
        "  img_post = fix_image(img_post)\n",
        "  if rgb:\n",
        "    img_pre = toRGB(img_pre)\n",
        "    img_post = toRGB(img_post)\n",
        "  if pre:\n",
        "    return (img_pre, label, shape)\n",
        "  return (img_post, label, shape)\n",
        "\n",
        "\n",
        "def load_numpy_image(filepath, label, shape, rgb = False):\n",
        "  with open(filepath, 'rb') as f:\n",
        "    img_pre = np.load(f)\n",
        "    # plt.imshow(img_pre)\n",
        "    # plt.show()\n",
        "    if rgb:\n",
        "      img_pre = toRGB(img_pre)\n",
        "    return (img_pre, label, shape)\n",
        "\n",
        "\n",
        "def toRGB(image):\n",
        "  #image = image/2500\n",
        "  rgb_image = np.stack((image, image, image), axis=2)\n",
        "  return rgb_image\n",
        "  \n",
        "def crop_center(img,cropx,cropy):\n",
        "    y,x = img.shape\n",
        "    startx = x//2-(cropx//2)\n",
        "    starty = y//2-(cropy//2)    \n",
        "    return img[starty:starty+cropy,startx:startx+cropx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwGfyvlWdnGt"
      },
      "source": [
        "# Spreedsheet integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC65vDCg-tlE"
      },
      "outputs": [],
      "source": [
        "def create_spreedsheet(name, dest_dir_id):\n",
        "  sh = gc.create(name, folder_id=dest_dir_id)\n",
        "  link = 'https://docs.google.com/spreadsheets/d/' + sh.id + '/edit#gid=0'\n",
        "  print(\"Created spreedsheet link:\", link)\n",
        "\n",
        "def next_available_row(worksheet):\n",
        "  str_list = list(filter(None, worksheet.col_values(1)))\n",
        "  return str(len(str_list)+1)\n",
        "\n",
        "def update_row(name, values):\n",
        "  worksheet = gc.open(name).sheet1\n",
        "  index = next_available_row(worksheet)\n",
        "  start = 'A' + str(index)\n",
        "  to = chr(ord('A') + len(values)) + str(index)\n",
        "  cell_list = worksheet.range(start + ':' + to)\n",
        "  for cell,val in zip(cell_list, values):\n",
        "    cell.value = val\n",
        "  worksheet.update_cells(cell_list)\n",
        "\n",
        "def print_sheet(name):\n",
        "  worksheet = gc.open(name).sheet1\n",
        "  rows = worksheet.get_all_values()\n",
        "  print(rows)\n",
        "  pd.DataFrame.from_records(rows)\n",
        "\n",
        "def create_results_spreedsheet(name, dest_dir_id):\n",
        "  create_spreedsheet(name, dest_dir_id)\n",
        "  update_row(name, ['date', 'conf_matrix', 'acc', 'metadata', 'params'])\n",
        "\n",
        "def append_results_to_spreedsheet(sp_name, params, conf_matrix, metadata={}):\n",
        "  date = str(datetime.now())\n",
        "  if type(conf_matrix) == str:\n",
        "    acc = conf_matrix\n",
        "  else:\n",
        "    acc = (conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "  values = [date, str(conf_matrix), acc, str(metadata)]\n",
        "  for p in params.items():\n",
        "    values.append(str(p))\n",
        "  update_row(sp_name, values)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aok32WkIb8w",
        "outputId": "11769a09-4af2-46c6-92c4-0ff5409ebb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created spreedsheet link: https://docs.google.com/spreadsheets/d/1p5crcGc0yi2CxQhgSnTlSZoWqjs87PMeYZ_Rk9P_GKs/edit#gid=0\n",
            "Created spreedsheet link: https://docs.google.com/spreadsheets/d/1gMMyvwNXLjnoqaMXo8ifViK68Ym14_DVWoNFcQNTORo/edit#gid=0\n"
          ]
        }
      ],
      "source": [
        "DESTINATION_DIR_ID = \"1Rl9xqRRWGUCN2T4ju4qTBKRkJGaHjtft\"\n",
        "\n",
        "SPREEDSHEET_NAME_FINAL = \"Results Final (multiple runs) 2\" + str(datetime.now())\n",
        "SPREEDSHEET_NAME_INT = \"Results Intermediate (multiple runs) 2\" + str(datetime.now())\n",
        "\n",
        "create_results_spreedsheet(SPREEDSHEET_NAME_FINAL, DESTINATION_DIR_ID)\n",
        "create_results_spreedsheet(SPREEDSHEET_NAME_INT, DESTINATION_DIR_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D11bsVzb67Qz"
      },
      "outputs": [],
      "source": [
        "DESTINATION_DIR_ID = \"1Rl9xqRRWGUCN2T4ju4qTBKRkJGaHjtft\"\n",
        "\n",
        "SPREEDSHEET_NAME_FINAL = \"Results Final (multiple runs) 2022-09-15 21:33:48.728393\"\n",
        "SPREEDSHEET_NAME_INT = \"Results Intermediate (multiple runs) 2022-09-15 21:33:48.728451\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52zT1iMimqi5"
      },
      "outputs": [],
      "source": [
        "DESTINATION_DIR_ID = \"1Rl9xqRRWGUCN2T4ju4qTBKRkJGaHjtft\"\n",
        "\n",
        "SPREEDSHEET_NAME_FINAL = \"Results Final (multiple runs) 22022-09-24 12:04:06.061946\"\n",
        "SPREEDSHEET_NAME_INT = \"Results Intermediate (multiple runs) 22022-09-24 12:04:06.062012\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0mDYnMp6JZ7"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coWXyhLVHj-6"
      },
      "outputs": [],
      "source": [
        "# PyTorch image augmentation module\n",
        "class PyTorchImageDataset(Dataset):\n",
        "    def __init__(self, fat_dir_square, fat_dir_rectangle, healthy_dir_square, healthy_dir_rectangle, transforms=None, rgb=False, pre=True):\n",
        "        fat_square = [load_image(os.path.join(fat_dir_square, filename), 1, 0, pre, rgb) for filename in os.listdir(fat_dir_square)]\n",
        "        fat_rectangle = [load_image(os.path.join(fat_dir_rectangle, filename), 1, 1, pre, rgb) for filename in os.listdir(fat_dir_rectangle)]\n",
        "        healthy_square = [load_image(os.path.join(healthy_dir_square, filename), 0, 0, pre, rgb) for filename in os.listdir(healthy_dir_square)]\n",
        "        healthy_rectangle = [load_image(os.path.join(healthy_dir_rectangle, filename), 0, 1, pre, rgb) for filename in os.listdir(healthy_dir_rectangle)]\n",
        "        all = np.array(fat_square + fat_rectangle + healthy_square + healthy_rectangle)\n",
        "        #np.random.shuffle(all)\n",
        "        self.image_list = [x[0] for x in all]\n",
        "        self.labels = [x[1] for x in all]\n",
        "        self.sh = [x[2] for x in all]\n",
        "        self.transforms = transforms\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.image_list))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = self.image_list[i]    \n",
        "        image = np.array(image/10).astype(np.uint8)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image) \n",
        "        return (image, self.labels[i], self.sh[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEL_qfdf3TNL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HeartDataset(Dataset):\n",
        "    def __init__(self, fat_dir_square, fat_dir_rectangle, healthy_dir_square, healthy_dir_rectangle, transforms=None, rgb=False, pre=True):\n",
        "        fat_square = [load_numpy_image(os.path.join(fat_dir_square, filename), 1, 0, rgb) for filename in os.listdir(fat_dir_square)]\n",
        "        fat_rectangle = [load_numpy_image(os.path.join(fat_dir_rectangle, filename), 1, 1, rgb) for filename in os.listdir(fat_dir_rectangle)]\n",
        "        healthy_square = [load_numpy_image(os.path.join(healthy_dir_square, filename), 0, 0, rgb) for filename in os.listdir(healthy_dir_square)]\n",
        "        healthy_rectangle = [load_numpy_image(os.path.join(healthy_dir_rectangle, filename), 0, 1, rgb) for filename in os.listdir(healthy_dir_rectangle)]\n",
        "        all = np.array(fat_square + fat_rectangle + healthy_square + healthy_rectangle)\n",
        "        #np.random.shuffle(all)\n",
        "        self.image_list = [x[0] for x in all]\n",
        "        self.labels = [x[1] for x in all]\n",
        "        self.sh = [x[2] for x in all]\n",
        "        self.transforms = transforms\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.image_list))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = self.image_list[i]\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)  \n",
        "        return (image, self.labels[i], self.sh[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7fjZfbDJwIp",
        "outputId": "a3c7562e-3769-4124-c3bc-98c095e6613c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 43  img shape: (192, 192, 3)\n",
            "Image shape: (192, 192, 3) min: 0.0  max: 2498.6437381880596\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From getter shape: (3, 192, 192) min: 0.0  max: 0.9764706\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#temp test\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    #transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, True)\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "img = dataset.image_list[0]\n",
        "#img = img.transpose((-1, 0, 1))\n",
        "print(\"Image shape:\", img.shape, \"min:\", np.min(img), \" max:\", np.max(img))\n",
        "#img = img[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "item = dataset.__getitem__(0)\n",
        "img = item[0].numpy()\n",
        "print(\"From getter shape:\", img.shape, \"min:\", np.min(img), \" max:\", np.max(img))\n",
        "plt.imshow(img[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOYjQdp75_Z8"
      },
      "source": [
        "# Networks defs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3gdZcfnpUxE"
      },
      "outputs": [],
      "source": [
        "class Net(Module):   \n",
        "    def __init__(self, params={}, number_of_channels=1, image_size=192):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.model_params = params\n",
        "        self.input_ll_size = params['number_of_filers'] * image_size * image_size\n",
        "        print(\"self.input_ll_size:\",self.input_ll_size)\n",
        "        if params['pooling']:\n",
        "          #self.input_ll_size = int(self.input_ll_size/(4 ** params['number_of_conv_layers']))\n",
        "          self.input_ll_size = params['number_of_filers'] * int( image_size /(2 ** params['number_of_conv_layers'])) * int( image_size /(2 ** params['number_of_conv_layers']))\n",
        "          print(\" self.input_ll_size:\",self.input_ll_size)\n",
        "        if params['shape_info']:\n",
        "          self.input_ll_size = self.input_ll_size + 1\n",
        "\n",
        "        self.cnn_layers = self._make_conv_layers(params['number_of_conv_layers'])\n",
        "\n",
        "        self.linear_layers = [Sequential(\n",
        "            Linear(self.input_ll_size, 2)\n",
        "        ), \n",
        "        Sequential(\n",
        "            Linear(self.input_ll_size, self.model_params['number_of_filers'] * 12 * 12),\n",
        "            Dropout(self.model_params['dropout']),\n",
        "            Linear(self.model_params['number_of_filers'] * 12 * 12, 2)\n",
        "        ),\n",
        "        Sequential(\n",
        "            Linear(self.input_ll_size, self.model_params['number_of_filers'] * 12 * 12),\n",
        "            Dropout(self.model_params['dropout']),\n",
        "            Linear(self.model_params['number_of_filers'] * 12 * 12, self.model_params['number_of_filers'] * 4 * 4),\n",
        "            Dropout(self.model_params['dropout']),\n",
        "            Linear(self.model_params['number_of_filers'] * 4 * 4, 2)\n",
        "        )]\n",
        "\n",
        "    def _make_conv_layers(self, number):\n",
        "      elements = self._make_conv_block(1, self.model_params['number_of_filers'])\n",
        "      for _ in range(number-1):\n",
        "        elements = elements + self._make_conv_block(self.model_params['number_of_filers'], self.model_params['number_of_filers'])\n",
        "      return Sequential(*elements)\n",
        "      \n",
        "    def _make_conv_block(self, ins, outs):\n",
        "      elements = []\n",
        "      elements.append(Conv2d(ins, outs, kernel_size=3, stride=1, padding=1))\n",
        "      if self.model_params['batch_norm']:\n",
        "        elements.append(BatchNorm2d(outs))\n",
        "      elements.append(ReLU(inplace=True))\n",
        "      if self.model_params['pooling']:\n",
        "        elements.append(MaxPool2d(kernel_size=2, stride=2))\n",
        "      return elements\n",
        " \n",
        "    def forward(self, x, shape=None):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.model_params['shape_info'] and shape != None:\n",
        "          shape = shape.view(-1, 1)\n",
        "          x = torch.cat((x, shape), 1)\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "        ll = self.linear_layers[self.model_params['number_of_linear_layers']-1].to(device)\n",
        "        x = ll(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDMw6FMagfZa"
      },
      "outputs": [],
      "source": [
        "def prepare_resnet_model(pretrained=False, dropout=0.0):\n",
        "  #finetune_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained)\n",
        "  finetune_model = torchvision.models.resnet18(pretrained=pretrained, progress=True,)\n",
        "  num_ftrs = finetune_model.fc.out_features\n",
        "  for param in finetune_model.parameters():\n",
        "    param.requires_grad = False\n",
        "  finetune_model.fc.weight.requires_grad = True\n",
        "  finetune_model.fc.bias.requires_grad = True\n",
        "  finetune_model = nn.Sequential(\n",
        "      finetune_model, \n",
        "      nn.Dropout(dropout),\n",
        "      nn.Linear(num_ftrs, 2))\n",
        "  #print(finetune_model)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  finetune_model = finetune_model.to(device)\n",
        "  return finetune_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7qKzycxIxro"
      },
      "source": [
        "test pretrained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5UTdvsIpiAJ"
      },
      "source": [
        "# Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEosZbPbRyvP"
      },
      "outputs": [],
      "source": [
        "def regularalize(model, loss, net_params):\n",
        "  l1_norm = sum(abs(p).sum() for p in model.parameters())\n",
        "  loss = loss + net_params['l1_regularization_lambda'] * l1_norm\n",
        "  l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
        "  loss = loss + net_params['l2_regularization_lambda'] * l2_norm  \n",
        "  return loss\n",
        "\n",
        "def update_loss(general_loss, general_correct, loss, images, labels, output):\n",
        "  general_loss += loss.item() * images.size(0)\n",
        "  scores, predictions = torch.max(output.data, 1)\n",
        "  general_correct += (predictions == labels).sum().item()\n",
        "  return general_loss, general_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmwMtluUx7c9"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, device, dataloader, loss_fn, optimizer, net_params, resnet=False):\n",
        "    train_loss, train_correct = 0.0, 0\n",
        "    model.train()\n",
        "    for batch_ndx,(images, labels, sh) in enumerate(dataloader):\n",
        "        images, labels, sh = images.to(device), labels.to(device), sh.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        if resnet:\n",
        "          output = model(images)\n",
        "        else:\n",
        "          output = model(images, sh) \n",
        "        loss = loss_fn(output, labels)\n",
        "        if resnet == False:\n",
        "          loss = regularalize(model, loss, net_params)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss, train_correct = update_loss(train_loss, train_correct, loss, images, labels, output)\n",
        "    return train_loss, train_correct\n",
        "  \n",
        "def valid_epoch(model, device, dataloader, loss_fn, net_params, resnet=False):\n",
        "    val_loss, val_correct = 0.0, 0\n",
        "    conf_matrix = [[0.0, 0.0], [0.0, 0.0]]\n",
        "    model.eval()\n",
        "    for batch_ndx,(images, labels, sh) in enumerate(dataloader):\n",
        "        images, labels, sh = images.to(device), labels.to(device), sh.to(device)\n",
        "        if resnet:\n",
        "          output = model(images)\n",
        "        else:\n",
        "          output = model(images, sh) \n",
        "        loss = loss_fn(output, labels)\n",
        "        val_loss, val_correct = update_loss(val_loss, val_correct, loss, images, labels, output)\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        cf_matrix = confusion_matrix(labels.cpu(), predictions.cpu()) \n",
        "        conf_matrix += cf_matrix\n",
        "    return val_loss, val_correct, conf_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4CZmPUV1-b0"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, device, net_params, train_loader, test_loader, criterion, optimizer, scheduler, resnet=False):\n",
        "    # Early stopping\n",
        "    last_loss = 100\n",
        "    patience = 5\n",
        "    trigger_times = 0\n",
        "    \n",
        "    for epoch in range(net_params['num_epochs']):\n",
        "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer, net_params, resnet)\n",
        "        test_loss, test_correct, cf_matrix = valid_epoch(model, device, test_loader, criterion, net_params, resnet)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
        "\n",
        "        #scheduler.step(test_loss)\n",
        "\n",
        "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1, net_params['num_epochs'], train_loss, test_loss, train_acc, test_acc))\n",
        "\n",
        "        # Early stopping\n",
        "        if train_loss >= last_loss:\n",
        "            #print(\"trt:\", trigger_times, \" patience:\", patience)\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                return cf_matrix\n",
        "        else:\n",
        "            trigger_times = 0\n",
        "        last_loss = train_loss\n",
        "    return cf_matrix\n",
        "\n",
        "def prepare_model(get_model, learning_rate):\n",
        "  model = get_model()\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)  \n",
        "  optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
        "  return model, optimizer, device, scheduler\n",
        "\n",
        "#to be changed\n",
        "# def folds_loop_seq(get_model, dataset0, dataset1, criterion, net_params, splits0, splits1):\n",
        "#   results, results1 = {}, {}\n",
        "#   for fold, ((train_idx, val_idx), (train_idx1, val_idx1)) in enumerate(zip(splits0, splits1)):\n",
        "#     print('Fold {}. train_idx:{} val_idx:{} train_idx1:{} val_idx1:{}'.format(fold + 1, train_idx, val_idx, train_idx1, val_idx1))\n",
        "\n",
        "#     model, optimizer, device = prepare_model(get_model, net_params['learning_rate'])\n",
        "#     test_loader, shapes_test = prepare_test_loader(val_idx, val_idx1, net_params['batch_size'], len(train_idx)+len(val_idx), joined_dataset)\n",
        "\n",
        "#     shapes_train = np.zeros((len(train_idx), 1))\n",
        "#     train_loader = DataLoader(dataset0, batch_size=net_params['batch_size']) #, sampler=SubsetRandomSampler(train_idx))\n",
        "#     results[fold] = train_loop(model, device, net_params, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "    \n",
        "#     shapes_train1 = np.ones((len(train_idx1), 1))\n",
        "#     train_loader1 = DataLoader(dataset1, batch_size=net_params['batch_size']) #, sampler=SubsetRandomSampler(train_idx1))\n",
        "#     results1[fold] = train_loop(model, device, net_params, train_loader1, test_loader, criterion, optimizer, shapes_train1, shapes_test)\n",
        "#   return results, results1\n",
        "\n",
        "def folds_loop(get_model, dataset, criterion, net_params, splits, resnet=False):\n",
        "  results = {}\n",
        "  for fold, (train_idx, val_idx) in enumerate(splits):\n",
        "      print('Fold {}. train_idx:{} val_idx:{}'.format(fold + 1, train_idx, val_idx))\n",
        "      model, optimizer, device, scheduler = prepare_model(get_model, net_params['learning_rate'])\n",
        "      test_loader = DataLoader(Subset(dataset, val_idx), batch_size=net_params['batch_size'])\n",
        "      train_loader = DataLoader(Subset(dataset, train_idx), batch_size=net_params['batch_size'])\n",
        "      results[fold] = train_loop(model, device, net_params, train_loader, test_loader, criterion, optimizer, scheduler, resnet)\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIJ78XTh2NC3"
      },
      "outputs": [],
      "source": [
        "def print_and_save_folds_results(conf_matrixes, params, sp_name, agums = None):\n",
        "  sum = 0.0\n",
        "  print(\"--- FOLDS RESULTS ---\")\n",
        "  for key, conf_matrix in conf_matrixes.items():\n",
        "    metadata = {'fold': str(key+1)+'/'+str(len(conf_matrixes.items()))}\n",
        "    if agums != None:\n",
        "      metadata = dict(**metadata, **agums)\n",
        "    append_results_to_spreedsheet(sp_name, params, conf_matrix, metadata)\n",
        "    v = (conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    print(f'Fold {key} acc: {v*100} %')\n",
        "    sum += v\n",
        "  result = sum/len(conf_matrixes.items())\n",
        "  print(f' Average acc: {result*100} %')\n",
        "  metadata = {'FINAL': 1}\n",
        "  if agums != None:\n",
        "    metadata = dict(**metadata, **agums)\n",
        "  append_results_to_spreedsheet(sp_name, params, str(result), metadata)\n",
        "  return result\n",
        "\n",
        "def find_best_params_ndim(grid_param, grid):\n",
        "  print(\"grid_param:\", grid_param, \" grid:\", grid)\n",
        "  keys = list(grid_param.keys())\n",
        "  shape = tuple(len(grid_param[keys[i]]) for i in range(len(keys)))\n",
        "  best, best_idx = 0, 0\n",
        "  for idx in itertools.product(*[range(s) for s in shape]):\n",
        "    current = grid[idx]\n",
        "    if current > best:\n",
        "      best = current\n",
        "      best_idx = idx\n",
        "  print(\"best:\", best, \"best_idx:\", best_idx)\n",
        "  best_params = {k: grid_param[k][best_idx[e]] for e,k in enumerate(keys)}\n",
        "  print(\"best params:\", best_params)\n",
        "  return best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcHfwTvpGfO6"
      },
      "outputs": [],
      "source": [
        "def search_for_best_params(train_idx, dataset, grid_param, resnet=False):\n",
        "  keys = list(grid_param.keys())\n",
        "  shape = tuple(len(grid_param[keys[i]]) for i in range(len(keys)))\n",
        "  grid = np.zeros((shape))\n",
        "  inner_splitter = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "  for idx in itertools.product(*[range(s) for s in shape]):\n",
        "    current_params = {k: grid_param[k][idx[e]] for e,k in enumerate(keys)}\n",
        "    print(\"current p:\", current_params)\n",
        "    def model_getter():\n",
        "      return Net(current_params, 1, dataset.image_list[0].shape[0] )\n",
        "    def model_getter_resnet():\n",
        "      return copy.deepcopy(resnet_model)\n",
        "\n",
        "    inner_splits = inner_splitter.split(train_idx, np.array(dataset.labels)[train_idx])\n",
        "\n",
        "    results = {}\n",
        "    for inner_fold, (inner_train_idxx, inner_val_idxx) in enumerate(inner_splits):\n",
        "      inner_train_idx, inner_val_idx = train_idx[inner_train_idxx], train_idx[inner_val_idxx]\n",
        "\n",
        "      if resnet:    \n",
        "        model, optimizer, device, scheduler = prepare_model(model_getter_resnet, current_params['learning_rate'])\n",
        "      else:\n",
        "        model, optimizer, device, scheduler = prepare_model(model_getter, current_params['learning_rate'])\n",
        "      test_loader = DataLoader(Subset(dataset, inner_val_idx), batch_size=current_params['batch_size']) \n",
        "      train_loader = DataLoader(Subset(dataset, inner_train_idx), batch_size=current_params['batch_size']) \n",
        "      results[inner_fold] = train_loop(model, device, current_params, train_loader, test_loader, criterion, optimizer, scheduler, resnet)  \n",
        "\n",
        "    grid[idx] = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_INT)\n",
        "  best_params = find_best_params_ndim(grid_param, grid)\n",
        "  return best_params\n",
        "\n",
        "\n",
        "def folds_loop_double(dataset, criterion, grid_param, splits, resnet=False):\n",
        "  out_results = {}\n",
        "  out_best_params = {}\n",
        "  trained_models = {}\n",
        "  for fold, (train_idx, val_idx) in enumerate(splits):\n",
        "      print('Fold(outher) {}. train_idx:{} val_idx:{}'.format(fold + 1, train_idx, val_idx))\n",
        "\n",
        "      best_params = search_for_best_params(train_idx, dataset, grid_param, resnet)\n",
        "\n",
        "      def model_getter():\n",
        "        return Net(best_params, 1, dataset.image_list[0].shape[0])\n",
        "      def model_getter_resnet():\n",
        "        return copy.deepcopy(resnet_model)\n",
        "\n",
        "      print(\"Running final learning session for Fold(outher):\", fold+1, \" with best_params:\", best_params)\n",
        "      if resnet:\n",
        "        model, optimizer, device, scheduler = prepare_model(model_getter_resnet, best_params['learning_rate'])\n",
        "      else:\n",
        "        model, optimizer, device, scheduler = prepare_model(model_getter, best_params['learning_rate'])\n",
        "      test_loader = DataLoader(dataset, batch_size=best_params['batch_size'], sampler=SubsetRandomSampler(val_idx))\n",
        "      train_loader = DataLoader(dataset, batch_size=best_params['batch_size'], sampler=SubsetRandomSampler(train_idx))\n",
        "      \n",
        "      out_results[fold] = train_loop(model, device, best_params, train_loader, test_loader, criterion, optimizer, scheduler, resnet)\n",
        "      out_best_params[fold] = best_params\n",
        "      trained_models[fold] = model\n",
        "  return out_results, out_best_params, trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ5dQkHyabez"
      },
      "outputs": [],
      "source": [
        "def grid_on_agumentations(model_type, dataset_type, grid_agumentations, grid_param):\n",
        "  torch.manual_seed(42)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  keys = list(grid_agumentations.keys())\n",
        "  shape = tuple(len(grid_agumentations[keys[i]]) for i in range(len(keys)))\n",
        "  grid = np.zeros((shape))\n",
        "\n",
        "  for idx in itertools.product(*[range(s) for s in shape]):\n",
        "    current_agumentations = {k: grid_agumentations[k][idx[e]] for e,k in enumerate(keys)}\n",
        "    print(\"  current_agumentations:\", current_agumentations)\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),                                  \n",
        "      transforms.RandomHorizontalFlip(p=current_agumentations['RandomHorizontalFlipProb']),\n",
        "      transforms.RandomRotation(degrees=(-1*current_agumentations['RandomRotation'], current_agumentations['RandomRotation'])),\n",
        "      transforms.RandomAffine(degrees=0, scale=(1.0-current_agumentations['RandomAffineScale'], 1.0+current_agumentations['RandomAffineScale']), shear=0),\n",
        "      #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "      transforms.RandomVerticalFlip(p=current_agumentations['RandomVerticalFlipProb']),\n",
        "      transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    rgb = True\n",
        "    if '.Net' in str(model_type):\n",
        "      rgb = False\n",
        "    if 'HeartDataset' in str(dataset_type):\n",
        "      dataset = dataset_type(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, rgb)\n",
        "    else:\n",
        "      dataset = dataset_type(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, rgb)\n",
        "\n",
        "\n",
        "    splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "    splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "    current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "    def model_getter():\n",
        "      return model_type(current_params, 1, dataset.image_list[0].shape[0])\n",
        "    def model_getter_resnet():\n",
        "      return copy.deepcopy(model_type)\n",
        "\n",
        "    if '.Net' in str(model_type):\n",
        "      results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "    else: #resnet\n",
        "      results = folds_loop(model_getter_resnet, dataset, criterion, current_params, splits, True)\n",
        "\n",
        "    grid[idx] = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL, current_agumentations)\n",
        "\n",
        "  best_params = find_best_params_ndim(grid_agumentations, grid)\n",
        "  print(\"best params:\", best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RKNaQioo_yh"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Network with cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-x99PhJSuKh"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uuo7yfFTkRcA"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {\n",
        "    'learning_rate': [0.001],\n",
        "    'batch_size': [4], \n",
        "    'dropout': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    'num_epochs': [30],\n",
        "    'number_of_linear_layers': [2], \n",
        "    'l1_regularization_lambda': [0.0, 0.01, 0.001], \n",
        "    'l2_regularization_lambda': [0.0, 0.01, 0.001],\n",
        "    'number_of_conv_layers': [2], \n",
        "    'number_of_filers': [3], \n",
        "    'pooling': [True],\n",
        "    'batch_norm': [True],\n",
        "    'shape_info': [False],\n",
        "}\n",
        "\n",
        "\n",
        "k = 4\n",
        "pre = False\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZc0EAuYtxm5"
      },
      "outputs": [],
      "source": [
        "#trianing (without grid search)\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, False, pre)\n",
        "print(\"Train dataset size:\", len(dataset))\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "def model_getter():\n",
        "  return Net(current_params, 1)\n",
        "\n",
        "results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xqhzv9YFoqm"
      },
      "outputs": [],
      "source": [
        "#trianing (without grid search) a lot of times\n",
        "\n",
        "# train_transform = transforms.Compose([\n",
        "#       transforms.ToPILImage(),                                  \n",
        "#       transforms.RandomHorizontalFlip(p=0.5),\n",
        "#       transforms.RandomRotation(degrees=(-1*30, 30)),\n",
        "#       transforms.RandomAffine(degrees=0, scale=(1.0-0.2, 1.0+0.2), shear=0),\n",
        "#       #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "#       transforms.RandomVerticalFlip(p=0),\n",
        "#       transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, False, pre)\n",
        "print(\"Train dataset size:\", len(dataset))\n",
        "\n",
        "times = 10\n",
        "final_acc = []\n",
        "\n",
        "for _ in range(times):\n",
        "\n",
        "  splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "  def model_getter():\n",
        "    return Net(current_params, 1)\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "  acc = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)\n",
        "  final_acc.append(acc)\n",
        "print(\"Runed \", times, \" times. Results:\", final_acc, \" avg:\", np.mean(final_acc), \" std:\", np.std(final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sZPihaNZ7lAj"
      },
      "outputs": [],
      "source": [
        "#grid search (single cross validation)\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, False, pre)\n",
        "splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "keys = list(grid_param.keys())\n",
        "print(\"grid_param:\", grid_param)\n",
        "shape = tuple(len(grid_param[keys[i]]) for i in range(len(keys)))\n",
        "gread = np.zeros((shape))\n",
        "\n",
        "for idx in itertools.product(*[range(s) for s in shape]):\n",
        "    current_params = {k: grid_param[k][idx[e]] for e,k in enumerate(keys)}\n",
        "    print(\" idx:\", idx, \" current_params:\", current_params)\n",
        "\n",
        "    def model_getter():\n",
        "      return Net(current_params, 1)\n",
        "      \n",
        "    splits = splitter.split(dataset, dataset.labels)\n",
        "    \n",
        "    results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "\n",
        "    avg_result = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)\n",
        "    print(\"result for idx:\", idx, \" res:\", avg_result)\n",
        "    gread[idx] = avg_result\n",
        "\n",
        "print(\"----------------\")\n",
        "find_best_params_ndim(grid_param, gread)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtHLNeRhaCew"
      },
      "outputs": [],
      "source": [
        "#grid search (double cross validation)\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, False, pre)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "out_results, out_best_params, trained_models = folds_loop_double(dataset, criterion, grid_param, splits)\n",
        "print_and_save_folds_results(out_results, out_best_params, SPREEDSHEET_NAME_FINAL)\n",
        "print(\"Final best params:\", out_best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgnYtG8IeiGu"
      },
      "source": [
        "RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sito4-lQelx1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {\n",
        "    'learning_rate': [0.001],\n",
        "    'batch_size': [6], \n",
        "    'num_epochs': [20]\n",
        "}\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCHSZBsEOYQU"
      },
      "outputs": [],
      "source": [
        "#trianing (without grid search) RESNET \n",
        "\n",
        "finetune_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
        "num_ftrs = finetune_model.fc.in_features\n",
        "finetune_model.fc = nn.Linear(num_ftrs, 2)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "finetune_model = finetune_model.to(device)\n",
        "#print(finetune_model)\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset shape:\", dataset[0][0].shape)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "\n",
        "def model_getter():\n",
        "  return copy.deepcopy(finetune_model)\n",
        "\n",
        "results = folds_loop(model_getter, dataset, criterion, current_params, splits, resnet=True)\n",
        "print_and_save_folds_results(results, grid_param, SPREEDSHEET_NAME_FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFUzDj3V1i84",
        "outputId": "9d8cc81e-2b65-4e53-ea97-4ffa2037a1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.839 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.215 AVG Test Loss:0.749 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.936 AVG Test Loss:0.715 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.735 AVG Test Loss:0.694 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.610 AVG Test Loss:0.699 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.546 AVG Test Loss:0.692 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.444 AVG Test Loss:0.699 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.341 AVG Test Loss:0.699 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.227 AVG Test Loss:0.722 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.154 AVG Test Loss:0.725 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.106 AVG Test Loss:0.737 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.059 AVG Test Loss:0.744 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.036 AVG Test Loss:0.740 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.023 AVG Test Loss:0.723 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.017 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.013 AVG Test Loss:0.729 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.010 AVG Test Loss:0.733 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.009 AVG Test Loss:0.732 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.008 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.007 AVG Test Loss:0.731 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.852 AVG Test Loss:0.789 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.219 AVG Test Loss:0.685 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.819 AVG Test Loss:0.686 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.665 AVG Test Loss:0.696 AVG Training Acc 68.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.513 AVG Test Loss:0.693 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.470 AVG Test Loss:0.703 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.303 AVG Test Loss:0.719 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.190 AVG Test Loss:0.693 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.116 AVG Test Loss:0.704 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.074 AVG Test Loss:0.671 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.053 AVG Test Loss:0.808 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.040 AVG Test Loss:0.700 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.024 AVG Test Loss:0.707 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.017 AVG Test Loss:0.703 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.013 AVG Test Loss:0.700 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.011 AVG Test Loss:0.705 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:0.009 AVG Test Loss:0.715 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.008 AVG Test Loss:0.723 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:0.007 AVG Test Loss:0.727 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.006 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.900 AVG Test Loss:0.710 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.076 AVG Test Loss:9.026 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.061 AVG Test Loss:1.752 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.965 AVG Test Loss:1.063 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.885 AVG Test Loss:1.932 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.927 AVG Test Loss:0.763 AVG Training Acc 6.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.855 AVG Test Loss:0.830 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.704 AVG Test Loss:1.746 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.679 AVG Test Loss:0.992 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.580 AVG Test Loss:0.879 AVG Training Acc 84.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.500 AVG Test Loss:0.745 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.442 AVG Test Loss:0.763 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.381 AVG Test Loss:0.705 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.343 AVG Test Loss:0.785 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.374 AVG Test Loss:0.778 AVG Training Acc 84.38 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.246 AVG Test Loss:0.809 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.235 AVG Test Loss:0.852 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.170 AVG Test Loss:1.149 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:19/20 AVG Training Loss:0.173 AVG Test Loss:0.599 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:0.153 AVG Test Loss:0.665 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.858 AVG Test Loss:0.695 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.996 AVG Test Loss:1.429 AVG Training Acc 33.33 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:1.520 AVG Training Acc 15.15 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.037 AVG Test Loss:1.521 AVG Training Acc 3.03 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.864 AVG Test Loss:1.359 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.736 AVG Test Loss:0.713 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.660 AVG Test Loss:0.695 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.589 AVG Test Loss:0.756 AVG Training Acc 75.76 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.543 AVG Test Loss:0.673 AVG Training Acc 78.79 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.444 AVG Test Loss:0.694 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.359 AVG Test Loss:0.697 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.255 AVG Test Loss:0.769 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.180 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.111 AVG Test Loss:0.727 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.063 AVG Test Loss:0.798 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.050 AVG Test Loss:0.665 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.027 AVG Test Loss:0.725 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.020 AVG Test Loss:0.825 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.016 AVG Test Loss:0.818 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.012 AVG Test Loss:0.807 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 49.890282131661436 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.871 AVG Test Loss:0.877 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.235 AVG Test Loss:1.702 AVG Training Acc 25.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.106 AVG Test Loss:2.666 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.989 AVG Test Loss:1.024 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.955 AVG Test Loss:1.801 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.761 AVG Test Loss:0.634 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:0.891 AVG Test Loss:0.777 AVG Training Acc 25.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.866 AVG Test Loss:1.330 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.813 AVG Test Loss:0.737 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.693 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.654 AVG Test Loss:0.734 AVG Training Acc 71.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.581 AVG Test Loss:0.719 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.520 AVG Test Loss:0.717 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.461 AVG Test Loss:0.722 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.385 AVG Test Loss:0.709 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.317 AVG Test Loss:0.724 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.256 AVG Test Loss:0.719 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.245 AVG Test Loss:0.674 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.166 AVG Test Loss:0.695 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Epoch:20/20 AVG Training Loss:0.352 AVG Test Loss:0.669 AVG Training Acc 81.25 % AVG Test Acc 63.64 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.909 AVG Test Loss:0.765 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.236 AVG Test Loss:0.989 AVG Training Acc 28.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.166 AVG Test Loss:1.887 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.807 AVG Test Loss:0.820 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.668 AVG Test Loss:0.766 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:0.512 AVG Test Loss:0.722 AVG Training Acc 87.50 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.379 AVG Test Loss:0.742 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.263 AVG Test Loss:0.722 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.156 AVG Test Loss:0.733 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.089 AVG Test Loss:0.734 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.051 AVG Test Loss:0.727 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.031 AVG Test Loss:0.719 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.021 AVG Test Loss:0.731 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.016 AVG Test Loss:0.728 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.012 AVG Test Loss:0.723 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.010 AVG Test Loss:0.726 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.009 AVG Test Loss:0.729 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.008 AVG Test Loss:0.729 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.007 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.006 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.917 AVG Test Loss:0.712 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.099 AVG Test Loss:12.883 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.050 AVG Test Loss:1.540 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.994 AVG Test Loss:1.409 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.782 AVG Test Loss:2.113 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.965 AVG Test Loss:1.101 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.801 AVG Test Loss:0.693 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.832 AVG Test Loss:0.702 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.758 AVG Test Loss:0.723 AVG Training Acc 28.12 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:0.662 AVG Test Loss:0.778 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.609 AVG Test Loss:0.821 AVG Training Acc 75.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.559 AVG Test Loss:0.809 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.569 AVG Test Loss:0.778 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.456 AVG Test Loss:0.757 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.383 AVG Test Loss:0.789 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.363 AVG Test Loss:0.699 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.293 AVG Test Loss:0.894 AVG Training Acc 96.88 % AVG Test Acc 18.18 %\n",
            "Epoch:18/20 AVG Training Loss:0.452 AVG Test Loss:0.818 AVG Training Acc 93.75 % AVG Test Acc 27.27 %\n",
            "Epoch:19/20 AVG Training Loss:0.284 AVG Test Loss:0.825 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.213 AVG Test Loss:0.721 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.896 AVG Test Loss:0.705 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.111 AVG Test Loss:0.970 AVG Training Acc 33.33 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.131 AVG Test Loss:4.841 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.003 AVG Test Loss:4.203 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.010 AVG Test Loss:1.323 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.888 AVG Test Loss:0.841 AVG Training Acc 9.09 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.890 AVG Test Loss:1.072 AVG Training Acc 15.15 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.904 AVG Test Loss:1.775 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.792 AVG Test Loss:2.141 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.741 AVG Test Loss:0.726 AVG Training Acc 30.30 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.681 AVG Test Loss:0.653 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.650 AVG Test Loss:0.662 AVG Training Acc 66.67 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.603 AVG Test Loss:0.668 AVG Training Acc 78.79 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.550 AVG Test Loss:0.697 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.501 AVG Test Loss:0.726 AVG Training Acc 90.91 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.440 AVG Test Loss:0.728 AVG Training Acc 96.97 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.371 AVG Test Loss:0.761 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.316 AVG Test Loss:1.200 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.416 AVG Test Loss:0.705 AVG Training Acc 84.85 % AVG Test Acc 60.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.434 AVG Test Loss:1.344 AVG Training Acc 87.88 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 42.30769230769231 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 49.213286713286706 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.734 AVG Test Loss:0.978 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.412 AVG Test Loss:1.819 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.008 AVG Test Loss:9.006 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.740 AVG Test Loss:1.030 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.650 AVG Test Loss:3.075 AVG Training Acc 68.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.591 AVG Test Loss:1.300 AVG Training Acc 78.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.496 AVG Test Loss:0.926 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.394 AVG Test Loss:1.833 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.361 AVG Test Loss:0.845 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.292 AVG Test Loss:0.755 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.134 AVG Test Loss:0.666 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.074 AVG Test Loss:0.723 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.038 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.023 AVG Test Loss:0.753 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.016 AVG Test Loss:0.763 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.012 AVG Test Loss:0.764 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.010 AVG Test Loss:0.771 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.008 AVG Test Loss:0.780 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.007 AVG Test Loss:0.787 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.006 AVG Test Loss:0.792 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.811 AVG Test Loss:0.745 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.226 AVG Test Loss:1.957 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.016 AVG Test Loss:0.752 AVG Training Acc 28.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.874 AVG Test Loss:1.679 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.788 AVG Test Loss:0.689 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.890 AVG Test Loss:0.730 AVG Training Acc 15.62 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.802 AVG Test Loss:0.953 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.848 AVG Test Loss:1.889 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.666 AVG Test Loss:1.027 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.635 AVG Test Loss:0.729 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.590 AVG Test Loss:0.705 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.452 AVG Test Loss:0.710 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.415 AVG Test Loss:0.717 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.266 AVG Test Loss:0.717 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.221 AVG Test Loss:0.714 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.159 AVG Test Loss:0.699 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.144 AVG Test Loss:0.734 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.065 AVG Test Loss:0.703 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.049 AVG Test Loss:0.678 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:0.036 AVG Test Loss:0.648 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.836 AVG Test Loss:0.753 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.122 AVG Test Loss:2.020 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.824 AVG Test Loss:0.677 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.709 AVG Test Loss:0.680 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.600 AVG Test Loss:0.680 AVG Training Acc 84.38 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.475 AVG Test Loss:0.695 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.350 AVG Test Loss:0.686 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.216 AVG Test Loss:0.682 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.124 AVG Test Loss:0.667 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.070 AVG Test Loss:0.649 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.042 AVG Test Loss:0.654 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.027 AVG Test Loss:0.656 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:0.019 AVG Test Loss:0.653 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.015 AVG Test Loss:0.668 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.012 AVG Test Loss:0.692 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.010 AVG Test Loss:0.707 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.008 AVG Test Loss:0.715 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.007 AVG Test Loss:0.724 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.007 AVG Test Loss:0.733 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.006 AVG Test Loss:0.738 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.776 AVG Test Loss:0.696 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.116 AVG Test Loss:2.321 AVG Training Acc 30.30 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.169 AVG Test Loss:1.393 AVG Training Acc 12.12 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.868 AVG Test Loss:0.818 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.934 AVG Test Loss:0.968 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.848 AVG Test Loss:1.657 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.794 AVG Test Loss:0.692 AVG Training Acc 21.21 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.926 AVG Test Loss:0.835 AVG Training Acc 6.06 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.815 AVG Test Loss:0.687 AVG Training Acc 30.30 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.744 AVG Test Loss:0.816 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.715 AVG Test Loss:0.687 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.645 AVG Test Loss:0.685 AVG Training Acc 69.70 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.566 AVG Test Loss:0.698 AVG Training Acc 84.85 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.509 AVG Test Loss:0.699 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.450 AVG Test Loss:0.737 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.395 AVG Test Loss:0.654 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.464 AVG Test Loss:0.692 AVG Training Acc 78.79 % AVG Test Acc 60.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.541 AVG Test Loss:0.665 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.321 AVG Test Loss:0.837 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.230 AVG Test Loss:0.790 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 45.45454545454545 %\n",
            " Average acc: 45.97902097902098 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.725 AVG Test Loss:0.712 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.194 AVG Test Loss:3.888 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.155 AVG Test Loss:10.937 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.816 AVG Test Loss:2.952 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.706 AVG Test Loss:3.667 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.605 AVG Test Loss:0.718 AVG Training Acc 71.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.530 AVG Test Loss:0.695 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.422 AVG Test Loss:0.675 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.352 AVG Test Loss:0.689 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.235 AVG Test Loss:0.682 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.160 AVG Test Loss:0.690 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.120 AVG Test Loss:0.703 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.115 AVG Test Loss:0.677 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.058 AVG Test Loss:0.666 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.037 AVG Test Loss:0.672 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.025 AVG Test Loss:0.672 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.019 AVG Test Loss:0.664 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.015 AVG Test Loss:0.668 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.013 AVG Test Loss:0.673 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.011 AVG Test Loss:0.675 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.805 AVG Test Loss:0.844 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.219 AVG Test Loss:0.695 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.941 AVG Test Loss:0.692 AVG Training Acc 28.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.683 AVG Test Loss:0.707 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.559 AVG Test Loss:0.693 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.506 AVG Test Loss:0.699 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.391 AVG Test Loss:0.696 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.274 AVG Test Loss:0.718 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.184 AVG Test Loss:0.734 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.130 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.093 AVG Test Loss:0.706 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.060 AVG Test Loss:0.685 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:0.035 AVG Test Loss:0.726 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.025 AVG Test Loss:0.765 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.018 AVG Test Loss:0.811 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.014 AVG Test Loss:0.834 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.012 AVG Test Loss:0.824 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.010 AVG Test Loss:0.816 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.009 AVG Test Loss:0.822 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.008 AVG Test Loss:0.829 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.825 AVG Test Loss:0.790 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.120 AVG Test Loss:1.046 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.915 AVG Test Loss:0.789 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.709 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.606 AVG Test Loss:0.675 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.470 AVG Test Loss:0.691 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.371 AVG Test Loss:0.694 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.318 AVG Test Loss:0.694 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.287 AVG Test Loss:0.789 AVG Training Acc 96.88 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:0.221 AVG Test Loss:0.778 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.133 AVG Test Loss:0.813 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.074 AVG Test Loss:0.896 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.041 AVG Test Loss:0.877 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.024 AVG Test Loss:0.871 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.017 AVG Test Loss:0.857 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.013 AVG Test Loss:0.856 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.011 AVG Test Loss:0.866 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.009 AVG Test Loss:0.878 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.008 AVG Test Loss:0.885 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.007 AVG Test Loss:0.886 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.797 AVG Test Loss:0.684 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.007 AVG Test Loss:2.715 AVG Training Acc 30.30 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.098 AVG Test Loss:0.830 AVG Training Acc 9.09 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.868 AVG Test Loss:1.071 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.856 AVG Test Loss:1.114 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.959 AVG Test Loss:1.418 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.876 AVG Test Loss:0.775 AVG Training Acc 12.12 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.881 AVG Test Loss:0.830 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.780 AVG Test Loss:0.776 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.729 AVG Test Loss:0.720 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.699 AVG Test Loss:0.689 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.634 AVG Test Loss:0.700 AVG Training Acc 75.76 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.587 AVG Test Loss:0.710 AVG Training Acc 87.88 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.524 AVG Test Loss:0.715 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.443 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.364 AVG Test Loss:0.667 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.356 AVG Test Loss:0.746 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.398 AVG Test Loss:0.645 AVG Training Acc 96.97 % AVG Test Acc 70.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.257 AVG Test Loss:0.673 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.175 AVG Test Loss:0.692 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 40.909090909090914 %\n",
            " Average acc: 41.026645768025084 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.818 AVG Test Loss:0.770 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.232 AVG Test Loss:2.861 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.091 AVG Test Loss:4.245 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.980 AVG Test Loss:1.558 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.947 AVG Test Loss:1.247 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.858 AVG Test Loss:1.160 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.892 AVG Test Loss:2.100 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.859 AVG Test Loss:1.203 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.719 AVG Test Loss:0.718 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.666 AVG Test Loss:0.743 AVG Training Acc 68.75 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.625 AVG Test Loss:0.724 AVG Training Acc 71.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.564 AVG Test Loss:0.720 AVG Training Acc 75.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.502 AVG Test Loss:0.739 AVG Training Acc 90.62 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.412 AVG Test Loss:0.714 AVG Training Acc 96.88 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.414 AVG Test Loss:0.675 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.309 AVG Test Loss:0.764 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.238 AVG Test Loss:1.012 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.195 AVG Test Loss:0.710 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.329 AVG Test Loss:1.772 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.169 AVG Test Loss:0.672 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.766 AVG Test Loss:0.702 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.248 AVG Test Loss:1.728 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.022 AVG Test Loss:0.662 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.898 AVG Test Loss:2.154 AVG Training Acc 25.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.839 AVG Test Loss:1.010 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.891 AVG Test Loss:1.025 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.757 AVG Test Loss:1.034 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.003 AVG Test Loss:0.761 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.746 AVG Test Loss:1.271 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.747 AVG Test Loss:0.777 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.628 AVG Test Loss:0.705 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.545 AVG Test Loss:0.736 AVG Training Acc 90.62 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.489 AVG Test Loss:0.719 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.402 AVG Test Loss:0.742 AVG Training Acc 100.00 % AVG Test Acc 18.18 %\n",
            "Epoch:15/20 AVG Training Loss:0.382 AVG Test Loss:0.732 AVG Training Acc 100.00 % AVG Test Acc 18.18 %\n",
            "Epoch:16/20 AVG Training Loss:0.335 AVG Test Loss:0.753 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.237 AVG Test Loss:0.698 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.173 AVG Test Loss:0.701 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.128 AVG Test Loss:0.692 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.132 AVG Test Loss:0.991 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.834 AVG Test Loss:0.784 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.083 AVG Test Loss:1.372 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.218 AVG Test Loss:1.683 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.924 AVG Test Loss:2.831 AVG Training Acc 15.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.818 AVG Test Loss:0.839 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.889 AVG Test Loss:0.733 AVG Training Acc 6.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.721 AVG Test Loss:0.833 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.682 AVG Test Loss:0.740 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.630 AVG Test Loss:0.690 AVG Training Acc 71.88 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.554 AVG Test Loss:0.695 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.502 AVG Test Loss:0.676 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.425 AVG Test Loss:0.731 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.348 AVG Test Loss:0.702 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.286 AVG Test Loss:0.791 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.353 AVG Test Loss:0.718 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.259 AVG Test Loss:0.723 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.171 AVG Test Loss:0.882 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.157 AVG Test Loss:0.779 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.133 AVG Test Loss:0.814 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.058 AVG Test Loss:0.845 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.854 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.119 AVG Test Loss:1.973 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.117 AVG Test Loss:0.690 AVG Training Acc 6.06 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.886 AVG Test Loss:0.841 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.926 AVG Test Loss:1.175 AVG Training Acc 24.24 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.896 AVG Test Loss:1.075 AVG Training Acc 9.09 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.802 AVG Test Loss:0.745 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.916 AVG Test Loss:0.748 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.848 AVG Test Loss:0.862 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.827 AVG Test Loss:0.728 AVG Training Acc 24.24 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.771 AVG Test Loss:0.684 AVG Training Acc 21.21 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.731 AVG Test Loss:1.097 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.677 AVG Test Loss:0.710 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.608 AVG Test Loss:0.714 AVG Training Acc 81.82 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.559 AVG Test Loss:0.937 AVG Training Acc 84.85 % AVG Test Acc 30.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.499 AVG Test Loss:0.781 AVG Training Acc 96.97 % AVG Test Acc 30.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.497 AVG Test Loss:0.852 AVG Training Acc 84.85 % AVG Test Acc 30.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.407 AVG Test Loss:0.833 AVG Training Acc 100.00 % AVG Test Acc 20.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.385 AVG Test Loss:0.931 AVG Training Acc 93.94 % AVG Test Acc 20.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.318 AVG Test Loss:0.734 AVG Training Acc 96.97 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 45.45454545454546 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.754 AVG Test Loss:0.953 AVG Training Acc 34.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.275 AVG Test Loss:5.807 AVG Training Acc 34.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.053 AVG Test Loss:1.444 AVG Training Acc 15.62 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.993 AVG Test Loss:0.618 AVG Training Acc 18.75 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.832 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.771 AVG Test Loss:0.712 AVG Training Acc 28.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.721 AVG Test Loss:0.698 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.629 AVG Test Loss:0.697 AVG Training Acc 68.75 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.549 AVG Test Loss:0.694 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.474 AVG Test Loss:0.719 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.391 AVG Test Loss:0.722 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.305 AVG Test Loss:0.752 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.240 AVG Test Loss:0.709 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.169 AVG Test Loss:0.729 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.108 AVG Test Loss:0.713 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.067 AVG Test Loss:0.701 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:0.051 AVG Test Loss:0.706 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.033 AVG Test Loss:0.713 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.024 AVG Test Loss:0.724 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.019 AVG Test Loss:0.729 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.752 AVG Test Loss:0.773 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.084 AVG Test Loss:0.935 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.045 AVG Test Loss:0.890 AVG Training Acc 28.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.003 AVG Test Loss:2.142 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.652 AVG Test Loss:1.979 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.596 AVG Test Loss:1.056 AVG Training Acc 75.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.496 AVG Test Loss:0.786 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.392 AVG Test Loss:0.737 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.354 AVG Test Loss:0.809 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.238 AVG Test Loss:0.734 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.165 AVG Test Loss:0.908 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.135 AVG Test Loss:0.732 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.178 AVG Test Loss:0.670 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:0.091 AVG Test Loss:0.674 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Epoch:15/20 AVG Training Loss:0.058 AVG Test Loss:0.695 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.042 AVG Test Loss:0.692 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.031 AVG Test Loss:0.689 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.020 AVG Test Loss:0.694 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.015 AVG Test Loss:0.694 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.013 AVG Test Loss:0.693 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.822 AVG Test Loss:0.725 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.177 AVG Test Loss:4.262 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.901 AVG Test Loss:1.595 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.815 AVG Test Loss:1.475 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.717 AVG Test Loss:1.182 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:0.648 AVG Test Loss:0.729 AVG Training Acc 75.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.513 AVG Test Loss:0.704 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.415 AVG Test Loss:0.702 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.323 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.234 AVG Test Loss:0.781 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.212 AVG Test Loss:0.799 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.147 AVG Test Loss:0.812 AVG Training Acc 100.00 % AVG Test Acc 18.18 %\n",
            "Epoch:13/20 AVG Training Loss:0.111 AVG Test Loss:0.836 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.078 AVG Test Loss:0.900 AVG Training Acc 100.00 % AVG Test Acc 18.18 %\n",
            "Epoch:15/20 AVG Training Loss:0.049 AVG Test Loss:0.780 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.032 AVG Test Loss:0.883 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.024 AVG Test Loss:0.917 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.017 AVG Test Loss:0.943 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.014 AVG Test Loss:0.965 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.012 AVG Test Loss:0.983 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.761 AVG Test Loss:0.733 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.174 AVG Test Loss:2.312 AVG Training Acc 21.21 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.086 AVG Test Loss:1.020 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.832 AVG Test Loss:21.675 AVG Training Acc 33.33 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.836 AVG Test Loss:7.234 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.866 AVG Test Loss:1.680 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.804 AVG Test Loss:0.835 AVG Training Acc 18.18 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.918 AVG Test Loss:0.672 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.798 AVG Test Loss:0.783 AVG Training Acc 15.15 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.756 AVG Test Loss:0.675 AVG Training Acc 12.12 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.693 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.649 AVG Test Loss:0.754 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.600 AVG Test Loss:0.766 AVG Training Acc 84.85 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.544 AVG Test Loss:0.754 AVG Training Acc 90.91 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.477 AVG Test Loss:0.749 AVG Training Acc 93.94 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.438 AVG Test Loss:0.728 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.374 AVG Test Loss:0.776 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.339 AVG Test Loss:0.682 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.244 AVG Test Loss:0.794 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.181 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.30769230769231 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 50.57692307692307 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:2.023 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.036 AVG Test Loss:2.118 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.804 AVG Test Loss:0.743 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.721 AVG Test Loss:0.691 AVG Training Acc 34.38 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.590 AVG Test Loss:0.710 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.521 AVG Test Loss:0.723 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.425 AVG Test Loss:0.714 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.316 AVG Test Loss:0.689 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.286 AVG Test Loss:0.733 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.216 AVG Test Loss:1.240 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.263 AVG Test Loss:0.732 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.181 AVG Test Loss:0.796 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.092 AVG Test Loss:0.809 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.093 AVG Test Loss:0.771 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.140 AVG Test Loss:0.575 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.053 AVG Test Loss:0.766 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.041 AVG Test Loss:0.712 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.024 AVG Test Loss:0.839 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.015 AVG Test Loss:0.713 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.012 AVG Test Loss:0.662 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:2.040 AVG Test Loss:0.714 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.120 AVG Test Loss:0.921 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.863 AVG Test Loss:0.704 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.663 AVG Test Loss:0.699 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.526 AVG Test Loss:0.691 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.397 AVG Test Loss:0.688 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.335 AVG Test Loss:0.703 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.232 AVG Test Loss:0.717 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.181 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:0.140 AVG Test Loss:0.740 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.107 AVG Test Loss:0.753 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.073 AVG Test Loss:0.744 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.057 AVG Test Loss:0.876 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.074 AVG Test Loss:0.797 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.046 AVG Test Loss:0.768 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.023 AVG Test Loss:0.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.018 AVG Test Loss:0.740 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.013 AVG Test Loss:0.751 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.010 AVG Test Loss:0.766 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.008 AVG Test Loss:0.786 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:2.040 AVG Test Loss:0.801 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.021 AVG Test Loss:13.410 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.095 AVG Test Loss:0.659 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.018 AVG Test Loss:2.946 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.761 AVG Test Loss:0.761 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.952 AVG Test Loss:1.499 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.882 AVG Test Loss:1.791 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.843 AVG Test Loss:0.747 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.749 AVG Test Loss:0.767 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.637 AVG Test Loss:0.968 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.606 AVG Test Loss:0.869 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.552 AVG Test Loss:0.780 AVG Training Acc 75.00 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.497 AVG Test Loss:0.777 AVG Training Acc 87.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.415 AVG Test Loss:0.740 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.353 AVG Test Loss:0.731 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.308 AVG Test Loss:0.753 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.219 AVG Test Loss:0.727 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.182 AVG Test Loss:0.754 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.286 AVG Test Loss:0.717 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.382 AVG Test Loss:1.427 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.963 AVG Test Loss:0.744 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.043 AVG Test Loss:1.110 AVG Training Acc 33.33 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.075 AVG Test Loss:0.679 AVG Training Acc 30.30 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.016 AVG Test Loss:4.566 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.993 AVG Test Loss:2.455 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.745 AVG Test Loss:2.192 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.861 AVG Test Loss:3.940 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.915 AVG Test Loss:0.870 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.883 AVG Test Loss:0.913 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.776 AVG Test Loss:1.758 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.738 AVG Test Loss:0.746 AVG Training Acc 30.30 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.697 AVG Test Loss:0.679 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.639 AVG Test Loss:0.663 AVG Training Acc 72.73 % AVG Test Acc 80.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.598 AVG Test Loss:0.654 AVG Training Acc 81.82 % AVG Test Acc 80.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.542 AVG Test Loss:0.691 AVG Training Acc 84.85 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.477 AVG Test Loss:0.749 AVG Training Acc 96.97 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.458 AVG Test Loss:1.015 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.510 AVG Test Loss:0.848 AVG Training Acc 78.79 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.641 AVG Test Loss:1.049 AVG Training Acc 75.76 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.510 AVG Test Loss:0.708 AVG Training Acc 75.76 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 48.369303110682424 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:2.032 AVG Test Loss:0.735 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.193 AVG Test Loss:0.708 AVG Training Acc 25.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.846 AVG Test Loss:0.774 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.735 AVG Test Loss:0.686 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.610 AVG Test Loss:0.688 AVG Training Acc 78.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.484 AVG Test Loss:0.685 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:0.434 AVG Test Loss:0.677 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.336 AVG Test Loss:0.690 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.248 AVG Test Loss:0.704 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.158 AVG Test Loss:0.688 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.099 AVG Test Loss:0.725 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.071 AVG Test Loss:0.673 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:0.045 AVG Test Loss:0.658 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:0.031 AVG Test Loss:0.699 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.023 AVG Test Loss:0.698 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.018 AVG Test Loss:0.668 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.014 AVG Test Loss:0.664 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.012 AVG Test Loss:0.670 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.011 AVG Test Loss:0.678 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.009 AVG Test Loss:0.686 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:2.123 AVG Test Loss:0.713 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.120 AVG Test Loss:3.228 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.990 AVG Test Loss:0.685 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.666 AVG Test Loss:0.690 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.524 AVG Test Loss:0.722 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.466 AVG Test Loss:0.816 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.331 AVG Test Loss:0.785 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.266 AVG Test Loss:0.843 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.229 AVG Test Loss:0.759 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.128 AVG Test Loss:0.780 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.077 AVG Test Loss:0.791 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.057 AVG Test Loss:0.764 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:0.041 AVG Test Loss:0.794 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.029 AVG Test Loss:0.862 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.022 AVG Test Loss:0.874 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.018 AVG Test Loss:0.858 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.015 AVG Test Loss:0.868 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.013 AVG Test Loss:0.902 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.011 AVG Test Loss:0.936 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.010 AVG Test Loss:0.952 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:2.108 AVG Test Loss:0.787 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.077 AVG Test Loss:17.620 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.113 AVG Test Loss:3.041 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.122 AVG Test Loss:2.259 AVG Training Acc 15.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.799 AVG Test Loss:2.399 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.679 AVG Test Loss:1.428 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.611 AVG Test Loss:0.722 AVG Training Acc 68.75 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.521 AVG Test Loss:0.763 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.417 AVG Test Loss:0.724 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.343 AVG Test Loss:0.719 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.318 AVG Test Loss:0.745 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.207 AVG Test Loss:0.785 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.144 AVG Test Loss:0.736 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.133 AVG Test Loss:0.766 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.076 AVG Test Loss:0.767 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:16/20 AVG Training Loss:0.048 AVG Test Loss:0.880 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.037 AVG Test Loss:0.800 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.025 AVG Test Loss:0.777 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.018 AVG Test Loss:0.794 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.015 AVG Test Loss:0.813 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:2.086 AVG Test Loss:0.719 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.961 AVG Test Loss:1.608 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.207 AVG Test Loss:4.538 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.972 AVG Test Loss:6.256 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.827 AVG Test Loss:1.104 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.709 AVG Test Loss:2.381 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.690 AVG Test Loss:0.709 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.584 AVG Test Loss:0.728 AVG Training Acc 78.79 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.547 AVG Test Loss:0.703 AVG Training Acc 75.76 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.452 AVG Test Loss:0.707 AVG Training Acc 96.97 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.383 AVG Test Loss:0.694 AVG Training Acc 96.97 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.282 AVG Test Loss:0.999 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.278 AVG Test Loss:0.664 AVG Training Acc 96.97 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.190 AVG Test Loss:0.710 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.124 AVG Test Loss:1.220 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.105 AVG Test Loss:1.631 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.089 AVG Test Loss:0.685 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.031 AVG Test Loss:0.992 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.027 AVG Test Loss:0.892 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.014 AVG Test Loss:0.792 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 41.37931034482759 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.55329153605015 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.711 AVG Test Loss:0.876 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.322 AVG Test Loss:0.675 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.962 AVG Test Loss:0.897 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.906 AVG Test Loss:0.854 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.902 AVG Test Loss:0.906 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.873 AVG Test Loss:0.967 AVG Training Acc 6.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.728 AVG Test Loss:0.805 AVG Training Acc 34.38 % AVG Test Acc 18.18 %\n",
            "Epoch:8/20 AVG Training Loss:0.658 AVG Test Loss:0.751 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.593 AVG Test Loss:0.745 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.559 AVG Test Loss:0.711 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.429 AVG Test Loss:0.711 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.376 AVG Test Loss:0.675 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:0.252 AVG Test Loss:0.650 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.209 AVG Test Loss:0.686 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.192 AVG Test Loss:0.608 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.261 AVG Test Loss:1.038 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.178 AVG Test Loss:0.559 AVG Training Acc 96.88 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:0.089 AVG Test Loss:0.772 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.047 AVG Test Loss:0.847 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.034 AVG Test Loss:0.763 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.764 AVG Test Loss:0.717 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.128 AVG Test Loss:4.633 AVG Training Acc 25.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.096 AVG Test Loss:1.470 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.992 AVG Test Loss:1.398 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.691 AVG Test Loss:0.747 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.657 AVG Test Loss:0.753 AVG Training Acc 68.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.586 AVG Test Loss:0.732 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.499 AVG Test Loss:0.713 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.427 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.341 AVG Test Loss:0.722 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.248 AVG Test Loss:0.742 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.166 AVG Test Loss:0.746 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.128 AVG Test Loss:0.698 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.082 AVG Test Loss:0.693 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.046 AVG Test Loss:0.709 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.031 AVG Test Loss:0.703 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.020 AVG Test Loss:0.688 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.016 AVG Test Loss:0.693 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.012 AVG Test Loss:0.689 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.010 AVG Test Loss:0.683 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.837 AVG Test Loss:0.771 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.061 AVG Test Loss:3.145 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.931 AVG Test Loss:7.004 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.990 AVG Test Loss:14.144 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.875 AVG Test Loss:5.384 AVG Training Acc 25.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.931 AVG Test Loss:2.283 AVG Training Acc 15.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.732 AVG Test Loss:0.737 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.675 AVG Test Loss:0.710 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.635 AVG Test Loss:0.670 AVG Training Acc 75.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.588 AVG Test Loss:0.647 AVG Training Acc 84.38 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.516 AVG Test Loss:0.640 AVG Training Acc 90.62 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:0.432 AVG Test Loss:0.673 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.363 AVG Test Loss:0.640 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.307 AVG Test Loss:0.770 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.253 AVG Test Loss:0.672 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.192 AVG Test Loss:0.791 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.134 AVG Test Loss:0.708 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.084 AVG Test Loss:0.727 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.074 AVG Test Loss:0.656 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.050 AVG Test Loss:0.684 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.742 AVG Test Loss:0.664 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.046 AVG Test Loss:0.829 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.110 AVG Test Loss:1.237 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.880 AVG Test Loss:1.125 AVG Training Acc 24.24 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.789 AVG Test Loss:0.694 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.869 AVG Test Loss:0.789 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.891 AVG Test Loss:0.971 AVG Training Acc 21.21 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.941 AVG Test Loss:2.654 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.830 AVG Test Loss:2.233 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.812 AVG Test Loss:1.204 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.715 AVG Test Loss:0.974 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.694 AVG Test Loss:0.694 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.602 AVG Test Loss:0.752 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.550 AVG Test Loss:0.771 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.498 AVG Test Loss:0.825 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.431 AVG Test Loss:0.803 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.357 AVG Test Loss:0.787 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.288 AVG Test Loss:0.835 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.225 AVG Test Loss:0.838 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.245 AVG Test Loss:0.707 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 57.95454545454546 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset shape: torch.Size([3, 192, 192])\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.877 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.193 AVG Test Loss:1.443 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.023 AVG Test Loss:0.763 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.936 AVG Test Loss:0.777 AVG Training Acc 21.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.723 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.645 AVG Test Loss:0.738 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.526 AVG Test Loss:0.708 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.414 AVG Test Loss:0.691 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.327 AVG Test Loss:0.696 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.199 AVG Test Loss:0.682 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.142 AVG Test Loss:0.720 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.081 AVG Test Loss:0.716 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.047 AVG Test Loss:0.718 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.031 AVG Test Loss:0.710 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.021 AVG Test Loss:0.717 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.016 AVG Test Loss:0.741 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.013 AVG Test Loss:0.741 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.011 AVG Test Loss:0.732 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.009 AVG Test Loss:0.734 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.008 AVG Test Loss:0.743 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.929 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.997 AVG Test Loss:2.044 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.783 AVG Test Loss:0.721 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.551 AVG Test Loss:0.693 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.411 AVG Test Loss:0.703 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.322 AVG Test Loss:0.714 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.203 AVG Test Loss:0.704 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.147 AVG Test Loss:0.773 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.085 AVG Test Loss:0.871 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.052 AVG Test Loss:0.874 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.037 AVG Test Loss:0.851 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.026 AVG Test Loss:0.862 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.019 AVG Test Loss:0.927 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.015 AVG Test Loss:0.977 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.013 AVG Test Loss:0.997 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.011 AVG Test Loss:1.009 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.009 AVG Test Loss:1.020 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.008 AVG Test Loss:1.038 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.007 AVG Test Loss:1.061 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.946 AVG Test Loss:0.710 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.046 AVG Test Loss:6.319 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.013 AVG Test Loss:1.731 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.961 AVG Test Loss:3.215 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.868 AVG Test Loss:1.728 AVG Training Acc 31.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.925 AVG Test Loss:1.206 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.757 AVG Test Loss:0.970 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.690 AVG Test Loss:1.933 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.664 AVG Test Loss:0.825 AVG Training Acc 68.75 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.589 AVG Test Loss:0.751 AVG Training Acc 75.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.497 AVG Test Loss:0.726 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.440 AVG Test Loss:0.696 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.374 AVG Test Loss:0.677 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.434 AVG Test Loss:0.822 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.341 AVG Test Loss:0.656 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.262 AVG Test Loss:0.867 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.258 AVG Test Loss:0.650 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.151 AVG Test Loss:0.776 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.125 AVG Test Loss:0.662 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.057 AVG Test Loss:0.668 AVG Training Acc 100.00 % AVG Test Acc 72.73 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.862 AVG Test Loss:0.673 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.030 AVG Test Loss:0.872 AVG Training Acc 33.33 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.096 AVG Test Loss:1.464 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.937 AVG Test Loss:1.248 AVG Training Acc 12.12 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.015 AVG Test Loss:0.857 AVG Training Acc 12.12 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.726 AVG Test Loss:0.670 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.679 AVG Test Loss:0.690 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.660 AVG Test Loss:0.704 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.581 AVG Test Loss:0.719 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.520 AVG Test Loss:0.717 AVG Training Acc 93.94 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.460 AVG Test Loss:0.715 AVG Training Acc 96.97 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.377 AVG Test Loss:0.755 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.314 AVG Test Loss:0.763 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.254 AVG Test Loss:0.811 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.148 AVG Test Loss:0.827 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.081 AVG Test Loss:0.763 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.048 AVG Test Loss:0.755 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.030 AVG Test Loss:0.793 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.021 AVG Test Loss:0.821 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.016 AVG Test Loss:0.820 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 50.6420303834097 %\n",
            "Runed  10  times. Results: [0.49890282131661434, 0.4921328671328671, 0.4597902097902098, 0.41026645768025083, 0.4545454545454546, 0.5057692307692307, 0.4836930311068242, 0.44553291536050155, 0.5795454545454546, 0.506420303834097]  avg: 0.4836598746081505  std: 0.04331594897758407\n"
          ]
        }
      ],
      "source": [
        "#trianing resnet (without grid search) a lot of times\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),                                  \n",
        "      # transforms.RandomHorizontalFlip(p=0.5),\n",
        "      # transforms.RandomRotation(degrees=(-1*90, 90)),\n",
        "      # transforms.RandomAffine(degrees=0, scale=(1.0-0.4, 1.0+0.4), shear=0),\n",
        "      # #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "      # transforms.RandomVerticalFlip(p=0.5),\n",
        "      transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "times = 10\n",
        "final_acc = []\n",
        "\n",
        "for _ in range(times):\n",
        "  finetune_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
        "  num_ftrs = finetune_model.fc.in_features\n",
        "  finetune_model.fc = nn.Linear(num_ftrs, 2)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  finetune_model = finetune_model.to(device)\n",
        "  #print(finetune_model)\n",
        "\n",
        "  dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, True)\n",
        "  print(\"Train dataset shape:\", dataset[0][0].shape)\n",
        "\n",
        "  splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "\n",
        "  def model_getter():\n",
        "    return copy.deepcopy(finetune_model)\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits, resnet=True)\n",
        "  acc = print_and_save_folds_results(results, grid_param, SPREEDSHEET_NAME_FINAL)\n",
        "  final_acc.append(acc)\n",
        "print(\"Runed \", times, \" times. Results:\", final_acc, \" avg:\", np.mean(final_acc), \" std:\", np.std(final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj0_uJyEe5wf",
        "outputId": "ad29d32d-a9da-4159-f9e3-c52221071b85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "Epoch:4/8 AVG Training Loss:2.035 AVG Test Loss:0.866 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:1.086 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.561 AVG Test Loss:0.884 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.261 AVG Test Loss:0.748 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.988 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:6.571 AVG Test Loss:0.756 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.120 AVG Test Loss:1.485 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:3.604 AVG Test Loss:0.888 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:2.093 AVG Test Loss:0.789 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:5/8 AVG Training Loss:1.130 AVG Test Loss:0.680 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.543 AVG Test Loss:0.940 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:1.216 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.992 AVG Test Loss:0.676 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 41.37931034482759 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 41.87192118226601 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:6.319 AVG Test Loss:0.824 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.126 AVG Test Loss:1.344 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.793 AVG Test Loss:0.841 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:2.036 AVG Test Loss:0.860 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.106 AVG Test Loss:0.687 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.546 AVG Test Loss:0.876 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.253 AVG Test Loss:0.750 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.992 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.797 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.639 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.691 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.804 AVG Test Loss:0.717 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.788 AVG Test Loss:0.692 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.735 AVG Test Loss:0.685 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.684 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:0.686 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.712 AVG Test Loss:0.701 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:0.712 AVG Test Loss:0.688 AVG Training Acc 47.62 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:6.349 AVG Test Loss:0.823 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.124 AVG Test Loss:1.356 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.769 AVG Test Loss:0.839 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:2.035 AVG Test Loss:0.866 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.086 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.561 AVG Test Loss:0.884 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.261 AVG Test Loss:0.748 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.988 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.792 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.634 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.700 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.810 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.787 AVG Test Loss:0.694 AVG Training Acc 9.52 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.733 AVG Test Loss:0.688 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.717 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.734 AVG Test Loss:0.704 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.728 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:20/20 AVG Training Loss:0.712 AVG Test Loss:0.694 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:6.571 AVG Test Loss:0.756 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.120 AVG Test Loss:1.485 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:3.604 AVG Test Loss:0.888 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:2.093 AVG Test Loss:0.789 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.130 AVG Test Loss:0.680 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.543 AVG Test Loss:0.940 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.216 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.992 AVG Test Loss:0.676 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.817 AVG Test Loss:0.676 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.644 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.689 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.796 AVG Test Loss:0.729 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.786 AVG Test Loss:0.694 AVG Training Acc 13.64 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.742 AVG Test Loss:0.682 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.701 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.690 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.713 AVG Test Loss:0.712 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.730 AVG Test Loss:0.691 AVG Training Acc 4.55 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.717 AVG Test Loss:0.687 AVG Training Acc 40.91 % AVG Test Acc 70.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 70.0 %\n",
            " Average acc: 62.727272727272734 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:6.319 AVG Test Loss:0.824 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.126 AVG Test Loss:1.344 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.793 AVG Test Loss:0.841 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:2.036 AVG Test Loss:0.860 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:1.106 AVG Test Loss:0.687 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.546 AVG Test Loss:0.876 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.253 AVG Test Loss:0.750 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.992 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.797 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.639 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.691 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.804 AVG Test Loss:0.717 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.788 AVG Test Loss:0.692 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.735 AVG Test Loss:0.685 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.695 AVG Test Loss:0.684 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:16/50 AVG Training Loss:0.686 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.712 AVG Test Loss:0.701 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.727 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:20/50 AVG Training Loss:0.712 AVG Test Loss:0.688 AVG Training Acc 47.62 % AVG Test Acc 72.73 %\n",
            "Epoch:21/50 AVG Training Loss:0.701 AVG Test Loss:0.689 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.701 AVG Test Loss:0.693 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.708 AVG Test Loss:0.693 AVG Training Acc 23.81 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.713 AVG Test Loss:0.691 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.710 AVG Test Loss:0.690 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.705 AVG Test Loss:0.690 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.702 AVG Test Loss:0.691 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:28/50 AVG Training Loss:0.702 AVG Test Loss:0.692 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 38.10 % AVG Test Acc 36.36 %\n",
            "Epoch:31/50 AVG Training Loss:0.703 AVG Test Loss:0.692 AVG Training Acc 38.10 % AVG Test Acc 36.36 %\n",
            "Epoch:32/50 AVG Training Loss:0.700 AVG Test Loss:0.692 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:33/50 AVG Training Loss:0.699 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:34/50 AVG Training Loss:0.699 AVG Test Loss:0.693 AVG Training Acc 38.10 % AVG Test Acc 36.36 %\n",
            "Epoch:35/50 AVG Training Loss:0.699 AVG Test Loss:0.693 AVG Training Acc 38.10 % AVG Test Acc 36.36 %\n",
            "Epoch:36/50 AVG Training Loss:0.699 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:37/50 AVG Training Loss:0.697 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:38/50 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 42.86 % AVG Test Acc 36.36 %\n",
            "Epoch:39/50 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 47.62 % AVG Test Acc 36.36 %\n",
            "Epoch:40/50 AVG Training Loss:0.695 AVG Test Loss:0.694 AVG Training Acc 47.62 % AVG Test Acc 36.36 %\n",
            "Epoch:41/50 AVG Training Loss:0.695 AVG Test Loss:0.694 AVG Training Acc 52.38 % AVG Test Acc 36.36 %\n",
            "Epoch:42/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:43/50 AVG Training Loss:0.693 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:44/50 AVG Training Loss:0.692 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:45/50 AVG Training Loss:0.692 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:46/50 AVG Training Loss:0.691 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:48/50 AVG Training Loss:0.689 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:49/50 AVG Training Loss:0.689 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:50/50 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 57.14 % AVG Test Acc 36.36 %\n",
            "Epoch:1/50 AVG Training Loss:6.349 AVG Test Loss:0.823 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.124 AVG Test Loss:1.356 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.769 AVG Test Loss:0.839 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:2.035 AVG Test Loss:0.866 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:1.086 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.561 AVG Test Loss:0.884 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.261 AVG Test Loss:0.748 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.988 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.792 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.634 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.700 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.810 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.787 AVG Test Loss:0.694 AVG Training Acc 9.52 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.733 AVG Test Loss:0.688 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.717 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.734 AVG Test Loss:0.704 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.728 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:20/50 AVG Training Loss:0.712 AVG Test Loss:0.694 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.701 AVG Test Loss:0.696 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.703 AVG Test Loss:0.699 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.711 AVG Test Loss:0.699 AVG Training Acc 23.81 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.711 AVG Test Loss:0.694 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.706 AVG Test Loss:0.693 AVG Training Acc 19.05 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.704 AVG Test Loss:0.696 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.706 AVG Test Loss:0.695 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.704 AVG Test Loss:0.694 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.702 AVG Test Loss:0.694 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.701 AVG Test Loss:0.694 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.701 AVG Test Loss:0.694 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.701 AVG Test Loss:0.694 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.700 AVG Test Loss:0.693 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.699 AVG Test Loss:0.693 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.698 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.697 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.697 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.696 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.696 AVG Test Loss:0.692 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.695 AVG Test Loss:0.692 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.694 AVG Test Loss:0.692 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.693 AVG Test Loss:0.692 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.693 AVG Test Loss:0.692 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.692 AVG Test Loss:0.692 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.691 AVG Test Loss:0.692 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.691 AVG Test Loss:0.692 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.690 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:6.571 AVG Test Loss:0.756 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.120 AVG Test Loss:1.485 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:3.604 AVG Test Loss:0.888 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:2.093 AVG Test Loss:0.789 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:5/50 AVG Training Loss:1.130 AVG Test Loss:0.680 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.543 AVG Test Loss:0.940 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:1.216 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.992 AVG Test Loss:0.676 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.817 AVG Test Loss:0.676 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.644 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.689 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/50 AVG Training Loss:0.796 AVG Test Loss:0.729 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/50 AVG Training Loss:0.786 AVG Test Loss:0.694 AVG Training Acc 13.64 % AVG Test Acc 50.00 %\n",
            "Epoch:14/50 AVG Training Loss:0.742 AVG Test Loss:0.682 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:15/50 AVG Training Loss:0.701 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:16/50 AVG Training Loss:0.690 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:17/50 AVG Training Loss:0.713 AVG Test Loss:0.712 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/50 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/50 AVG Training Loss:0.730 AVG Test Loss:0.691 AVG Training Acc 4.55 % AVG Test Acc 50.00 %\n",
            "Epoch:20/50 AVG Training Loss:0.717 AVG Test Loss:0.687 AVG Training Acc 40.91 % AVG Test Acc 70.00 %\n",
            "Epoch:21/50 AVG Training Loss:0.706 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:22/50 AVG Training Loss:0.704 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:23/50 AVG Training Loss:0.710 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:24/50 AVG Training Loss:0.715 AVG Test Loss:0.699 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:25/50 AVG Training Loss:0.714 AVG Test Loss:0.695 AVG Training Acc 4.55 % AVG Test Acc 50.00 %\n",
            "Epoch:26/50 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 22.73 % AVG Test Acc 60.00 %\n",
            "Epoch:27/50 AVG Training Loss:0.706 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:28/50 AVG Training Loss:0.706 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:29/50 AVG Training Loss:0.707 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:30/50 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:31/50 AVG Training Loss:0.707 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:32/50 AVG Training Loss:0.705 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:33/50 AVG Training Loss:0.704 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:34/50 AVG Training Loss:0.703 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:35/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:36/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:37/50 AVG Training Loss:0.702 AVG Test Loss:0.694 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:38/50 AVG Training Loss:0.701 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:39/50 AVG Training Loss:0.700 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:40/50 AVG Training Loss:0.700 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:41/50 AVG Training Loss:0.700 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:42/50 AVG Training Loss:0.699 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:43/50 AVG Training Loss:0.698 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:44/50 AVG Training Loss:0.698 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:45/50 AVG Training Loss:0.697 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:46/50 AVG Training Loss:0.697 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:47/50 AVG Training Loss:0.696 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:48/50 AVG Training Loss:0.696 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:49/50 AVG Training Loss:0.695 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:50/50 AVG Training Loss:0.694 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 42.30769230769231 %\n",
            "Fold 2 acc: 40.909090909090914 %\n",
            " Average acc: 39.86013986013986 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:4.156 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.402 AVG Test Loss:1.084 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.236 AVG Test Loss:0.853 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:1.586 AVG Test Loss:0.701 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.922 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.600 AVG Test Loss:0.920 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.284 AVG Test Loss:0.862 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1.101 AVG Test Loss:0.706 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:4.135 AVG Test Loss:0.688 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.422 AVG Test Loss:1.101 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.239 AVG Test Loss:0.858 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:1.564 AVG Test Loss:0.702 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.900 AVG Test Loss:0.710 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.609 AVG Test Loss:0.944 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.292 AVG Test Loss:0.879 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1.084 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:4.290 AVG Test Loss:0.683 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.406 AVG Test Loss:1.178 AVG Training Acc 90.91 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:3.072 AVG Test Loss:0.895 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:1.585 AVG Test Loss:0.677 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.943 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.597 AVG Test Loss:0.947 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:1.243 AVG Test Loss:0.878 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:1.084 AVG Test Loss:0.704 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:4.156 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.402 AVG Test Loss:1.084 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.236 AVG Test Loss:0.853 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.586 AVG Test Loss:0.701 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.922 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.600 AVG Test Loss:0.920 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.284 AVG Test Loss:0.862 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.101 AVG Test Loss:0.706 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.786 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.651 AVG Test Loss:0.742 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.713 AVG Test Loss:0.827 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.897 AVG Test Loss:0.802 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.854 AVG Test Loss:0.736 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.719 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.679 AVG Test Loss:0.744 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.787 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.767 AVG Test Loss:0.784 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.777 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.724 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.733 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:4.135 AVG Test Loss:0.688 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.422 AVG Test Loss:1.101 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.239 AVG Test Loss:0.858 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.564 AVG Test Loss:0.702 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.900 AVG Test Loss:0.710 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.609 AVG Test Loss:0.944 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.292 AVG Test Loss:0.879 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.084 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.772 AVG Test Loss:0.697 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.639 AVG Test Loss:0.762 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.717 AVG Test Loss:0.853 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.897 AVG Test Loss:0.823 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.841 AVG Test Loss:0.750 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.726 AVG Test Loss:0.728 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.668 AVG Test Loss:0.759 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.692 AVG Test Loss:0.807 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.764 AVG Test Loss:0.807 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.768 AVG Test Loss:0.760 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.719 AVG Test Loss:0.731 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.683 AVG Test Loss:0.738 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:4.290 AVG Test Loss:0.683 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.406 AVG Test Loss:1.178 AVG Training Acc 90.91 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:3.072 AVG Test Loss:0.895 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.585 AVG Test Loss:0.677 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.943 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.597 AVG Test Loss:0.947 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.243 AVG Test Loss:0.878 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.084 AVG Test Loss:0.704 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.803 AVG Test Loss:0.684 AVG Training Acc 9.09 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.660 AVG Test Loss:0.745 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.708 AVG Test Loss:0.832 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.883 AVG Test Loss:0.807 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.853 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.714 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.689 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.697 AVG Test Loss:0.788 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.762 AVG Test Loss:0.801 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.781 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.745 AVG Test Loss:0.745 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.708 AVG Test Loss:0.750 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:4.156 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.402 AVG Test Loss:1.084 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.236 AVG Test Loss:0.853 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:1.586 AVG Test Loss:0.701 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.922 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.600 AVG Test Loss:0.920 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.284 AVG Test Loss:0.862 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1.101 AVG Test Loss:0.706 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.786 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 90.91 %\n",
            "Epoch:10/50 AVG Training Loss:0.651 AVG Test Loss:0.742 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.713 AVG Test Loss:0.827 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.897 AVG Test Loss:0.802 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.854 AVG Test Loss:0.736 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.739 AVG Test Loss:0.719 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.679 AVG Test Loss:0.744 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.695 AVG Test Loss:0.787 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.767 AVG Test Loss:0.784 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.777 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.731 AVG Test Loss:0.724 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.694 AVG Test Loss:0.733 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.693 AVG Test Loss:0.759 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.723 AVG Test Loss:0.764 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.733 AVG Test Loss:0.744 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.713 AVG Test Loss:0.728 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.691 AVG Test Loss:0.732 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.691 AVG Test Loss:0.742 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.704 AVG Test Loss:0.740 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.705 AVG Test Loss:0.728 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.691 AVG Test Loss:0.723 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.681 AVG Test Loss:0.729 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.683 AVG Test Loss:0.732 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.687 AVG Test Loss:0.726 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.680 AVG Test Loss:0.720 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.671 AVG Test Loss:0.722 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.669 AVG Test Loss:0.725 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.670 AVG Test Loss:0.721 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.665 AVG Test Loss:0.718 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.658 AVG Test Loss:0.719 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.655 AVG Test Loss:0.720 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.654 AVG Test Loss:0.718 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.649 AVG Test Loss:0.716 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.643 AVG Test Loss:0.716 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.640 AVG Test Loss:0.716 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.637 AVG Test Loss:0.714 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.631 AVG Test Loss:0.713 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.626 AVG Test Loss:0.713 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.623 AVG Test Loss:0.711 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.618 AVG Test Loss:0.710 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.613 AVG Test Loss:0.710 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.608 AVG Test Loss:0.709 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:4.135 AVG Test Loss:0.688 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.422 AVG Test Loss:1.101 AVG Training Acc 90.48 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.239 AVG Test Loss:0.858 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:1.564 AVG Test Loss:0.702 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.900 AVG Test Loss:0.710 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.609 AVG Test Loss:0.944 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.292 AVG Test Loss:0.879 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1.084 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.772 AVG Test Loss:0.697 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.639 AVG Test Loss:0.762 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.717 AVG Test Loss:0.853 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.897 AVG Test Loss:0.823 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.841 AVG Test Loss:0.750 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.726 AVG Test Loss:0.728 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.668 AVG Test Loss:0.759 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.692 AVG Test Loss:0.807 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.764 AVG Test Loss:0.807 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.768 AVG Test Loss:0.760 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.719 AVG Test Loss:0.731 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.683 AVG Test Loss:0.738 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.687 AVG Test Loss:0.756 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.717 AVG Test Loss:0.750 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.724 AVG Test Loss:0.723 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.701 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.681 AVG Test Loss:0.707 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.683 AVG Test Loss:0.711 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.696 AVG Test Loss:0.702 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.695 AVG Test Loss:0.686 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.680 AVG Test Loss:0.679 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.671 AVG Test Loss:0.681 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.675 AVG Test Loss:0.680 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.678 AVG Test Loss:0.673 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.670 AVG Test Loss:0.667 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.661 AVG Test Loss:0.667 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.660 AVG Test Loss:0.667 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.661 AVG Test Loss:0.663 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.656 AVG Test Loss:0.659 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.648 AVG Test Loss:0.658 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.646 AVG Test Loss:0.657 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.644 AVG Test Loss:0.654 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.639 AVG Test Loss:0.651 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.633 AVG Test Loss:0.650 AVG Training Acc 52.38 % AVG Test Acc 63.64 %\n",
            "Epoch:43/50 AVG Training Loss:0.630 AVG Test Loss:0.649 AVG Training Acc 61.90 % AVG Test Acc 63.64 %\n",
            "Epoch:44/50 AVG Training Loss:0.627 AVG Test Loss:0.646 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:45/50 AVG Training Loss:0.622 AVG Test Loss:0.645 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:46/50 AVG Training Loss:0.617 AVG Test Loss:0.643 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:47/50 AVG Training Loss:0.614 AVG Test Loss:0.641 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:48/50 AVG Training Loss:0.609 AVG Test Loss:0.640 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:49/50 AVG Training Loss:0.604 AVG Test Loss:0.639 AVG Training Acc 61.90 % AVG Test Acc 63.64 %\n",
            "Epoch:50/50 AVG Training Loss:0.599 AVG Test Loss:0.637 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:1/50 AVG Training Loss:4.290 AVG Test Loss:0.683 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.406 AVG Test Loss:1.178 AVG Training Acc 90.91 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:3.072 AVG Test Loss:0.895 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:1.585 AVG Test Loss:0.677 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.943 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.597 AVG Test Loss:0.947 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:1.243 AVG Test Loss:0.878 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:1.084 AVG Test Loss:0.704 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.803 AVG Test Loss:0.684 AVG Training Acc 9.09 % AVG Test Acc 60.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.660 AVG Test Loss:0.745 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.708 AVG Test Loss:0.832 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/50 AVG Training Loss:0.883 AVG Test Loss:0.807 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/50 AVG Training Loss:0.853 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/50 AVG Training Loss:0.751 AVG Test Loss:0.714 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:15/50 AVG Training Loss:0.689 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/50 AVG Training Loss:0.697 AVG Test Loss:0.788 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:17/50 AVG Training Loss:0.762 AVG Test Loss:0.801 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/50 AVG Training Loss:0.781 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/50 AVG Training Loss:0.745 AVG Test Loss:0.745 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/50 AVG Training Loss:0.708 AVG Test Loss:0.750 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:21/50 AVG Training Loss:0.700 AVG Test Loss:0.773 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:22/50 AVG Training Loss:0.723 AVG Test Loss:0.787 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:23/50 AVG Training Loss:0.740 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:24/50 AVG Training Loss:0.730 AVG Test Loss:0.757 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:25/50 AVG Training Loss:0.710 AVG Test Loss:0.760 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:26/50 AVG Training Loss:0.701 AVG Test Loss:0.775 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:27/50 AVG Training Loss:0.709 AVG Test Loss:0.787 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:28/50 AVG Training Loss:0.718 AVG Test Loss:0.782 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:29/50 AVG Training Loss:0.714 AVG Test Loss:0.772 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:30/50 AVG Training Loss:0.703 AVG Test Loss:0.772 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:31/50 AVG Training Loss:0.697 AVG Test Loss:0.781 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:32/50 AVG Training Loss:0.701 AVG Test Loss:0.786 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:33/50 AVG Training Loss:0.703 AVG Test Loss:0.781 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:34/50 AVG Training Loss:0.699 AVG Test Loss:0.777 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:35/50 AVG Training Loss:0.692 AVG Test Loss:0.779 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:36/50 AVG Training Loss:0.690 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:37/50 AVG Training Loss:0.691 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:38/50 AVG Training Loss:0.690 AVG Test Loss:0.781 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:39/50 AVG Training Loss:0.685 AVG Test Loss:0.781 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:40/50 AVG Training Loss:0.681 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:41/50 AVG Training Loss:0.680 AVG Test Loss:0.785 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:42/50 AVG Training Loss:0.679 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:43/50 AVG Training Loss:0.675 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:44/50 AVG Training Loss:0.672 AVG Test Loss:0.786 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:45/50 AVG Training Loss:0.670 AVG Test Loss:0.787 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:46/50 AVG Training Loss:0.668 AVG Test Loss:0.787 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:47/50 AVG Training Loss:0.664 AVG Test Loss:0.788 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:48/50 AVG Training Loss:0.661 AVG Test Loss:0.789 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:49/50 AVG Training Loss:0.658 AVG Test Loss:0.790 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:50/50 AVG Training Loss:0.656 AVG Test Loss:0.791 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 50.0 %\n",
            " Average acc: 52.16450216450216 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:1.356 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.556 AVG Test Loss:0.724 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.805 AVG Test Loss:0.773 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.935 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.812 AVG Test Loss:0.687 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:6/8 AVG Training Loss:0.723 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:7/8 AVG Training Loss:0.684 AVG Test Loss:0.707 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.723 AVG Test Loss:0.727 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.367 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.556 AVG Test Loss:0.725 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.811 AVG Test Loss:0.778 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.943 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.817 AVG Test Loss:0.693 AVG Training Acc 4.76 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.726 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.399 AVG Test Loss:0.673 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.557 AVG Test Loss:0.747 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.784 AVG Test Loss:0.813 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.918 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.815 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 60.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.729 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.684 AVG Test Loss:0.713 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.718 AVG Test Loss:0.727 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 37.5 %\n",
            " Average acc: 39.166666666666664 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:1.356 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.556 AVG Test Loss:0.724 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.805 AVG Test Loss:0.773 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.935 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.812 AVG Test Loss:0.687 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.723 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.684 AVG Test Loss:0.707 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.723 AVG Test Loss:0.727 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.757 AVG Test Loss:0.712 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.748 AVG Test Loss:0.692 AVG Training Acc 4.76 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.692 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.718 AVG Test Loss:0.694 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.723 AVG Test Loss:0.694 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.730 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.730 AVG Test Loss:0.689 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.725 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:0.722 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:1/20 AVG Training Loss:1.367 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.556 AVG Test Loss:0.725 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.811 AVG Test Loss:0.778 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.943 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.817 AVG Test Loss:0.693 AVG Training Acc 4.76 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.726 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.761 AVG Test Loss:0.706 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.752 AVG Test Loss:0.690 AVG Training Acc 4.76 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.691 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.721 AVG Test Loss:0.700 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.727 AVG Test Loss:0.701 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 19.05 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.734 AVG Test Loss:0.693 AVG Training Acc 4.76 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.729 AVG Test Loss:0.692 AVG Training Acc 9.52 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.727 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:1/20 AVG Training Loss:1.399 AVG Test Loss:0.673 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.557 AVG Test Loss:0.747 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.784 AVG Test Loss:0.813 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.918 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.815 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.729 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.684 AVG Test Loss:0.713 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.718 AVG Test Loss:0.727 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.752 AVG Test Loss:0.720 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.691 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.717 AVG Test Loss:0.694 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.722 AVG Test Loss:0.700 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.729 AVG Test Loss:0.699 AVG Training Acc 13.64 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.729 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.725 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.722 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.722 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.723 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.722 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 50.0 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 43.75 %\n",
            " Average acc: 52.462121212121204 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:1.356 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.556 AVG Test Loss:0.724 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.805 AVG Test Loss:0.773 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.935 AVG Test Loss:0.714 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.812 AVG Test Loss:0.687 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:6/50 AVG Training Loss:0.723 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:7/50 AVG Training Loss:0.684 AVG Test Loss:0.707 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.723 AVG Test Loss:0.727 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.757 AVG Test Loss:0.712 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.748 AVG Test Loss:0.692 AVG Training Acc 4.76 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.727 AVG Test Loss:0.692 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.718 AVG Test Loss:0.694 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.723 AVG Test Loss:0.694 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.730 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.730 AVG Test Loss:0.689 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.725 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:18/50 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:0.722 AVG Test Loss:0.688 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:20/50 AVG Training Loss:0.722 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:21/50 AVG Training Loss:0.720 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:22/50 AVG Training Loss:0.718 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:23/50 AVG Training Loss:0.718 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:24/50 AVG Training Loss:0.717 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:25/50 AVG Training Loss:0.716 AVG Test Loss:0.687 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:26/50 AVG Training Loss:0.715 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:27/50 AVG Training Loss:0.714 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.713 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:29/50 AVG Training Loss:0.712 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:30/50 AVG Training Loss:0.711 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:31/50 AVG Training Loss:0.710 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:32/50 AVG Training Loss:0.709 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:33/50 AVG Training Loss:0.708 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:34/50 AVG Training Loss:0.707 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 63.64 %\n",
            "Epoch:35/50 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.705 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.704 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.703 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.702 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.701 AVG Test Loss:0.687 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.700 AVG Test Loss:0.687 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.699 AVG Test Loss:0.687 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.698 AVG Test Loss:0.687 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.697 AVG Test Loss:0.687 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.696 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.695 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.694 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.693 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.692 AVG Test Loss:0.687 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.691 AVG Test Loss:0.687 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:1.367 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.556 AVG Test Loss:0.725 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.811 AVG Test Loss:0.778 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.943 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.817 AVG Test Loss:0.693 AVG Training Acc 4.76 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.726 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.761 AVG Test Loss:0.706 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.752 AVG Test Loss:0.690 AVG Training Acc 4.76 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.731 AVG Test Loss:0.691 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.721 AVG Test Loss:0.700 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.727 AVG Test Loss:0.701 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 19.05 % AVG Test Acc 36.36 %\n",
            "Epoch:15/50 AVG Training Loss:0.734 AVG Test Loss:0.693 AVG Training Acc 4.76 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.729 AVG Test Loss:0.692 AVG Training Acc 9.52 % AVG Test Acc 63.64 %\n",
            "Epoch:17/50 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.727 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 54.55 %\n",
            "Epoch:20/50 AVG Training Loss:0.727 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:21/50 AVG Training Loss:0.725 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:22/50 AVG Training Loss:0.724 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:23/50 AVG Training Loss:0.723 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:24/50 AVG Training Loss:0.722 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:25/50 AVG Training Loss:0.722 AVG Test Loss:0.691 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:26/50 AVG Training Loss:0.721 AVG Test Loss:0.690 AVG Training Acc 14.29 % AVG Test Acc 63.64 %\n",
            "Epoch:27/50 AVG Training Loss:0.720 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.719 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:29/50 AVG Training Loss:0.718 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:30/50 AVG Training Loss:0.717 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:31/50 AVG Training Loss:0.716 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:32/50 AVG Training Loss:0.715 AVG Test Loss:0.690 AVG Training Acc 19.05 % AVG Test Acc 63.64 %\n",
            "Epoch:33/50 AVG Training Loss:0.714 AVG Test Loss:0.690 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:34/50 AVG Training Loss:0.714 AVG Test Loss:0.690 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:35/50 AVG Training Loss:0.713 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:36/50 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:37/50 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.710 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.709 AVG Test Loss:0.689 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.708 AVG Test Loss:0.689 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.708 AVG Test Loss:0.689 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.707 AVG Test Loss:0.689 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.706 AVG Test Loss:0.688 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.705 AVG Test Loss:0.688 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.704 AVG Test Loss:0.688 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.703 AVG Test Loss:0.688 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.703 AVG Test Loss:0.688 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.702 AVG Test Loss:0.688 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.701 AVG Test Loss:0.688 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.700 AVG Test Loss:0.688 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:1.399 AVG Test Loss:0.673 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.557 AVG Test Loss:0.747 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.784 AVG Test Loss:0.813 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.918 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.815 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 60.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.729 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.684 AVG Test Loss:0.713 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.718 AVG Test Loss:0.727 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.752 AVG Test Loss:0.720 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.728 AVG Test Loss:0.691 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:12/50 AVG Training Loss:0.717 AVG Test Loss:0.694 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/50 AVG Training Loss:0.722 AVG Test Loss:0.700 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:14/50 AVG Training Loss:0.729 AVG Test Loss:0.699 AVG Training Acc 13.64 % AVG Test Acc 50.00 %\n",
            "Epoch:15/50 AVG Training Loss:0.729 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:16/50 AVG Training Loss:0.725 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 50.00 %\n",
            "Epoch:17/50 AVG Training Loss:0.722 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:18/50 AVG Training Loss:0.722 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:19/50 AVG Training Loss:0.723 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:20/50 AVG Training Loss:0.722 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:21/50 AVG Training Loss:0.721 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 50.00 %\n",
            "Epoch:22/50 AVG Training Loss:0.720 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:23/50 AVG Training Loss:0.719 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:24/50 AVG Training Loss:0.718 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:25/50 AVG Training Loss:0.718 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:26/50 AVG Training Loss:0.717 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:27/50 AVG Training Loss:0.716 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:28/50 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:29/50 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:30/50 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:31/50 AVG Training Loss:0.713 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:32/50 AVG Training Loss:0.712 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:33/50 AVG Training Loss:0.711 AVG Test Loss:0.696 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:34/50 AVG Training Loss:0.711 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:35/50 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:36/50 AVG Training Loss:0.709 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:37/50 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:38/50 AVG Training Loss:0.707 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:39/50 AVG Training Loss:0.707 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:40/50 AVG Training Loss:0.706 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:41/50 AVG Training Loss:0.705 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:42/50 AVG Training Loss:0.704 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:43/50 AVG Training Loss:0.704 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:44/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:45/50 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:46/50 AVG Training Loss:0.701 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:47/50 AVG Training Loss:0.701 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:48/50 AVG Training Loss:0.700 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:49/50 AVG Training Loss:0.699 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "Epoch:50/50 AVG Training Loss:0.698 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 43.75 %\n",
            " Average acc: 50.94696969696969 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:1.137 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.655 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.641 AVG Test Loss:0.729 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.809 AVG Test Loss:0.740 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.839 AVG Test Loss:0.718 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.784 AVG Test Loss:0.695 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.736 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 81.82 %\n",
            "Epoch:8/8 AVG Training Loss:0.704 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.140 AVG Test Loss:0.687 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.652 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.641 AVG Test Loss:0.731 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.813 AVG Test Loss:0.743 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.841 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.783 AVG Test Loss:0.700 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.735 AVG Test Loss:0.693 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.171 AVG Test Loss:0.677 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.667 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.633 AVG Test Loss:0.755 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.792 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.824 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.778 AVG Test Loss:0.709 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.739 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.708 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 50.0 %\n",
            " Average acc: 46.96969696969697 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:1.137 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.655 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.641 AVG Test Loss:0.729 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.809 AVG Test Loss:0.740 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.839 AVG Test Loss:0.718 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.784 AVG Test Loss:0.695 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.736 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:0.704 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.692 AVG Test Loss:0.703 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.713 AVG Test Loss:0.711 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.727 AVG Test Loss:0.717 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.728 AVG Test Loss:0.710 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.719 AVG Test Loss:0.699 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.689 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.704 AVG Test Loss:0.690 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.703 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.691 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:1.140 AVG Test Loss:0.687 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.652 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.641 AVG Test Loss:0.731 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.813 AVG Test Loss:0.743 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.841 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.783 AVG Test Loss:0.700 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.735 AVG Test Loss:0.693 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.685 AVG Test Loss:0.701 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.692 AVG Test Loss:0.706 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.713 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.728 AVG Test Loss:0.704 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.728 AVG Test Loss:0.702 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.719 AVG Test Loss:0.693 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.687 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.704 AVG Test Loss:0.690 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 28.57 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.706 AVG Test Loss:0.700 AVG Training Acc 23.81 % AVG Test Acc 27.27 %\n",
            "Epoch:19/20 AVG Training Loss:0.710 AVG Test Loss:0.700 AVG Training Acc 23.81 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.711 AVG Test Loss:0.697 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:1.171 AVG Test Loss:0.677 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.667 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.633 AVG Test Loss:0.755 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.792 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.824 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.778 AVG Test Loss:0.709 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.739 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.708 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.688 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.690 AVG Test Loss:0.715 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.708 AVG Test Loss:0.717 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.723 AVG Test Loss:0.715 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.724 AVG Test Loss:0.712 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.718 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.698 AVG Training Acc 36.36 % AVG Test Acc 30.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.692 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.705 AVG Test Loss:0.692 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.708 AVG Test Loss:0.694 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.692 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.30769230769231 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 40.909090909090914 %\n",
            " Average acc: 45.92074592074592 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:1.137 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.655 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.641 AVG Test Loss:0.729 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.809 AVG Test Loss:0.740 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.839 AVG Test Loss:0.718 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.784 AVG Test Loss:0.695 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.736 AVG Test Loss:0.687 AVG Training Acc 47.62 % AVG Test Acc 81.82 %\n",
            "Epoch:8/50 AVG Training Loss:0.704 AVG Test Loss:0.689 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.692 AVG Test Loss:0.703 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.713 AVG Test Loss:0.711 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.727 AVG Test Loss:0.717 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.728 AVG Test Loss:0.710 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.719 AVG Test Loss:0.699 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.710 AVG Test Loss:0.689 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.704 AVG Test Loss:0.690 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.703 AVG Test Loss:0.693 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.709 AVG Test Loss:0.691 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:20/50 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 28.57 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.709 AVG Test Loss:0.687 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.707 AVG Test Loss:0.686 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.705 AVG Test Loss:0.685 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.704 AVG Test Loss:0.685 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.703 AVG Test Loss:0.685 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.703 AVG Test Loss:0.685 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.703 AVG Test Loss:0.685 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.703 AVG Test Loss:0.685 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.702 AVG Test Loss:0.685 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.701 AVG Test Loss:0.685 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.700 AVG Test Loss:0.685 AVG Training Acc 38.10 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.700 AVG Test Loss:0.685 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.699 AVG Test Loss:0.685 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.699 AVG Test Loss:0.685 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.698 AVG Test Loss:0.685 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.697 AVG Test Loss:0.685 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.697 AVG Test Loss:0.685 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.696 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.695 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.695 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.694 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.693 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.693 AVG Test Loss:0.686 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.692 AVG Test Loss:0.686 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.691 AVG Test Loss:0.686 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.691 AVG Test Loss:0.686 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.690 AVG Test Loss:0.686 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.689 AVG Test Loss:0.686 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.689 AVG Test Loss:0.686 AVG Training Acc 66.67 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.688 AVG Test Loss:0.686 AVG Training Acc 71.43 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:1.140 AVG Test Loss:0.687 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.652 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.641 AVG Test Loss:0.731 AVG Training Acc 76.19 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.813 AVG Test Loss:0.743 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.841 AVG Test Loss:0.721 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.783 AVG Test Loss:0.700 AVG Training Acc 19.05 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.735 AVG Test Loss:0.693 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.685 AVG Test Loss:0.701 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.692 AVG Test Loss:0.706 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.713 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.728 AVG Test Loss:0.704 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.728 AVG Test Loss:0.702 AVG Training Acc 28.57 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.719 AVG Test Loss:0.693 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.710 AVG Test Loss:0.687 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.704 AVG Test Loss:0.690 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 28.57 % AVG Test Acc 36.36 %\n",
            "Epoch:18/50 AVG Training Loss:0.706 AVG Test Loss:0.700 AVG Training Acc 23.81 % AVG Test Acc 27.27 %\n",
            "Epoch:19/50 AVG Training Loss:0.710 AVG Test Loss:0.700 AVG Training Acc 23.81 % AVG Test Acc 36.36 %\n",
            "Epoch:20/50 AVG Training Loss:0.711 AVG Test Loss:0.697 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:22/50 AVG Training Loss:0.707 AVG Test Loss:0.692 AVG Training Acc 19.05 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:0.705 AVG Test Loss:0.692 AVG Training Acc 14.29 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 19.05 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:26/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:27/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 23.81 % AVG Test Acc 63.64 %\n",
            "Epoch:29/50 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.702 AVG Test Loss:0.691 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.701 AVG Test Loss:0.691 AVG Training Acc 23.81 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.700 AVG Test Loss:0.691 AVG Training Acc 33.33 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.700 AVG Test Loss:0.691 AVG Training Acc 38.10 % AVG Test Acc 63.64 %\n",
            "Epoch:34/50 AVG Training Loss:0.699 AVG Test Loss:0.691 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.699 AVG Test Loss:0.691 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.698 AVG Test Loss:0.691 AVG Training Acc 38.10 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.698 AVG Test Loss:0.691 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.697 AVG Test Loss:0.691 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.696 AVG Test Loss:0.691 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.696 AVG Test Loss:0.691 AVG Training Acc 42.86 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.695 AVG Test Loss:0.691 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.695 AVG Test Loss:0.691 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.694 AVG Test Loss:0.691 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.693 AVG Test Loss:0.691 AVG Training Acc 47.62 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.693 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.692 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.692 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.691 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.690 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.690 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:1.171 AVG Test Loss:0.677 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.667 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.633 AVG Test Loss:0.755 AVG Training Acc 72.73 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.792 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.824 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.778 AVG Test Loss:0.709 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.739 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.708 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.688 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.690 AVG Test Loss:0.715 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.708 AVG Test Loss:0.717 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:12/50 AVG Training Loss:0.723 AVG Test Loss:0.715 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:13/50 AVG Training Loss:0.724 AVG Test Loss:0.712 AVG Training Acc 36.36 % AVG Test Acc 40.00 %\n",
            "Epoch:14/50 AVG Training Loss:0.718 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 40.00 %\n",
            "Epoch:15/50 AVG Training Loss:0.710 AVG Test Loss:0.698 AVG Training Acc 36.36 % AVG Test Acc 30.00 %\n",
            "Epoch:16/50 AVG Training Loss:0.704 AVG Test Loss:0.692 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:17/50 AVG Training Loss:0.702 AVG Test Loss:0.692 AVG Training Acc 40.91 % AVG Test Acc 40.00 %\n",
            "Epoch:18/50 AVG Training Loss:0.705 AVG Test Loss:0.692 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:19/50 AVG Training Loss:0.708 AVG Test Loss:0.694 AVG Training Acc 31.82 % AVG Test Acc 40.00 %\n",
            "Epoch:20/50 AVG Training Loss:0.709 AVG Test Loss:0.692 AVG Training Acc 27.27 % AVG Test Acc 50.00 %\n",
            "Epoch:21/50 AVG Training Loss:0.709 AVG Test Loss:0.690 AVG Training Acc 18.18 % AVG Test Acc 50.00 %\n",
            "Epoch:22/50 AVG Training Loss:0.707 AVG Test Loss:0.689 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:23/50 AVG Training Loss:0.705 AVG Test Loss:0.689 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:24/50 AVG Training Loss:0.703 AVG Test Loss:0.690 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:25/50 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:26/50 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:27/50 AVG Training Loss:0.704 AVG Test Loss:0.691 AVG Training Acc 27.27 % AVG Test Acc 60.00 %\n",
            "Epoch:28/50 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 31.82 % AVG Test Acc 60.00 %\n",
            "Epoch:29/50 AVG Training Loss:0.703 AVG Test Loss:0.690 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:30/50 AVG Training Loss:0.702 AVG Test Loss:0.690 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:31/50 AVG Training Loss:0.701 AVG Test Loss:0.690 AVG Training Acc 40.91 % AVG Test Acc 60.00 %\n",
            "Epoch:32/50 AVG Training Loss:0.700 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:33/50 AVG Training Loss:0.700 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:34/50 AVG Training Loss:0.700 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:35/50 AVG Training Loss:0.699 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:36/50 AVG Training Loss:0.699 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:37/50 AVG Training Loss:0.698 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:38/50 AVG Training Loss:0.698 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:39/50 AVG Training Loss:0.697 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:40/50 AVG Training Loss:0.697 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:41/50 AVG Training Loss:0.696 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:42/50 AVG Training Loss:0.696 AVG Test Loss:0.690 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:43/50 AVG Training Loss:0.695 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:44/50 AVG Training Loss:0.695 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:46/50 AVG Training Loss:0.694 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:47/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:48/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:49/50 AVG Training Loss:0.692 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:50/50 AVG Training Loss:0.692 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            " Average acc: 48.484848484848484 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.901 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.636 AVG Test Loss:0.706 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.730 AVG Test Loss:0.738 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.877 AVG Test Loss:0.758 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.907 AVG Test Loss:0.753 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.850 AVG Test Loss:0.733 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.779 AVG Test Loss:0.716 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.898 AVG Test Loss:0.690 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.633 AVG Test Loss:0.707 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.734 AVG Test Loss:0.744 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.886 AVG Test Loss:0.765 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.914 AVG Test Loss:0.759 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.853 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.778 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.728 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.925 AVG Test Loss:0.690 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.641 AVG Test Loss:0.721 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.722 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.863 AVG Test Loss:0.795 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.894 AVG Test Loss:0.785 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.842 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.776 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.733 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.901 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.636 AVG Test Loss:0.706 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.730 AVG Test Loss:0.738 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.877 AVG Test Loss:0.758 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.907 AVG Test Loss:0.753 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.850 AVG Test Loss:0.733 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.779 AVG Test Loss:0.716 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.706 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.701 AVG Test Loss:0.719 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.714 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.736 AVG Test Loss:0.743 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.756 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.763 AVG Test Loss:0.749 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.757 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.749 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.732 AVG Test Loss:0.742 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.723 AVG Test Loss:0.735 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.720 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.721 AVG Test Loss:0.731 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:0.898 AVG Test Loss:0.690 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.633 AVG Test Loss:0.707 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.734 AVG Test Loss:0.744 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.886 AVG Test Loss:0.765 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.914 AVG Test Loss:0.759 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.853 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.778 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.728 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.704 AVG Test Loss:0.721 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.700 AVG Test Loss:0.732 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.714 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.737 AVG Test Loss:0.759 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.757 AVG Test Loss:0.762 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.764 AVG Test Loss:0.756 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.757 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.730 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.721 AVG Test Loss:0.734 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.718 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.719 AVG Test Loss:0.730 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:0.925 AVG Test Loss:0.690 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.641 AVG Test Loss:0.721 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.722 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.863 AVG Test Loss:0.795 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.894 AVG Test Loss:0.785 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.842 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.776 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.733 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.710 AVG Test Loss:0.728 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.713 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.733 AVG Test Loss:0.766 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.752 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.760 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.755 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.733 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.725 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.721 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.722 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.901 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.636 AVG Test Loss:0.706 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.730 AVG Test Loss:0.738 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.877 AVG Test Loss:0.758 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.907 AVG Test Loss:0.753 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.850 AVG Test Loss:0.733 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.779 AVG Test Loss:0.716 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.706 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.701 AVG Test Loss:0.719 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.714 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.736 AVG Test Loss:0.743 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.756 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.763 AVG Test Loss:0.749 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.757 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.745 AVG Test Loss:0.749 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.732 AVG Test Loss:0.742 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.723 AVG Test Loss:0.735 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.720 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.721 AVG Test Loss:0.731 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.725 AVG Test Loss:0.735 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.729 AVG Test Loss:0.738 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.730 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.729 AVG Test Loss:0.733 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.726 AVG Test Loss:0.728 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.722 AVG Test Loss:0.725 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.719 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.717 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.716 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.715 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.715 AVG Test Loss:0.723 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.715 AVG Test Loss:0.722 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.714 AVG Test Loss:0.721 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.712 AVG Test Loss:0.720 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.711 AVG Test Loss:0.719 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.709 AVG Test Loss:0.719 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.707 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.706 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.705 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.704 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.703 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.702 AVG Test Loss:0.717 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.701 AVG Test Loss:0.717 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.699 AVG Test Loss:0.717 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.698 AVG Test Loss:0.716 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.696 AVG Test Loss:0.716 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.695 AVG Test Loss:0.716 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.694 AVG Test Loss:0.716 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.693 AVG Test Loss:0.715 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.692 AVG Test Loss:0.715 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:0.898 AVG Test Loss:0.690 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.633 AVG Test Loss:0.707 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.734 AVG Test Loss:0.744 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.886 AVG Test Loss:0.765 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.914 AVG Test Loss:0.759 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.853 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.778 AVG Test Loss:0.723 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.728 AVG Test Loss:0.718 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.704 AVG Test Loss:0.721 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.700 AVG Test Loss:0.732 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.714 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.737 AVG Test Loss:0.759 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.757 AVG Test Loss:0.762 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.764 AVG Test Loss:0.756 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.757 AVG Test Loss:0.747 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.743 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.730 AVG Test Loss:0.739 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.721 AVG Test Loss:0.734 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.718 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.719 AVG Test Loss:0.730 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.723 AVG Test Loss:0.730 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.727 AVG Test Loss:0.731 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.729 AVG Test Loss:0.732 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.727 AVG Test Loss:0.731 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.724 AVG Test Loss:0.725 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.720 AVG Test Loss:0.720 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.716 AVG Test Loss:0.716 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.714 AVG Test Loss:0.713 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.713 AVG Test Loss:0.712 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.713 AVG Test Loss:0.711 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.713 AVG Test Loss:0.710 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.712 AVG Test Loss:0.708 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.711 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.709 AVG Test Loss:0.704 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.707 AVG Test Loss:0.703 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.705 AVG Test Loss:0.701 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.704 AVG Test Loss:0.700 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.702 AVG Test Loss:0.700 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.701 AVG Test Loss:0.699 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.700 AVG Test Loss:0.698 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.699 AVG Test Loss:0.697 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.698 AVG Test Loss:0.696 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.695 AVG Test Loss:0.694 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.693 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.692 AVG Test Loss:0.692 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.691 AVG Test Loss:0.692 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.690 AVG Test Loss:0.691 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.688 AVG Test Loss:0.690 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.687 AVG Test Loss:0.689 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:0.925 AVG Test Loss:0.690 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.641 AVG Test Loss:0.721 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.722 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.863 AVG Test Loss:0.795 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.894 AVG Test Loss:0.785 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.842 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.776 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.733 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.710 AVG Test Loss:0.728 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.713 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:12/50 AVG Training Loss:0.733 AVG Test Loss:0.766 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:13/50 AVG Training Loss:0.752 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/50 AVG Training Loss:0.760 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:15/50 AVG Training Loss:0.755 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:16/50 AVG Training Loss:0.745 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:17/50 AVG Training Loss:0.733 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:18/50 AVG Training Loss:0.725 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:19/50 AVG Training Loss:0.721 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:20/50 AVG Training Loss:0.722 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:21/50 AVG Training Loss:0.726 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:22/50 AVG Training Loss:0.729 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:23/50 AVG Training Loss:0.731 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:24/50 AVG Training Loss:0.731 AVG Test Loss:0.750 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:25/50 AVG Training Loss:0.729 AVG Test Loss:0.750 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:26/50 AVG Training Loss:0.725 AVG Test Loss:0.750 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:27/50 AVG Training Loss:0.722 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:28/50 AVG Training Loss:0.720 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:29/50 AVG Training Loss:0.719 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:30/50 AVG Training Loss:0.719 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:31/50 AVG Training Loss:0.719 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:32/50 AVG Training Loss:0.719 AVG Test Loss:0.758 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:33/50 AVG Training Loss:0.719 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:34/50 AVG Training Loss:0.718 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:35/50 AVG Training Loss:0.716 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:36/50 AVG Training Loss:0.715 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:37/50 AVG Training Loss:0.713 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:38/50 AVG Training Loss:0.712 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:39/50 AVG Training Loss:0.712 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:40/50 AVG Training Loss:0.711 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:41/50 AVG Training Loss:0.710 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:42/50 AVG Training Loss:0.709 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:43/50 AVG Training Loss:0.708 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:44/50 AVG Training Loss:0.707 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:45/50 AVG Training Loss:0.706 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:46/50 AVG Training Loss:0.705 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:47/50 AVG Training Loss:0.704 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:48/50 AVG Training Loss:0.703 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:49/50 AVG Training Loss:0.703 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:50/50 AVG Training Loss:0.702 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.735 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:0.682 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:4/8 AVG Training Loss:0.681 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.683 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.690 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.738 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.691 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:3/8 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.683 AVG Test Loss:0.697 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.692 AVG Test Loss:0.699 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.696 AVG Test Loss:0.697 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.742 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.697 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.685 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.705 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.692 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 37.5 %\n",
            " Average acc: 39.166666666666664 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.735 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.682 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.681 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.683 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.690 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.695 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.738 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.691 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.683 AVG Test Loss:0.697 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.692 AVG Test Loss:0.699 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.696 AVG Test Loss:0.697 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.698 AVG Test Loss:0.699 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.742 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.697 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.685 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.705 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.692 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.694 AVG Test Loss:0.710 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.695 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 37.5 %\n",
            " Average acc: 39.166666666666664 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.735 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:0.682 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 63.64 %\n",
            "Epoch:4/50 AVG Training Loss:0.681 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.683 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.690 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.695 AVG Test Loss:0.706 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.738 AVG Test Loss:0.690 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.691 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:3/50 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.683 AVG Test Loss:0.697 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.692 AVG Test Loss:0.699 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.696 AVG Test Loss:0.697 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.698 AVG Test Loss:0.699 AVG Training Acc 33.33 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.742 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.697 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.685 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.705 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.687 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.692 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.694 AVG Test Loss:0.710 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.695 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 37.5 %\n",
            " Average acc: 39.166666666666664 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.722 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.690 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.685 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.721 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:2/8 AVG Training Loss:0.689 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.683 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.683 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.687 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.686 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.686 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.687 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.688 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            " Average acc: 37.76223776223777 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.690 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.685 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.692 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.721 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.689 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.683 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.683 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.691 AVG Test Loss:0.699 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.687 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.686 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.686 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.687 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.688 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.689 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.690 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            " Average acc: 37.76223776223777 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.722 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.690 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.685 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.686 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.692 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.721 AVG Test Loss:0.691 AVG Training Acc 57.14 % AVG Test Acc 72.73 %\n",
            "Epoch:2/50 AVG Training Loss:0.689 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.683 AVG Test Loss:0.694 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.683 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.691 AVG Test Loss:0.699 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.690 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.687 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.686 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.686 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.687 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.688 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/50 AVG Training Loss:0.689 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/50 AVG Training Loss:0.690 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:11/50 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            " Average acc: 37.76223776223777 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.700 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.680 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.679 AVG Test Loss:0.696 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.682 AVG Test Loss:0.699 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.686 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.692 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.698 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.705 AVG Test Loss:0.710 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/8 AVG Training Loss:0.699 AVG Test Loss:0.692 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.678 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.678 AVG Test Loss:0.696 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.681 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.691 AVG Test Loss:0.709 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.698 AVG Test Loss:0.714 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/8 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:2/8 AVG Training Loss:0.689 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/8 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/8 AVG Training Loss:0.687 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:5/8 AVG Training Loss:0.690 AVG Test Loss:0.715 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/8 AVG Training Loss:0.694 AVG Test Loss:0.720 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:7/8 AVG Training Loss:0.699 AVG Test Loss:0.726 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/8 AVG Training Loss:0.704 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.700 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.680 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.679 AVG Test Loss:0.696 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.682 AVG Test Loss:0.699 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.686 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.692 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.710 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.699 AVG Test Loss:0.692 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.678 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.678 AVG Test Loss:0.696 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.681 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.691 AVG Test Loss:0.709 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.714 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.689 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.687 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.690 AVG Test Loss:0.715 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.694 AVG Test Loss:0.720 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.699 AVG Test Loss:0.726 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.704 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.700 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.680 AVG Test Loss:0.694 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.679 AVG Test Loss:0.696 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.682 AVG Test Loss:0.699 AVG Training Acc 61.90 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.686 AVG Test Loss:0.703 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.692 AVG Test Loss:0.706 AVG Training Acc 47.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.698 AVG Test Loss:0.709 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.705 AVG Test Loss:0.710 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.699 AVG Test Loss:0.692 AVG Training Acc 52.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.678 AVG Test Loss:0.693 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.678 AVG Test Loss:0.696 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.681 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.691 AVG Test Loss:0.709 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.698 AVG Test Loss:0.714 AVG Training Acc 52.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 42.86 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:2/50 AVG Training Loss:0.689 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 40.00 %\n",
            "Epoch:3/50 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:4/50 AVG Training Loss:0.687 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:5/50 AVG Training Loss:0.690 AVG Test Loss:0.715 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/50 AVG Training Loss:0.694 AVG Test Loss:0.720 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:7/50 AVG Training Loss:0.699 AVG Test Loss:0.726 AVG Training Acc 50.00 % AVG Test Acc 40.00 %\n",
            "Epoch:8/50 AVG Training Loss:0.704 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.904761904761905 %\n",
            "grid_param: {'learning_rate': [0.1, 0.01, 0.001, 0.0001, 1e-05], 'batch_size': [4, 6, 10], 'num_epochs': [8, 20, 50]}  grid: [[[0.44137022 0.39166667 0.45416667]\n",
            "  [0.37762238 0.41871921 0.39277389]\n",
            "  [0.52467532 0.45800866 0.56277056]]\n",
            "\n",
            " [[0.44137022 0.40833333 0.40984848]\n",
            "  [0.37762238 0.39044289 0.40559441]\n",
            "  [0.56363636 0.41904762 0.48831169]]\n",
            "\n",
            " [[0.39166667 0.40833333 0.47765152]\n",
            "  [0.41871921 0.62727273 0.3986014 ]\n",
            "  [0.41904762 0.41904762 0.52164502]]\n",
            "\n",
            " [[0.39166667 0.52462121 0.5094697 ]\n",
            "  [0.46969697 0.45920746 0.48484848]\n",
            "  [0.41904762 0.41904762 0.41904762]]\n",
            "\n",
            " [[0.39166667 0.39166667 0.39166667]\n",
            "  [0.37762238 0.37762238 0.37762238]\n",
            "  [0.41904762 0.41904762 0.41904762]]]\n",
            "best: 0.6272727272727273 best_idx: (2, 1, 1)\n",
            "best params: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Running final learning session for Fold(outher): 3  with best_params: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:3.155 AVG Test Loss:0.802 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.895 AVG Test Loss:1.341 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.622 AVG Test Loss:0.713 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.934 AVG Test Loss:0.964 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.838 AVG Test Loss:0.744 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.651 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.695 AVG Test Loss:0.819 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.694 AVG Test Loss:0.742 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.631 AVG Test Loss:0.762 AVG Training Acc 68.75 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.646 AVG Test Loss:0.694 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.643 AVG Test Loss:0.650 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.639 AVG Test Loss:0.655 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.685 AVG Test Loss:0.644 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.596 AVG Test Loss:0.685 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.651 AVG Test Loss:0.645 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.581 AVG Test Loss:0.645 AVG Training Acc 68.75 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.813 AVG Test Loss:0.649 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.635 AVG Test Loss:0.864 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.741 AVG Test Loss:0.670 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.638 AVG Test Loss:0.682 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Fold(outher) 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:285.688 AVG Test Loss:8082.435 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:24182.107 AVG Test Loss:83.809 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:1848.751 AVG Test Loss:2077.172 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:5326.551 AVG Test Loss:1406.127 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:5930.376 AVG Test Loss:1508.142 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:89.333 AVG Test Loss:39.408 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:1121.565 AVG Test Loss:335.985 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1089.864 AVG Test Loss:154.292 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:324.914 AVG Test Loss:7992.586 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:24067.845 AVG Test Loss:13.570 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:1960.361 AVG Test Loss:2051.131 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:5321.460 AVG Test Loss:1202.717 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:4505.984 AVG Test Loss:490.813 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:459.809 AVG Test Loss:131.922 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:933.724 AVG Test Loss:26.097 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:258.125 AVG Test Loss:52.724 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:313.697 AVG Test Loss:8046.018 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:24154.243 AVG Test Loss:57.973 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:1875.960 AVG Test Loss:2061.748 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:5322.467 AVG Test Loss:1310.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:6258.388 AVG Test Loss:1658.629 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:125.469 AVG Test Loss:63.064 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:1239.260 AVG Test Loss:200.279 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:690.523 AVG Test Loss:191.353 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 43.47826086956522 %\n",
            "Fold 1 acc: 43.47826086956522 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 42.31884057971014 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:285.688 AVG Test Loss:8082.435 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:24182.107 AVG Test Loss:83.809 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1848.751 AVG Test Loss:2077.172 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:5326.551 AVG Test Loss:1406.127 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:5930.376 AVG Test Loss:1508.142 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:89.333 AVG Test Loss:39.408 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1121.565 AVG Test Loss:335.985 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1089.864 AVG Test Loss:154.292 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:100.769 AVG Test Loss:398.459 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:835.983 AVG Test Loss:74.467 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:206.659 AVG Test Loss:56.634 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:159.357 AVG Test Loss:36.290 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:8.029 AVG Test Loss:20.766 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:58.569 AVG Test Loss:88.477 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:110.444 AVG Test Loss:13.959 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:15.928 AVG Test Loss:35.798 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:42.700 AVG Test Loss:17.184 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:29.615 AVG Test Loss:6.643 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:2.090 AVG Test Loss:5.153 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:9.110 AVG Test Loss:4.110 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:324.914 AVG Test Loss:7992.586 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:24067.845 AVG Test Loss:13.570 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1960.361 AVG Test Loss:2051.131 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:5321.460 AVG Test Loss:1202.717 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:4505.984 AVG Test Loss:490.813 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:459.809 AVG Test Loss:131.922 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:933.724 AVG Test Loss:26.097 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:258.125 AVG Test Loss:52.724 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:20.860 AVG Test Loss:64.232 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:153.991 AVG Test Loss:171.430 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:228.368 AVG Test Loss:27.293 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:60.516 AVG Test Loss:12.423 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:5.602 AVG Test Loss:5.322 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:24.851 AVG Test Loss:17.654 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:28.680 AVG Test Loss:2.091 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:3.500 AVG Test Loss:3.532 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:4.412 AVG Test Loss:6.749 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:6.314 AVG Test Loss:1.078 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.655 AVG Test Loss:0.802 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:2.218 AVG Test Loss:2.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:313.697 AVG Test Loss:8046.018 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:24154.243 AVG Test Loss:57.973 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1875.960 AVG Test Loss:2061.748 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:5322.467 AVG Test Loss:1310.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:6258.388 AVG Test Loss:1658.629 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:125.469 AVG Test Loss:63.064 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1239.260 AVG Test Loss:200.279 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:690.523 AVG Test Loss:191.353 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1298.968 AVG Test Loss:70.730 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:365.315 AVG Test Loss:105.093 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:519.011 AVG Test Loss:88.291 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:255.391 AVG Test Loss:138.707 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:63.273 AVG Test Loss:102.047 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:174.650 AVG Test Loss:39.685 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:8.861 AVG Test Loss:17.555 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:31.066 AVG Test Loss:3.160 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:8.068 AVG Test Loss:1.581 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:3.523 AVG Test Loss:5.500 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:8.174 AVG Test Loss:2.748 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:4.153 AVG Test Loss:1.398 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 43.47826086956522 %\n",
            " Average acc: 41.15942028985507 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:285.688 AVG Test Loss:8082.435 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:24182.107 AVG Test Loss:83.809 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:1848.751 AVG Test Loss:2077.172 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:5326.551 AVG Test Loss:1406.127 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:5930.376 AVG Test Loss:1508.142 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:89.333 AVG Test Loss:39.408 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:1121.565 AVG Test Loss:335.985 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1089.864 AVG Test Loss:154.292 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:100.769 AVG Test Loss:398.459 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:835.983 AVG Test Loss:74.467 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:206.659 AVG Test Loss:56.634 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:159.357 AVG Test Loss:36.290 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:8.029 AVG Test Loss:20.766 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:58.569 AVG Test Loss:88.477 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:110.444 AVG Test Loss:13.959 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:15.928 AVG Test Loss:35.798 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:42.700 AVG Test Loss:17.184 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:29.615 AVG Test Loss:6.643 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:2.090 AVG Test Loss:5.153 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:9.110 AVG Test Loss:4.110 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:9.398 AVG Test Loss:1.212 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:2.992 AVG Test Loss:0.744 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.936 AVG Test Loss:3.412 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:3.854 AVG Test Loss:2.896 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:3.100 AVG Test Loss:0.799 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:26/50 AVG Training Loss:0.979 AVG Test Loss:0.803 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.362 AVG Test Loss:1.362 AVG Training Acc 86.36 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.977 AVG Test Loss:1.239 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:1.025 AVG Test Loss:0.864 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.548 AVG Test Loss:0.851 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.301 AVG Test Loss:1.147 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.661 AVG Test Loss:0.960 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.578 AVG Test Loss:0.924 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.447 AVG Test Loss:0.993 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.473 AVG Test Loss:1.230 AVG Training Acc 72.73 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.626 AVG Test Loss:1.878 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.904 AVG Test Loss:2.652 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:1.623 AVG Test Loss:1.085 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.866 AVG Test Loss:0.738 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.602 AVG Test Loss:0.743 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.496 AVG Test Loss:0.899 AVG Training Acc 90.91 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.574 AVG Test Loss:2.234 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:1.326 AVG Test Loss:3.503 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:2.549 AVG Test Loss:1.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:2.915 AVG Test Loss:1.601 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:2.798 AVG Test Loss:5.516 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:9.359 AVG Test Loss:3.351 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:16.967 AVG Test Loss:17.858 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:50.920 AVG Test Loss:55.097 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:259.229 AVG Test Loss:49.702 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:324.914 AVG Test Loss:7992.586 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:24067.845 AVG Test Loss:13.570 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:1960.361 AVG Test Loss:2051.131 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:5321.460 AVG Test Loss:1202.717 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:4505.984 AVG Test Loss:490.813 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:459.809 AVG Test Loss:131.922 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:933.724 AVG Test Loss:26.097 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:258.125 AVG Test Loss:52.724 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:20.860 AVG Test Loss:64.232 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:153.991 AVG Test Loss:171.430 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:228.368 AVG Test Loss:27.293 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:60.516 AVG Test Loss:12.423 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:5.602 AVG Test Loss:5.322 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:24.851 AVG Test Loss:17.654 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:28.680 AVG Test Loss:2.091 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:3.500 AVG Test Loss:3.532 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:4.412 AVG Test Loss:6.749 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:6.314 AVG Test Loss:1.078 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:0.655 AVG Test Loss:0.802 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:2.218 AVG Test Loss:2.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:3.238 AVG Test Loss:1.542 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:1.709 AVG Test Loss:0.909 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.313 AVG Test Loss:1.742 AVG Training Acc 86.36 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:1.241 AVG Test Loss:0.832 AVG Training Acc 13.64 % AVG Test Acc 36.36 %\n",
            "Epoch:25/50 AVG Training Loss:0.410 AVG Test Loss:1.097 AVG Training Acc 86.36 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.673 AVG Test Loss:1.825 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:1.327 AVG Test Loss:0.877 AVG Training Acc 22.73 % AVG Test Acc 36.36 %\n",
            "Epoch:28/50 AVG Training Loss:0.517 AVG Test Loss:0.879 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.648 AVG Test Loss:1.934 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:1.428 AVG Test Loss:0.906 AVG Training Acc 13.64 % AVG Test Acc 36.36 %\n",
            "Epoch:31/50 AVG Training Loss:0.581 AVG Test Loss:0.851 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "Epoch:32/50 AVG Training Loss:0.555 AVG Test Loss:0.905 AVG Training Acc 72.73 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.508 AVG Test Loss:0.938 AVG Training Acc 77.27 % AVG Test Acc 36.36 %\n",
            "Epoch:34/50 AVG Training Loss:0.432 AVG Test Loss:1.452 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.942 AVG Test Loss:1.475 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:1.105 AVG Test Loss:0.830 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.331 AVG Test Loss:1.054 AVG Training Acc 95.45 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.708 AVG Test Loss:0.905 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:39/50 AVG Training Loss:0.443 AVG Test Loss:1.264 AVG Training Acc 77.27 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.696 AVG Test Loss:2.207 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:1.401 AVG Test Loss:1.557 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:1.130 AVG Test Loss:0.714 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.587 AVG Test Loss:0.980 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.953 AVG Test Loss:2.162 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:1.390 AVG Test Loss:1.893 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:1.527 AVG Test Loss:2.902 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:1.819 AVG Test Loss:1.715 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:1.466 AVG Test Loss:4.229 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:2.533 AVG Test Loss:6.291 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:3.071 AVG Test Loss:17.116 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:313.697 AVG Test Loss:8046.018 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:24154.243 AVG Test Loss:57.973 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:1875.960 AVG Test Loss:2061.748 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:5322.467 AVG Test Loss:1310.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:6258.388 AVG Test Loss:1658.629 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:125.469 AVG Test Loss:63.064 AVG Training Acc 81.82 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:1239.260 AVG Test Loss:200.279 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:690.523 AVG Test Loss:191.353 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:1298.968 AVG Test Loss:70.730 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:365.315 AVG Test Loss:105.093 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:519.011 AVG Test Loss:88.291 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:255.391 AVG Test Loss:138.707 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:63.273 AVG Test Loss:102.047 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:174.650 AVG Test Loss:39.685 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:8.861 AVG Test Loss:17.555 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:31.066 AVG Test Loss:3.160 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:8.068 AVG Test Loss:1.581 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:3.523 AVG Test Loss:5.500 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:8.174 AVG Test Loss:2.748 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:4.153 AVG Test Loss:1.398 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.302 AVG Test Loss:1.150 AVG Training Acc 86.36 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:1.815 AVG Test Loss:1.391 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:1.457 AVG Test Loss:0.814 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.315 AVG Test Loss:1.349 AVG Training Acc 95.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.996 AVG Test Loss:2.383 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:2.064 AVG Test Loss:0.819 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.702 AVG Test Loss:0.729 AVG Training Acc 63.64 % AVG Test Acc 36.36 %\n",
            "Epoch:28/50 AVG Training Loss:0.935 AVG Test Loss:1.757 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:1.736 AVG Test Loss:0.851 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.370 AVG Test Loss:0.938 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.663 AVG Test Loss:0.888 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.629 AVG Test Loss:0.814 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.333 AVG Test Loss:1.012 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.592 AVG Test Loss:1.004 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.691 AVG Test Loss:0.995 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:36/50 AVG Training Loss:0.706 AVG Test Loss:0.952 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:37/50 AVG Training Loss:0.619 AVG Test Loss:0.900 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "Epoch:38/50 AVG Training Loss:0.462 AVG Test Loss:0.917 AVG Training Acc 81.82 % AVG Test Acc 27.27 %\n",
            "Epoch:39/50 AVG Training Loss:0.416 AVG Test Loss:1.037 AVG Training Acc 86.36 % AVG Test Acc 27.27 %\n",
            "Epoch:40/50 AVG Training Loss:0.539 AVG Test Loss:1.314 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.769 AVG Test Loss:1.914 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:1.084 AVG Test Loss:1.970 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:1.394 AVG Test Loss:0.794 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.463 AVG Test Loss:0.905 AVG Training Acc 77.27 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.698 AVG Test Loss:0.743 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.454 AVG Test Loss:1.081 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.739 AVG Test Loss:1.745 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:1.080 AVG Test Loss:1.968 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:1.390 AVG Test Loss:0.808 AVG Training Acc 9.09 % AVG Test Acc 36.36 %\n",
            "Epoch:50/50 AVG Training Loss:0.643 AVG Test Loss:0.783 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 39.130434782608695 %\n",
            " Average acc: 39.710144927536234 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:313.145 AVG Test Loss:3588.513 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:15686.915 AVG Test Loss:1185.881 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2498.422 AVG Test Loss:174.757 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:833.770 AVG Test Loss:1094.803 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:4273.092 AVG Test Loss:914.950 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.000 AVG Test Loss:1620.640 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:3016.558 AVG Test Loss:25.168 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:437.480 AVG Test Loss:248.683 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:410.051 AVG Test Loss:3500.931 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:15494.888 AVG Test Loss:1138.793 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2386.491 AVG Test Loss:191.823 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:869.246 AVG Test Loss:1458.117 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:3138.148 AVG Test Loss:451.685 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:447.322 AVG Test Loss:837.022 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1538.156 AVG Test Loss:49.900 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:0.251 AVG Test Loss:182.423 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:399.633 AVG Test Loss:3524.134 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:15519.296 AVG Test Loss:1149.746 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2411.549 AVG Test Loss:183.271 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:843.429 AVG Test Loss:1429.198 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:3118.748 AVG Test Loss:503.465 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:513.502 AVG Test Loss:802.906 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1510.804 AVG Test Loss:87.601 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:34.114 AVG Test Loss:462.239 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:313.145 AVG Test Loss:3588.513 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:15686.915 AVG Test Loss:1185.881 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2498.422 AVG Test Loss:174.757 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:833.770 AVG Test Loss:1094.803 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:4273.092 AVG Test Loss:914.950 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.000 AVG Test Loss:1620.640 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:3016.558 AVG Test Loss:25.168 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:437.480 AVG Test Loss:248.683 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:398.942 AVG Test Loss:355.863 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1118.619 AVG Test Loss:306.531 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.000 AVG Test Loss:282.091 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:645.907 AVG Test Loss:180.937 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:41.727 AVG Test Loss:285.401 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:398.252 AVG Test Loss:49.259 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:220.859 AVG Test Loss:39.180 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:15.110 AVG Test Loss:65.756 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:170.506 AVG Test Loss:24.663 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:82.297 AVG Test Loss:40.822 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:71.183 AVG Test Loss:18.004 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:19.380 AVG Test Loss:68.393 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:410.051 AVG Test Loss:3500.931 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:15494.888 AVG Test Loss:1138.793 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2386.491 AVG Test Loss:191.823 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:869.246 AVG Test Loss:1458.117 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:3138.148 AVG Test Loss:451.685 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:447.322 AVG Test Loss:837.022 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1538.156 AVG Test Loss:49.900 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.251 AVG Test Loss:182.423 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:600.141 AVG Test Loss:192.001 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:78.719 AVG Test Loss:74.151 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:134.520 AVG Test Loss:52.857 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:103.965 AVG Test Loss:14.557 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:25.463 AVG Test Loss:21.157 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:89.892 AVG Test Loss:13.817 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:73.317 AVG Test Loss:13.934 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:7.778 AVG Test Loss:12.210 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:18.392 AVG Test Loss:28.277 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:63.375 AVG Test Loss:10.042 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:5.191 AVG Test Loss:4.126 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:23.333 AVG Test Loss:19.481 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:399.633 AVG Test Loss:3524.134 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:15519.296 AVG Test Loss:1149.746 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2411.549 AVG Test Loss:183.271 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:843.429 AVG Test Loss:1429.198 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:3118.748 AVG Test Loss:503.465 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:513.502 AVG Test Loss:802.906 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1510.804 AVG Test Loss:87.601 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:34.114 AVG Test Loss:462.239 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:749.770 AVG Test Loss:90.534 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:398.978 AVG Test Loss:103.887 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:22.934 AVG Test Loss:8.945 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:140.560 AVG Test Loss:90.072 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:246.386 AVG Test Loss:1.006 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:47.653 AVG Test Loss:79.922 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:233.904 AVG Test Loss:70.556 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.000 AVG Test Loss:82.286 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:124.762 AVG Test Loss:13.819 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:4.766 AVG Test Loss:10.337 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:25.225 AVG Test Loss:6.615 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:1.307 AVG Test Loss:9.078 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:313.145 AVG Test Loss:3588.513 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:15686.915 AVG Test Loss:1185.881 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2498.422 AVG Test Loss:174.757 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:833.770 AVG Test Loss:1094.803 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:4273.092 AVG Test Loss:914.950 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.000 AVG Test Loss:1620.640 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:3016.558 AVG Test Loss:25.168 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:437.480 AVG Test Loss:248.683 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:398.942 AVG Test Loss:355.863 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1118.619 AVG Test Loss:306.531 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.000 AVG Test Loss:282.091 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:645.907 AVG Test Loss:180.937 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:41.727 AVG Test Loss:285.401 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:398.252 AVG Test Loss:49.259 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:220.859 AVG Test Loss:39.180 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:15.110 AVG Test Loss:65.756 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:170.506 AVG Test Loss:24.663 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:82.297 AVG Test Loss:40.822 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:71.183 AVG Test Loss:18.004 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:19.380 AVG Test Loss:68.393 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:124.897 AVG Test Loss:27.982 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:8.751 AVG Test Loss:3.544 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:12.643 AVG Test Loss:27.601 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:40.798 AVG Test Loss:5.707 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:5.804 AVG Test Loss:2.063 AVG Training Acc 72.73 % AVG Test Acc 36.36 %\n",
            "Epoch:26/50 AVG Training Loss:11.050 AVG Test Loss:28.574 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:24.670 AVG Test Loss:3.168 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:1.148 AVG Test Loss:74.248 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:62.006 AVG Test Loss:1.703 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:8.199 AVG Test Loss:8.687 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:42.309 AVG Test Loss:6.683 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:9.437 AVG Test Loss:34.868 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:50.365 AVG Test Loss:1.936 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:6.039 AVG Test Loss:3.482 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.034 AVG Test Loss:11.310 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:33.252 AVG Test Loss:16.729 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:20.688 AVG Test Loss:12.784 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:1.085 AVG Test Loss:52.803 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:44.112 AVG Test Loss:1.858 AVG Training Acc 18.18 % AVG Test Acc 27.27 %\n",
            "Epoch:40/50 AVG Training Loss:8.663 AVG Test Loss:2.818 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:11.322 AVG Test Loss:22.543 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:27.140 AVG Test Loss:2.683 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:8.674 AVG Test Loss:1.794 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:9.216 AVG Test Loss:31.173 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:31.348 AVG Test Loss:1.744 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:7.558 AVG Test Loss:2.144 AVG Training Acc 72.73 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:8.659 AVG Test Loss:41.759 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:33.327 AVG Test Loss:6.347 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:6.406 AVG Test Loss:2.997 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:4.355 AVG Test Loss:10.553 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:410.051 AVG Test Loss:3500.931 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:15494.888 AVG Test Loss:1138.793 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2386.491 AVG Test Loss:191.823 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:869.246 AVG Test Loss:1458.117 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:3138.148 AVG Test Loss:451.685 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:447.322 AVG Test Loss:837.022 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1538.156 AVG Test Loss:49.900 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:0.251 AVG Test Loss:182.423 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:600.141 AVG Test Loss:192.001 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:78.719 AVG Test Loss:74.151 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:134.520 AVG Test Loss:52.857 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:12/50 AVG Training Loss:103.965 AVG Test Loss:14.557 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:25.463 AVG Test Loss:21.157 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:89.892 AVG Test Loss:13.817 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:73.317 AVG Test Loss:13.934 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:7.778 AVG Test Loss:12.210 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:18.392 AVG Test Loss:28.277 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:63.375 AVG Test Loss:10.042 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:5.191 AVG Test Loss:4.126 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:23.333 AVG Test Loss:19.481 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:21.823 AVG Test Loss:6.767 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.001 AVG Test Loss:25.605 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:40.490 AVG Test Loss:4.928 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:10.695 AVG Test Loss:0.888 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:5.328 AVG Test Loss:8.734 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:8.537 AVG Test Loss:15.356 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:14.196 AVG Test Loss:1.678 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:3.414 AVG Test Loss:5.315 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:7.371 AVG Test Loss:0.904 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:1.568 AVG Test Loss:0.823 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:31/50 AVG Training Loss:1.380 AVG Test Loss:12.692 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:10.392 AVG Test Loss:9.366 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:9.860 AVG Test Loss:1.883 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.195 AVG Test Loss:5.395 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:6.562 AVG Test Loss:0.967 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.973 AVG Test Loss:1.180 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:1.613 AVG Test Loss:11.918 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:8.476 AVG Test Loss:11.338 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:13.150 AVG Test Loss:0.955 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:1.572 AVG Test Loss:1.336 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:4.646 AVG Test Loss:12.446 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:11.482 AVG Test Loss:6.220 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:6.279 AVG Test Loss:0.945 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:1.049 AVG Test Loss:0.983 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.822 AVG Test Loss:8.661 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:6.442 AVG Test Loss:12.582 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:13.837 AVG Test Loss:0.942 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:48/50 AVG Training Loss:2.878 AVG Test Loss:0.890 AVG Training Acc 72.73 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:2.778 AVG Test Loss:5.169 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:8.834 AVG Test Loss:3.123 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:399.633 AVG Test Loss:3524.134 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:15519.296 AVG Test Loss:1149.746 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2411.549 AVG Test Loss:183.271 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:843.429 AVG Test Loss:1429.198 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:3118.748 AVG Test Loss:503.465 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:513.502 AVG Test Loss:802.906 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1510.804 AVG Test Loss:87.601 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:34.114 AVG Test Loss:462.239 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:749.770 AVG Test Loss:90.534 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:398.978 AVG Test Loss:103.887 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:22.934 AVG Test Loss:8.945 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:140.560 AVG Test Loss:90.072 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:246.386 AVG Test Loss:1.006 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:47.653 AVG Test Loss:79.922 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:233.904 AVG Test Loss:70.556 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.000 AVG Test Loss:82.286 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:124.762 AVG Test Loss:13.819 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:4.766 AVG Test Loss:10.337 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:25.225 AVG Test Loss:6.615 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/50 AVG Training Loss:1.307 AVG Test Loss:9.078 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:14.095 AVG Test Loss:12.593 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:13.659 AVG Test Loss:1.794 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:1.761 AVG Test Loss:19.096 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:19.363 AVG Test Loss:1.328 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.352 AVG Test Loss:1.940 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:4.776 AVG Test Loss:5.614 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:5.713 AVG Test Loss:1.604 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.477 AVG Test Loss:8.921 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:8.151 AVG Test Loss:1.028 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:1.622 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:31/50 AVG Training Loss:1.178 AVG Test Loss:3.777 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:3.989 AVG Test Loss:0.807 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.548 AVG Test Loss:1.648 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:2.825 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.719 AVG Test Loss:0.984 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:1.520 AVG Test Loss:6.732 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:7.219 AVG Test Loss:2.922 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:3.988 AVG Test Loss:0.828 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.574 AVG Test Loss:1.646 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:2.005 AVG Test Loss:0.740 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.703 AVG Test Loss:0.841 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.992 AVG Test Loss:2.358 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:2.133 AVG Test Loss:0.725 AVG Training Acc 4.55 % AVG Test Acc 36.36 %\n",
            "Epoch:44/50 AVG Training Loss:0.586 AVG Test Loss:0.859 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:1.453 AVG Test Loss:0.995 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:1.134 AVG Test Loss:0.734 AVG Training Acc 4.55 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.530 AVG Test Loss:1.495 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:1.485 AVG Test Loss:3.008 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:2.356 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.660 AVG Test Loss:1.160 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:296.626 AVG Test Loss:1996.148 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:11014.751 AVG Test Loss:1243.262 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:8764.050 AVG Test Loss:1346.599 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:1176.426 AVG Test Loss:659.649 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1482.612 AVG Test Loss:353.277 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:1420.259 AVG Test Loss:174.676 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:330.859 AVG Test Loss:64.987 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:280.014 AVG Test Loss:1206.133 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:310.420 AVG Test Loss:1984.500 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:11103.084 AVG Test Loss:1334.873 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:9019.166 AVG Test Loss:1478.107 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:1431.916 AVG Test Loss:510.015 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1178.613 AVG Test Loss:575.542 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:1974.025 AVG Test Loss:21.303 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:365.447 AVG Test Loss:2903.859 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:5028.952 AVG Test Loss:617.079 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:307.152 AVG Test Loss:2004.267 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:11003.146 AVG Test Loss:1278.982 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:8820.998 AVG Test Loss:1378.808 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:1192.249 AVG Test Loss:643.417 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1447.070 AVG Test Loss:377.414 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:1471.087 AVG Test Loss:131.663 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:230.445 AVG Test Loss:90.780 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:332.512 AVG Test Loss:1158.103 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:296.626 AVG Test Loss:1996.148 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:11014.751 AVG Test Loss:1243.262 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:8764.050 AVG Test Loss:1346.599 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1176.426 AVG Test Loss:659.649 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1482.612 AVG Test Loss:353.277 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1420.259 AVG Test Loss:174.676 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:330.859 AVG Test Loss:64.987 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:280.014 AVG Test Loss:1206.133 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1971.804 AVG Test Loss:382.684 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:830.909 AVG Test Loss:1059.794 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1756.200 AVG Test Loss:849.708 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1334.012 AVG Test Loss:551.832 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:752.828 AVG Test Loss:546.825 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:880.737 AVG Test Loss:888.217 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1283.337 AVG Test Loss:219.874 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:287.305 AVG Test Loss:91.093 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:98.221 AVG Test Loss:66.020 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:122.841 AVG Test Loss:195.542 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:284.041 AVG Test Loss:51.439 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:131.751 AVG Test Loss:62.867 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:310.420 AVG Test Loss:1984.500 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:11103.084 AVG Test Loss:1334.873 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:9019.166 AVG Test Loss:1478.107 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1431.916 AVG Test Loss:510.015 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1178.613 AVG Test Loss:575.542 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1974.025 AVG Test Loss:21.303 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:365.447 AVG Test Loss:2903.859 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:5028.952 AVG Test Loss:617.079 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:2536.784 AVG Test Loss:1103.944 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1447.793 AVG Test Loss:576.295 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:821.388 AVG Test Loss:1018.865 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1387.892 AVG Test Loss:146.280 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:479.350 AVG Test Loss:343.433 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:442.951 AVG Test Loss:24.023 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:126.693 AVG Test Loss:199.283 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:459.971 AVG Test Loss:54.484 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:216.529 AVG Test Loss:165.572 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:149.619 AVG Test Loss:29.309 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:88.566 AVG Test Loss:89.107 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:132.524 AVG Test Loss:22.295 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:307.152 AVG Test Loss:2004.267 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:11003.146 AVG Test Loss:1278.982 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:8820.998 AVG Test Loss:1378.808 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1192.249 AVG Test Loss:643.417 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1447.070 AVG Test Loss:377.414 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1471.087 AVG Test Loss:131.663 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:230.445 AVG Test Loss:90.780 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:332.512 AVG Test Loss:1158.103 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1866.340 AVG Test Loss:352.678 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:813.226 AVG Test Loss:1045.392 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1664.974 AVG Test Loss:862.490 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1187.065 AVG Test Loss:124.144 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:245.429 AVG Test Loss:235.988 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:331.353 AVG Test Loss:422.321 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:582.118 AVG Test Loss:314.918 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:401.524 AVG Test Loss:133.886 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:163.813 AVG Test Loss:184.352 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:241.128 AVG Test Loss:268.546 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:328.720 AVG Test Loss:59.958 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:80.408 AVG Test Loss:40.349 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            " Average acc: 54.54545454545454 %\n",
            "current p: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:296.626 AVG Test Loss:1996.148 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:11014.751 AVG Test Loss:1243.262 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:8764.050 AVG Test Loss:1346.599 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:1176.426 AVG Test Loss:659.649 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1482.612 AVG Test Loss:353.277 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:1420.259 AVG Test Loss:174.676 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:330.859 AVG Test Loss:64.987 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:280.014 AVG Test Loss:1206.133 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:1971.804 AVG Test Loss:382.684 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:830.909 AVG Test Loss:1059.794 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:1756.200 AVG Test Loss:849.708 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1334.012 AVG Test Loss:551.832 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:752.828 AVG Test Loss:546.825 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:880.737 AVG Test Loss:888.217 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:1283.337 AVG Test Loss:219.874 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:287.305 AVG Test Loss:91.093 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:98.221 AVG Test Loss:66.020 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:122.841 AVG Test Loss:195.542 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:284.041 AVG Test Loss:51.439 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:131.751 AVG Test Loss:62.867 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:65.347 AVG Test Loss:52.476 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:78.699 AVG Test Loss:93.628 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:109.951 AVG Test Loss:2.299 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:26.627 AVG Test Loss:12.846 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.000 AVG Test Loss:33.927 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:25.970 AVG Test Loss:6.581 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:27/50 AVG Training Loss:6.758 AVG Test Loss:5.818 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.623 AVG Test Loss:28.712 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:16.368 AVG Test Loss:6.738 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:3.238 AVG Test Loss:6.018 AVG Training Acc 63.64 % AVG Test Acc 27.27 %\n",
            "Epoch:31/50 AVG Training Loss:0.170 AVG Test Loss:10.789 AVG Training Acc 95.45 % AVG Test Acc 36.36 %\n",
            "Epoch:32/50 AVG Training Loss:2.542 AVG Test Loss:12.662 AVG Training Acc 72.73 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:7.545 AVG Test Loss:10.059 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:34/50 AVG Training Loss:2.250 AVG Test Loss:24.846 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:13.231 AVG Test Loss:4.871 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:36/50 AVG Training Loss:0.917 AVG Test Loss:6.392 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.453 AVG Test Loss:4.152 AVG Training Acc 81.82 % AVG Test Acc 36.36 %\n",
            "Epoch:38/50 AVG Training Loss:0.203 AVG Test Loss:5.855 AVG Training Acc 90.91 % AVG Test Acc 36.36 %\n",
            "Epoch:39/50 AVG Training Loss:1.085 AVG Test Loss:3.365 AVG Training Acc 72.73 % AVG Test Acc 36.36 %\n",
            "Epoch:40/50 AVG Training Loss:0.104 AVG Test Loss:4.203 AVG Training Acc 95.45 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.486 AVG Test Loss:3.062 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "Epoch:42/50 AVG Training Loss:0.020 AVG Test Loss:3.441 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:43/50 AVG Training Loss:0.347 AVG Test Loss:2.917 AVG Training Acc 81.82 % AVG Test Acc 36.36 %\n",
            "Epoch:44/50 AVG Training Loss:0.160 AVG Test Loss:2.912 AVG Training Acc 90.91 % AVG Test Acc 27.27 %\n",
            "Epoch:45/50 AVG Training Loss:0.122 AVG Test Loss:3.137 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.115 AVG Test Loss:2.793 AVG Training Acc 90.91 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.032 AVG Test Loss:2.742 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:48/50 AVG Training Loss:0.070 AVG Test Loss:2.800 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:49/50 AVG Training Loss:0.082 AVG Test Loss:2.814 AVG Training Acc 95.45 % AVG Test Acc 27.27 %\n",
            "Epoch:50/50 AVG Training Loss:0.045 AVG Test Loss:2.993 AVG Training Acc 100.00 % AVG Test Acc 27.27 %\n",
            "Epoch:1/50 AVG Training Loss:310.420 AVG Test Loss:1984.500 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:11103.084 AVG Test Loss:1334.873 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:9019.166 AVG Test Loss:1478.107 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:1431.916 AVG Test Loss:510.015 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1178.613 AVG Test Loss:575.542 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:1974.025 AVG Test Loss:21.303 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:365.447 AVG Test Loss:2903.859 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:5028.952 AVG Test Loss:617.079 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:2536.784 AVG Test Loss:1103.944 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:1447.793 AVG Test Loss:576.295 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:821.388 AVG Test Loss:1018.865 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1387.892 AVG Test Loss:146.280 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:479.350 AVG Test Loss:343.433 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:442.951 AVG Test Loss:24.023 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:126.693 AVG Test Loss:199.283 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:459.971 AVG Test Loss:54.484 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:216.529 AVG Test Loss:165.572 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:149.619 AVG Test Loss:29.309 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:88.566 AVG Test Loss:89.107 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:132.524 AVG Test Loss:22.295 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:44.516 AVG Test Loss:36.672 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:35.445 AVG Test Loss:41.621 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:43.111 AVG Test Loss:14.893 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:3.194 AVG Test Loss:26.423 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:21.076 AVG Test Loss:12.031 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:2.490 AVG Test Loss:22.341 AVG Training Acc 72.73 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:14.161 AVG Test Loss:4.240 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.205 AVG Test Loss:11.967 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:6.380 AVG Test Loss:3.466 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:30/50 AVG Training Loss:0.557 AVG Test Loss:7.082 AVG Training Acc 90.91 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:3.760 AVG Test Loss:2.806 AVG Training Acc 59.09 % AVG Test Acc 72.73 %\n",
            "Epoch:32/50 AVG Training Loss:0.549 AVG Test Loss:3.582 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:1.592 AVG Test Loss:1.965 AVG Training Acc 72.73 % AVG Test Acc 63.64 %\n",
            "Epoch:34/50 AVG Training Loss:0.865 AVG Test Loss:1.794 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.456 AVG Test Loss:3.072 AVG Training Acc 90.91 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:1.662 AVG Test Loss:1.802 AVG Training Acc 63.64 % AVG Test Acc 63.64 %\n",
            "Epoch:37/50 AVG Training Loss:1.002 AVG Test Loss:1.318 AVG Training Acc 63.64 % AVG Test Acc 63.64 %\n",
            "Epoch:38/50 AVG Training Loss:0.219 AVG Test Loss:3.516 AVG Training Acc 90.91 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:2.216 AVG Test Loss:1.551 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.651 AVG Test Loss:1.076 AVG Training Acc 68.18 % AVG Test Acc 72.73 %\n",
            "Epoch:41/50 AVG Training Loss:0.474 AVG Test Loss:0.925 AVG Training Acc 68.18 % AVG Test Acc 72.73 %\n",
            "Epoch:42/50 AVG Training Loss:0.123 AVG Test Loss:1.441 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.737 AVG Test Loss:0.990 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.337 AVG Test Loss:1.104 AVG Training Acc 90.91 % AVG Test Acc 72.73 %\n",
            "Epoch:45/50 AVG Training Loss:0.245 AVG Test Loss:1.075 AVG Training Acc 86.36 % AVG Test Acc 63.64 %\n",
            "Epoch:46/50 AVG Training Loss:0.132 AVG Test Loss:1.300 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.311 AVG Test Loss:1.188 AVG Training Acc 90.91 % AVG Test Acc 63.64 %\n",
            "Epoch:48/50 AVG Training Loss:0.168 AVG Test Loss:1.303 AVG Training Acc 95.45 % AVG Test Acc 72.73 %\n",
            "Epoch:49/50 AVG Training Loss:0.123 AVG Test Loss:1.291 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:50/50 AVG Training Loss:0.083 AVG Test Loss:1.366 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:307.152 AVG Test Loss:2004.267 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:11003.146 AVG Test Loss:1278.982 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:8820.998 AVG Test Loss:1378.808 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:1192.249 AVG Test Loss:643.417 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1447.070 AVG Test Loss:377.414 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:1471.087 AVG Test Loss:131.663 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:230.445 AVG Test Loss:90.780 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:332.512 AVG Test Loss:1158.103 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:1866.340 AVG Test Loss:352.678 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:813.226 AVG Test Loss:1045.392 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:1664.974 AVG Test Loss:862.490 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1187.065 AVG Test Loss:124.144 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:245.429 AVG Test Loss:235.988 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:331.353 AVG Test Loss:422.321 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:582.118 AVG Test Loss:314.918 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:401.524 AVG Test Loss:133.886 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:163.813 AVG Test Loss:184.352 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:241.128 AVG Test Loss:268.546 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:328.720 AVG Test Loss:59.958 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:80.408 AVG Test Loss:40.349 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:45.834 AVG Test Loss:13.682 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:26.803 AVG Test Loss:49.337 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:65.036 AVG Test Loss:8.285 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:29.959 AVG Test Loss:7.363 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:3.987 AVG Test Loss:31.121 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:36.875 AVG Test Loss:1.017 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:27/50 AVG Training Loss:16.486 AVG Test Loss:11.855 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:5.082 AVG Test Loss:12.242 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:8.100 AVG Test Loss:12.321 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:7.368 AVG Test Loss:7.518 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:9.407 AVG Test Loss:1.487 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:32/50 AVG Training Loss:0.000 AVG Test Loss:27.046 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:20.113 AVG Test Loss:13.711 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:8.854 AVG Test Loss:5.848 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:4.604 AVG Test Loss:1.674 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.063 AVG Test Loss:9.942 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:6.233 AVG Test Loss:2.216 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:4.624 AVG Test Loss:4.941 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:1.950 AVG Test Loss:11.466 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:6.707 AVG Test Loss:2.323 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:2.779 AVG Test Loss:1.259 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:42/50 AVG Training Loss:0.001 AVG Test Loss:9.172 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:4.796 AVG Test Loss:1.979 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.165 AVG Test Loss:3.090 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:2.008 AVG Test Loss:1.129 AVG Training Acc 63.64 % AVG Test Acc 63.64 %\n",
            "Epoch:46/50 AVG Training Loss:0.004 AVG Test Loss:5.124 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:2.024 AVG Test Loss:1.283 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.113 AVG Test Loss:1.429 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.536 AVG Test Loss:1.017 AVG Training Acc 86.36 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.102 AVG Test Loss:1.213 AVG Training Acc 95.45 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            " Average acc: 43.93939393939394 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:36.418 AVG Test Loss:52.310 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:168.974 AVG Test Loss:18.325 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:10.684 AVG Test Loss:14.805 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:31.948 AVG Test Loss:5.581 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:9.102 AVG Test Loss:7.840 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:14.633 AVG Test Loss:1.298 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.741 AVG Test Loss:2.466 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:4.373 AVG Test Loss:0.851 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:36.439 AVG Test Loss:53.613 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:171.931 AVG Test Loss:16.115 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:8.336 AVG Test Loss:14.967 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:32.124 AVG Test Loss:5.606 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:7.988 AVG Test Loss:8.572 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:15.955 AVG Test Loss:1.598 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:1.018 AVG Test Loss:2.744 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:4.793 AVG Test Loss:0.938 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:36.634 AVG Test Loss:52.784 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:170.111 AVG Test Loss:17.590 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:9.558 AVG Test Loss:15.307 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:32.909 AVG Test Loss:5.662 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:9.013 AVG Test Loss:7.764 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:14.712 AVG Test Loss:1.281 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.631 AVG Test Loss:2.365 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:4.392 AVG Test Loss:0.824 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 43.47826086956522 %\n",
            "Fold 1 acc: 43.47826086956522 %\n",
            "Fold 2 acc: 43.47826086956522 %\n",
            " Average acc: 43.47826086956522 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:36.418 AVG Test Loss:52.310 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:168.974 AVG Test Loss:18.325 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:10.684 AVG Test Loss:14.805 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:31.948 AVG Test Loss:5.581 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:9.102 AVG Test Loss:7.840 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:14.633 AVG Test Loss:1.298 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.741 AVG Test Loss:2.466 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:4.373 AVG Test Loss:0.851 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.543 AVG Test Loss:0.825 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.250 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.802 AVG Test Loss:0.762 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.934 AVG Test Loss:0.705 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.828 AVG Test Loss:0.688 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.697 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.694 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:36.439 AVG Test Loss:53.613 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:171.931 AVG Test Loss:16.115 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:8.336 AVG Test Loss:14.967 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:32.124 AVG Test Loss:5.606 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:7.988 AVG Test Loss:8.572 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:15.955 AVG Test Loss:1.598 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.018 AVG Test Loss:2.744 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:4.793 AVG Test Loss:0.938 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.569 AVG Test Loss:0.919 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.431 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.786 AVG Test Loss:0.770 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.912 AVG Test Loss:0.719 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.856 AVG Test Loss:0.682 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.691 AVG Test Loss:0.697 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.706 AVG Test Loss:0.696 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.698 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.697 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:36.634 AVG Test Loss:52.784 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:170.111 AVG Test Loss:17.590 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:9.558 AVG Test Loss:15.307 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:32.909 AVG Test Loss:5.662 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:9.013 AVG Test Loss:7.764 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:14.712 AVG Test Loss:1.281 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.631 AVG Test Loss:2.365 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:4.392 AVG Test Loss:0.824 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.522 AVG Test Loss:0.798 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.258 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.778 AVG Test Loss:0.760 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.954 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.792 AVG Test Loss:0.691 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.716 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.708 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.698 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 40.00000000000001 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:36.418 AVG Test Loss:52.310 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:168.974 AVG Test Loss:18.325 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:10.684 AVG Test Loss:14.805 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:31.948 AVG Test Loss:5.581 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:9.102 AVG Test Loss:7.840 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:14.633 AVG Test Loss:1.298 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.741 AVG Test Loss:2.466 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:4.373 AVG Test Loss:0.851 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.543 AVG Test Loss:0.825 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.250 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.802 AVG Test Loss:0.762 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.934 AVG Test Loss:0.705 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.828 AVG Test Loss:0.688 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.697 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.700 AVG Test Loss:0.694 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:0.695 AVG Test Loss:0.694 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:0.694 AVG Test Loss:0.694 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:36.439 AVG Test Loss:53.613 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:171.931 AVG Test Loss:16.115 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:8.336 AVG Test Loss:14.967 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:32.124 AVG Test Loss:5.606 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:7.988 AVG Test Loss:8.572 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:15.955 AVG Test Loss:1.598 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:1.018 AVG Test Loss:2.744 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:4.793 AVG Test Loss:0.938 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.569 AVG Test Loss:0.919 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.431 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.786 AVG Test Loss:0.770 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.912 AVG Test Loss:0.719 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.856 AVG Test Loss:0.682 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.691 AVG Test Loss:0.697 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.706 AVG Test Loss:0.696 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.702 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.698 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.697 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:36.634 AVG Test Loss:52.784 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:170.111 AVG Test Loss:17.590 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:9.558 AVG Test Loss:15.307 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:32.909 AVG Test Loss:5.662 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:9.013 AVG Test Loss:7.764 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:14.712 AVG Test Loss:1.281 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.631 AVG Test Loss:2.365 AVG Training Acc 81.82 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:4.392 AVG Test Loss:0.824 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.522 AVG Test Loss:0.798 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.258 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.778 AVG Test Loss:0.760 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.954 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.792 AVG Test Loss:0.691 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.716 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.708 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.698 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:18/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.696 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.695 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.66666666666667 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:41.633 AVG Test Loss:18.679 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:81.901 AVG Test Loss:3.593 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:8.957 AVG Test Loss:2.788 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:8.031 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:9.985 AVG Test Loss:2.592 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.063 AVG Test Loss:2.812 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:5.411 AVG Test Loss:1.133 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:1.084 AVG Test Loss:1.591 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:42.308 AVG Test Loss:18.010 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:80.542 AVG Test Loss:4.125 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:10.091 AVG Test Loss:2.304 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:6.968 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:8.116 AVG Test Loss:1.519 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.427 AVG Test Loss:1.528 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:4.659 AVG Test Loss:1.254 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:0.376 AVG Test Loss:1.584 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:42.393 AVG Test Loss:18.196 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:80.705 AVG Test Loss:3.919 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:9.661 AVG Test Loss:2.485 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:7.366 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:8.764 AVG Test Loss:1.925 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.123 AVG Test Loss:2.438 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:5.331 AVG Test Loss:1.116 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:0.608 AVG Test Loss:1.426 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:41.633 AVG Test Loss:18.679 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:81.901 AVG Test Loss:3.593 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:8.957 AVG Test Loss:2.788 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:8.031 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:9.985 AVG Test Loss:2.592 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.063 AVG Test Loss:2.812 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:5.411 AVG Test Loss:1.133 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.084 AVG Test Loss:1.591 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:2.846 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.780 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.530 AVG Test Loss:0.856 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.260 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.905 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.661 AVG Test Loss:0.757 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.874 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.807 AVG Test Loss:0.687 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.706 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.680 AVG Test Loss:0.701 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.708 AVG Test Loss:0.702 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.719 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:42.308 AVG Test Loss:18.010 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:80.542 AVG Test Loss:4.125 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:10.091 AVG Test Loss:2.304 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:6.968 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:8.116 AVG Test Loss:1.519 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.427 AVG Test Loss:1.528 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:4.659 AVG Test Loss:1.254 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.376 AVG Test Loss:1.584 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:2.769 AVG Test Loss:0.747 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.287 AVG Test Loss:0.729 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.885 AVG Test Loss:0.795 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.232 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.686 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.835 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.798 AVG Test Loss:0.685 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.696 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.720 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.719 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:42.393 AVG Test Loss:18.196 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:80.705 AVG Test Loss:3.919 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:9.661 AVG Test Loss:2.485 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:7.366 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:8.764 AVG Test Loss:1.925 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.123 AVG Test Loss:2.438 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:5.331 AVG Test Loss:1.116 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.608 AVG Test Loss:1.426 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:2.518 AVG Test Loss:0.706 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.387 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.745 AVG Test Loss:0.810 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.204 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.800 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.659 AVG Test Loss:0.730 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.809 AVG Test Loss:0.702 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.795 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.722 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.689 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.705 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:41.633 AVG Test Loss:18.679 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:81.901 AVG Test Loss:3.593 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:8.957 AVG Test Loss:2.788 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:8.031 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:9.985 AVG Test Loss:2.592 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.063 AVG Test Loss:2.812 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:5.411 AVG Test Loss:1.133 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:1.084 AVG Test Loss:1.591 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:2.846 AVG Test Loss:0.689 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:1.780 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.530 AVG Test Loss:0.856 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1.260 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:0.905 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.661 AVG Test Loss:0.757 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.874 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.807 AVG Test Loss:0.687 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.706 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.680 AVG Test Loss:0.701 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.708 AVG Test Loss:0.702 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.719 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.701 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.694 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:0.693 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.695 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:42.308 AVG Test Loss:18.010 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:80.542 AVG Test Loss:4.125 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:10.091 AVG Test Loss:2.304 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:6.968 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:8.116 AVG Test Loss:1.519 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.427 AVG Test Loss:1.528 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:4.659 AVG Test Loss:1.254 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:0.376 AVG Test Loss:1.584 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:2.769 AVG Test Loss:0.747 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:1.287 AVG Test Loss:0.729 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.885 AVG Test Loss:0.795 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1.232 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.686 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.835 AVG Test Loss:0.695 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.798 AVG Test Loss:0.685 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.702 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.696 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.720 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.719 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.707 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.696 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.692 AVG Test Loss:0.697 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.695 AVG Test Loss:0.699 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.696 AVG Test Loss:0.699 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.695 AVG Test Loss:0.699 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.695 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.695 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.694 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.694 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.694 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:42.393 AVG Test Loss:18.196 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:80.705 AVG Test Loss:3.919 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:9.661 AVG Test Loss:2.485 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:7.366 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:8.764 AVG Test Loss:1.925 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.123 AVG Test Loss:2.438 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:5.331 AVG Test Loss:1.116 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:0.608 AVG Test Loss:1.426 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:2.518 AVG Test Loss:0.706 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:1.387 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.745 AVG Test Loss:0.810 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:1.204 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:0.800 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.659 AVG Test Loss:0.730 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.809 AVG Test Loss:0.702 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.795 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.722 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.689 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.705 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.709 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.700 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:0.694 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:24/50 AVG Training Loss:0.693 AVG Test Loss:0.696 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.695 AVG Test Loss:0.697 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:33.710 AVG Test Loss:10.609 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:58.860 AVG Test Loss:2.193 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:19.701 AVG Test Loss:1.298 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.977 AVG Test Loss:5.623 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:13.204 AVG Test Loss:3.706 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:7.387 AVG Test Loss:4.998 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:10.408 AVG Test Loss:5.412 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:9.896 AVG Test Loss:3.186 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:32.894 AVG Test Loss:10.568 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:59.371 AVG Test Loss:2.623 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:21.013 AVG Test Loss:1.469 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:1.103 AVG Test Loss:5.983 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:14.528 AVG Test Loss:3.918 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:7.026 AVG Test Loss:5.358 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:11.859 AVG Test Loss:6.093 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:11.275 AVG Test Loss:2.874 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:33.676 AVG Test Loss:10.668 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:58.903 AVG Test Loss:2.315 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:19.962 AVG Test Loss:1.332 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.988 AVG Test Loss:5.756 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:13.519 AVG Test Loss:3.824 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:7.384 AVG Test Loss:5.328 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:11.015 AVG Test Loss:5.872 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:10.598 AVG Test Loss:3.084 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            " Average acc: 54.54545454545454 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:33.710 AVG Test Loss:10.609 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:58.860 AVG Test Loss:2.193 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:19.701 AVG Test Loss:1.298 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.977 AVG Test Loss:5.623 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:13.204 AVG Test Loss:3.706 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:7.387 AVG Test Loss:4.998 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:10.408 AVG Test Loss:5.412 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:9.896 AVG Test Loss:3.186 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:5.741 AVG Test Loss:0.850 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.318 AVG Test Loss:1.553 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:2.815 AVG Test Loss:0.986 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.190 AVG Test Loss:1.412 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:2.216 AVG Test Loss:0.922 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.748 AVG Test Loss:0.775 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.721 AVG Test Loss:0.823 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.950 AVG Test Loss:0.822 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.062 AVG Test Loss:0.691 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.768 AVG Test Loss:0.772 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.774 AVG Test Loss:0.928 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.057 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:32.894 AVG Test Loss:10.568 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:59.371 AVG Test Loss:2.623 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:21.013 AVG Test Loss:1.469 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.103 AVG Test Loss:5.983 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:14.528 AVG Test Loss:3.918 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:7.026 AVG Test Loss:5.358 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:11.859 AVG Test Loss:6.093 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:11.275 AVG Test Loss:2.874 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:5.161 AVG Test Loss:0.997 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.715 AVG Test Loss:1.567 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:2.776 AVG Test Loss:0.951 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.156 AVG Test Loss:1.116 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.681 AVG Test Loss:0.876 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.581 AVG Test Loss:0.742 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.662 AVG Test Loss:0.943 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:1.177 AVG Test Loss:0.860 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.096 AVG Test Loss:0.684 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.750 AVG Test Loss:0.719 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.649 AVG Test Loss:0.885 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.896 AVG Test Loss:0.818 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:33.676 AVG Test Loss:10.668 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:58.903 AVG Test Loss:2.315 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:19.962 AVG Test Loss:1.332 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.988 AVG Test Loss:5.756 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:13.519 AVG Test Loss:3.824 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:7.384 AVG Test Loss:5.328 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:11.015 AVG Test Loss:5.872 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:10.598 AVG Test Loss:3.084 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:5.609 AVG Test Loss:0.948 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.536 AVG Test Loss:1.617 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:2.851 AVG Test Loss:0.988 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.266 AVG Test Loss:1.236 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.906 AVG Test Loss:0.955 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.703 AVG Test Loss:0.767 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.765 AVG Test Loss:0.827 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.963 AVG Test Loss:0.864 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.112 AVG Test Loss:0.687 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.811 AVG Test Loss:0.710 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.659 AVG Test Loss:0.883 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.978 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.01, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:33.710 AVG Test Loss:10.609 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:58.860 AVG Test Loss:2.193 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:19.701 AVG Test Loss:1.298 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.977 AVG Test Loss:5.623 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:13.204 AVG Test Loss:3.706 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:7.387 AVG Test Loss:4.998 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:10.408 AVG Test Loss:5.412 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:9.896 AVG Test Loss:3.186 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:5.741 AVG Test Loss:0.850 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.318 AVG Test Loss:1.553 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:2.815 AVG Test Loss:0.986 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:12/50 AVG Training Loss:1.190 AVG Test Loss:1.412 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:2.216 AVG Test Loss:0.922 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:1.748 AVG Test Loss:0.775 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.721 AVG Test Loss:0.823 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.950 AVG Test Loss:0.822 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:1.062 AVG Test Loss:0.691 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.768 AVG Test Loss:0.772 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.774 AVG Test Loss:0.928 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:1.057 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.799 AVG Test Loss:0.700 AVG Training Acc 9.09 % AVG Test Acc 36.36 %\n",
            "Epoch:22/50 AVG Training Loss:0.667 AVG Test Loss:0.765 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.730 AVG Test Loss:0.827 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.813 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.768 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.709 AVG Test Loss:0.734 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.685 AVG Test Loss:0.779 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.717 AVG Test Loss:0.816 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.754 AVG Test Loss:0.790 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.735 AVG Test Loss:0.764 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.699 AVG Test Loss:0.782 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.695 AVG Test Loss:0.825 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.726 AVG Test Loss:0.824 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.729 AVG Test Loss:0.803 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.703 AVG Test Loss:0.824 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.704 AVG Test Loss:0.854 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.726 AVG Test Loss:0.842 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.714 AVG Test Loss:0.844 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.701 AVG Test Loss:0.872 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.716 AVG Test Loss:0.870 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.712 AVG Test Loss:0.871 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.699 AVG Test Loss:0.894 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.708 AVG Test Loss:0.895 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.704 AVG Test Loss:0.901 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.695 AVG Test Loss:0.920 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.702 AVG Test Loss:0.922 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.694 AVG Test Loss:0.936 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.692 AVG Test Loss:0.949 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.693 AVG Test Loss:0.955 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.686 AVG Test Loss:0.973 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:32.894 AVG Test Loss:10.568 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:59.371 AVG Test Loss:2.623 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:21.013 AVG Test Loss:1.469 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:1.103 AVG Test Loss:5.983 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:14.528 AVG Test Loss:3.918 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:7.026 AVG Test Loss:5.358 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:11.859 AVG Test Loss:6.093 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:11.275 AVG Test Loss:2.874 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:5.161 AVG Test Loss:0.997 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.715 AVG Test Loss:1.567 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:2.776 AVG Test Loss:0.951 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:12/50 AVG Training Loss:1.156 AVG Test Loss:1.116 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:1.681 AVG Test Loss:0.876 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:1.581 AVG Test Loss:0.742 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.662 AVG Test Loss:0.943 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:1.177 AVG Test Loss:0.860 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:1.096 AVG Test Loss:0.684 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.750 AVG Test Loss:0.719 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.649 AVG Test Loss:0.885 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.896 AVG Test Loss:0.818 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.836 AVG Test Loss:0.709 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.722 AVG Test Loss:0.700 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.665 AVG Test Loss:0.769 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.722 AVG Test Loss:0.827 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.795 AVG Test Loss:0.768 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.758 AVG Test Loss:0.703 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.698 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.674 AVG Test Loss:0.739 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.708 AVG Test Loss:0.762 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.742 AVG Test Loss:0.722 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.718 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.685 AVG Test Loss:0.717 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.695 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.725 AVG Test Loss:0.717 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.710 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.688 AVG Test Loss:0.728 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.704 AVG Test Loss:0.730 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.712 AVG Test Loss:0.713 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.691 AVG Test Loss:0.725 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.692 AVG Test Loss:0.735 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.702 AVG Test Loss:0.723 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.687 AVG Test Loss:0.731 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.685 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.691 AVG Test Loss:0.735 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.680 AVG Test Loss:0.744 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.679 AVG Test Loss:0.751 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.681 AVG Test Loss:0.751 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.672 AVG Test Loss:0.763 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.674 AVG Test Loss:0.766 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.670 AVG Test Loss:0.773 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:33.676 AVG Test Loss:10.668 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:58.903 AVG Test Loss:2.315 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:19.962 AVG Test Loss:1.332 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.988 AVG Test Loss:5.756 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:13.519 AVG Test Loss:3.824 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:7.384 AVG Test Loss:5.328 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:11.015 AVG Test Loss:5.872 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:10.598 AVG Test Loss:3.084 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:5.609 AVG Test Loss:0.948 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:1.536 AVG Test Loss:1.617 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:2.851 AVG Test Loss:0.988 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:12/50 AVG Training Loss:1.266 AVG Test Loss:1.236 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:1.906 AVG Test Loss:0.955 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:1.703 AVG Test Loss:0.767 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.765 AVG Test Loss:0.827 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.963 AVG Test Loss:0.864 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:1.112 AVG Test Loss:0.687 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.811 AVG Test Loss:0.710 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.659 AVG Test Loss:0.883 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.978 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.858 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.722 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.675 AVG Test Loss:0.757 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.738 AVG Test Loss:0.797 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.795 AVG Test Loss:0.765 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.768 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.722 AVG Test Loss:0.718 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.698 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.712 AVG Test Loss:0.772 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.745 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.746 AVG Test Loss:0.742 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.722 AVG Test Loss:0.735 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.705 AVG Test Loss:0.753 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.716 AVG Test Loss:0.771 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.735 AVG Test Loss:0.761 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.730 AVG Test Loss:0.749 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.713 AVG Test Loss:0.760 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.715 AVG Test Loss:0.774 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.729 AVG Test Loss:0.767 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.724 AVG Test Loss:0.762 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.713 AVG Test Loss:0.774 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.718 AVG Test Loss:0.778 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.723 AVG Test Loss:0.773 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.714 AVG Test Loss:0.779 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.713 AVG Test Loss:0.786 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.718 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.712 AVG Test Loss:0.788 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.710 AVG Test Loss:0.795 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.713 AVG Test Loss:0.795 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.708 AVG Test Loss:0.801 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 45.23809523809524 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:7.830 AVG Test Loss:0.816 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.700 AVG Test Loss:1.104 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2.562 AVG Test Loss:0.774 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.539 AVG Test Loss:0.847 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1.244 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:1.056 AVG Test Loss:0.697 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.639 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.834 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:7.791 AVG Test Loss:0.811 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.732 AVG Test Loss:1.077 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2.552 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.525 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1.260 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:1.055 AVG Test Loss:0.696 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.638 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.828 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:7.802 AVG Test Loss:0.817 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.736 AVG Test Loss:1.086 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:2.548 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.529 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:1.257 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:1.056 AVG Test Loss:0.692 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.640 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.827 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 40.00000000000001 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:7.830 AVG Test Loss:0.816 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.700 AVG Test Loss:1.104 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.562 AVG Test Loss:0.774 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.539 AVG Test Loss:0.847 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.244 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.056 AVG Test Loss:0.697 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.639 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.834 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.858 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.738 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.723 AVG Test Loss:0.715 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.706 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.762 AVG Test Loss:0.697 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.731 AVG Test Loss:0.706 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.729 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.726 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.727 AVG Test Loss:0.702 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:7.791 AVG Test Loss:0.811 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.732 AVG Test Loss:1.077 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.552 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.525 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.260 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.055 AVG Test Loss:0.696 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.638 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.828 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.858 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.740 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.719 AVG Test Loss:0.717 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.707 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.762 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.729 AVG Test Loss:0.708 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.739 AVG Test Loss:0.706 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.728 AVG Test Loss:0.703 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.724 AVG Test Loss:0.705 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.725 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:7.802 AVG Test Loss:0.817 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.736 AVG Test Loss:1.086 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.548 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.529 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.257 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.056 AVG Test Loss:0.692 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.640 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.858 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.719 AVG Test Loss:0.711 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.702 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.763 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.729 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.737 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.729 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.724 AVG Test Loss:0.702 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.725 AVG Test Loss:0.702 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 40.00000000000001 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:7.830 AVG Test Loss:0.816 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.700 AVG Test Loss:1.104 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2.562 AVG Test Loss:0.774 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.539 AVG Test Loss:0.847 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1.244 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:1.056 AVG Test Loss:0.697 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.639 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.834 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.858 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.738 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.723 AVG Test Loss:0.715 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.774 AVG Test Loss:0.706 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.762 AVG Test Loss:0.697 AVG Training Acc 4.55 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.731 AVG Test Loss:0.706 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.729 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.726 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.727 AVG Test Loss:0.702 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.725 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.722 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.719 AVG Test Loss:0.701 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.718 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.717 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.715 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.713 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.712 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.710 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.709 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.708 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.706 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.705 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.704 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.703 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.703 AVG Test Loss:0.702 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.702 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.701 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.701 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.700 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.700 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.699 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.699 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.698 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.698 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.697 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.697 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.697 AVG Test Loss:0.704 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.696 AVG Test Loss:0.704 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:7.791 AVG Test Loss:0.811 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.732 AVG Test Loss:1.077 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2.552 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.525 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1.260 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:1.055 AVG Test Loss:0.696 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.638 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.828 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.858 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.740 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:11/50 AVG Training Loss:0.719 AVG Test Loss:0.717 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.770 AVG Test Loss:0.707 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.762 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.729 AVG Test Loss:0.708 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.739 AVG Test Loss:0.706 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.728 AVG Test Loss:0.703 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.724 AVG Test Loss:0.705 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.725 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.724 AVG Test Loss:0.704 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.721 AVG Test Loss:0.704 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.718 AVG Test Loss:0.704 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.716 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.715 AVG Test Loss:0.705 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.712 AVG Test Loss:0.704 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.709 AVG Test Loss:0.705 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.708 AVG Test Loss:0.705 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.707 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.706 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.705 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.704 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.703 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.702 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.701 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.699 AVG Test Loss:0.706 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.699 AVG Test Loss:0.706 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.698 AVG Test Loss:0.707 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.698 AVG Test Loss:0.707 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.697 AVG Test Loss:0.707 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.697 AVG Test Loss:0.707 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.695 AVG Test Loss:0.709 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:7.802 AVG Test Loss:0.817 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.736 AVG Test Loss:1.086 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:2.548 AVG Test Loss:0.780 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.529 AVG Test Loss:0.856 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:1.257 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:1.056 AVG Test Loss:0.692 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.640 AVG Test Loss:0.728 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.827 AVG Test Loss:0.724 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.858 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.719 AVG Test Loss:0.711 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.769 AVG Test Loss:0.702 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.763 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/50 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.729 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.737 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.729 AVG Test Loss:0.700 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.724 AVG Test Loss:0.702 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.725 AVG Test Loss:0.702 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.724 AVG Test Loss:0.701 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.721 AVG Test Loss:0.701 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.718 AVG Test Loss:0.701 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.716 AVG Test Loss:0.701 AVG Training Acc 4.55 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.715 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.714 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.712 AVG Test Loss:0.701 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.711 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.709 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.708 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 36.36 %\n",
            "Epoch:32/50 AVG Training Loss:0.706 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 36.36 %\n",
            "Epoch:33/50 AVG Training Loss:0.705 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 36.36 %\n",
            "Epoch:34/50 AVG Training Loss:0.704 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:35/50 AVG Training Loss:0.703 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:36/50 AVG Training Loss:0.703 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:37/50 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.700 AVG Test Loss:0.702 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.700 AVG Test Loss:0.702 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.699 AVG Test Loss:0.702 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.699 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.698 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.698 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.697 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.697 AVG Test Loss:0.703 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.697 AVG Test Loss:0.703 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.696 AVG Test Loss:0.703 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.696 AVG Test Loss:0.703 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.696 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.81818181818181 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:6.576 AVG Test Loss:0.823 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.117 AVG Test Loss:1.372 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.613 AVG Test Loss:0.844 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:2.084 AVG Test Loss:0.864 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:1.126 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.538 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.211 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.989 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:6.571 AVG Test Loss:0.826 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.118 AVG Test Loss:1.367 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.624 AVG Test Loss:0.836 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:2.092 AVG Test Loss:0.870 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:1.130 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.540 AVG Test Loss:0.891 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.221 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.991 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/8 AVG Training Loss:6.569 AVG Test Loss:0.828 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.118 AVG Test Loss:1.364 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.617 AVG Test Loss:0.832 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:2.085 AVG Test Loss:0.875 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:1.126 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.547 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.221 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.988 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 41.37931034482759 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 41.37931034482759 %\n",
            " Average acc: 41.37931034482759 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:6.576 AVG Test Loss:0.823 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.117 AVG Test Loss:1.372 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.613 AVG Test Loss:0.844 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:2.084 AVG Test Loss:0.864 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.126 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.538 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.211 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.989 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.815 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.643 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.686 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.794 AVG Test Loss:0.713 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.784 AVG Test Loss:0.690 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.686 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.698 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.687 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.711 AVG Test Loss:0.712 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.730 AVG Test Loss:0.706 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:20/20 AVG Training Loss:0.714 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:1/20 AVG Training Loss:6.571 AVG Test Loss:0.826 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.118 AVG Test Loss:1.367 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.624 AVG Test Loss:0.836 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:2.092 AVG Test Loss:0.870 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.130 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.540 AVG Test Loss:0.891 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.221 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.991 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.815 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.642 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.685 AVG Test Loss:0.730 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.794 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.784 AVG Test Loss:0.691 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.684 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.698 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.686 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.710 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.713 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:6.569 AVG Test Loss:0.828 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.118 AVG Test Loss:1.364 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.617 AVG Test Loss:0.832 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:2.085 AVG Test Loss:0.875 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.126 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.547 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.221 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.988 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.814 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.641 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.689 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.796 AVG Test Loss:0.717 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.784 AVG Test Loss:0.697 AVG Training Acc 9.09 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.698 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.711 AVG Test Loss:0.706 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.730 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.713 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            " Average acc: 45.45454545454545 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:6.576 AVG Test Loss:0.823 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.117 AVG Test Loss:1.372 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.613 AVG Test Loss:0.844 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:2.084 AVG Test Loss:0.864 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:1.126 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.538 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.211 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.989 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.815 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.643 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.686 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.794 AVG Test Loss:0.713 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.784 AVG Test Loss:0.690 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.739 AVG Test Loss:0.686 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.698 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:16/50 AVG Training Loss:0.687 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.711 AVG Test Loss:0.712 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.730 AVG Test Loss:0.706 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.727 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:20/50 AVG Training Loss:0.714 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:21/50 AVG Training Loss:0.703 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.702 AVG Test Loss:0.704 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.709 AVG Test Loss:0.706 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.713 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.712 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.704 AVG Test Loss:0.703 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.704 AVG Test Loss:0.705 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.705 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.706 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.703 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.702 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.701 AVG Test Loss:0.706 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.701 AVG Test Loss:0.706 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.701 AVG Test Loss:0.706 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.699 AVG Test Loss:0.707 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.698 AVG Test Loss:0.707 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.698 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.697 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.697 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.695 AVG Test Loss:0.709 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.695 AVG Test Loss:0.709 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.694 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.694 AVG Test Loss:0.710 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.693 AVG Test Loss:0.710 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.692 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.692 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:6.571 AVG Test Loss:0.826 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.118 AVG Test Loss:1.367 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.624 AVG Test Loss:0.836 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:2.092 AVG Test Loss:0.870 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:1.130 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.540 AVG Test Loss:0.891 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.221 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.991 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.815 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.642 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.685 AVG Test Loss:0.730 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.794 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.784 AVG Test Loss:0.691 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:14/50 AVG Training Loss:0.739 AVG Test Loss:0.684 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.698 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.686 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.710 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.727 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.713 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.702 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.701 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.708 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.712 AVG Test Loss:0.703 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.711 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.706 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.702 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.702 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.704 AVG Test Loss:0.706 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.705 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.703 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.701 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.700 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.700 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.699 AVG Test Loss:0.707 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.698 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.697 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.696 AVG Test Loss:0.709 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.695 AVG Test Loss:0.709 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.695 AVG Test Loss:0.709 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.694 AVG Test Loss:0.710 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.693 AVG Test Loss:0.710 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.692 AVG Test Loss:0.711 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.691 AVG Test Loss:0.712 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.691 AVG Test Loss:0.712 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.690 AVG Test Loss:0.712 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.689 AVG Test Loss:0.713 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:6.569 AVG Test Loss:0.828 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.118 AVG Test Loss:1.364 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.617 AVG Test Loss:0.832 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:2.085 AVG Test Loss:0.875 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:1.126 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.547 AVG Test Loss:0.887 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.221 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.988 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.814 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.641 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.689 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.796 AVG Test Loss:0.717 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.784 AVG Test Loss:0.697 AVG Training Acc 9.09 % AVG Test Acc 36.36 %\n",
            "Epoch:14/50 AVG Training Loss:0.739 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.698 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.711 AVG Test Loss:0.706 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.730 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.727 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/50 AVG Training Loss:0.713 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.702 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.702 AVG Test Loss:0.700 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.708 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.713 AVG Test Loss:0.699 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.711 AVG Test Loss:0.697 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.706 AVG Test Loss:0.697 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.703 AVG Test Loss:0.698 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.703 AVG Test Loss:0.700 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.705 AVG Test Loss:0.700 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.705 AVG Test Loss:0.699 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.704 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.702 AVG Test Loss:0.699 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.701 AVG Test Loss:0.699 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.701 AVG Test Loss:0.700 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.700 AVG Test Loss:0.700 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.700 AVG Test Loss:0.699 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.699 AVG Test Loss:0.699 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.698 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.697 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.697 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.695 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.694 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.693 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.692 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.692 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.30769230769231 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 39.743589743589745 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:4.277 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.398 AVG Test Loss:1.089 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.060 AVG Test Loss:0.845 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:1.559 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.941 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.588 AVG Test Loss:0.905 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.234 AVG Test Loss:0.842 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1.068 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:4.196 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.389 AVG Test Loss:1.102 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.123 AVG Test Loss:0.861 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:1.563 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.925 AVG Test Loss:0.718 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.583 AVG Test Loss:0.977 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.247 AVG Test Loss:0.920 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1.071 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:4.272 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.398 AVG Test Loss:1.091 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:3.092 AVG Test Loss:0.851 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:1.585 AVG Test Loss:0.709 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.942 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.593 AVG Test Loss:0.917 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:1.247 AVG Test Loss:0.859 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:1.085 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:4.277 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.398 AVG Test Loss:1.089 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.060 AVG Test Loss:0.845 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.559 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.941 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.588 AVG Test Loss:0.905 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.234 AVG Test Loss:0.842 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.068 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.791 AVG Test Loss:0.690 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.648 AVG Test Loss:0.729 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.698 AVG Test Loss:0.796 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.872 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.837 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.734 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.673 AVG Test Loss:0.727 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.684 AVG Test Loss:0.761 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.765 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.764 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.725 AVG Test Loss:0.726 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.688 AVG Test Loss:0.736 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:4.196 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.389 AVG Test Loss:1.102 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.123 AVG Test Loss:0.861 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.563 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.925 AVG Test Loss:0.718 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.583 AVG Test Loss:0.977 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.247 AVG Test Loss:0.920 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.071 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.782 AVG Test Loss:0.709 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.640 AVG Test Loss:0.793 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.688 AVG Test Loss:0.908 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.867 AVG Test Loss:0.887 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.836 AVG Test Loss:0.797 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.730 AVG Test Loss:0.761 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.666 AVG Test Loss:0.796 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.672 AVG Test Loss:0.863 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.739 AVG Test Loss:0.875 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.759 AVG Test Loss:0.827 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.720 AVG Test Loss:0.787 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.681 AVG Test Loss:0.785 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:4.272 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.398 AVG Test Loss:1.091 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:3.092 AVG Test Loss:0.851 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.585 AVG Test Loss:0.709 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.942 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.593 AVG Test Loss:0.917 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.247 AVG Test Loss:0.859 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.085 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.800 AVG Test Loss:0.693 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.656 AVG Test Loss:0.742 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.705 AVG Test Loss:0.822 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.882 AVG Test Loss:0.797 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.852 AVG Test Loss:0.731 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.710 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.686 AVG Test Loss:0.730 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.693 AVG Test Loss:0.773 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.759 AVG Test Loss:0.783 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.779 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.742 AVG Test Loss:0.732 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.704 AVG Test Loss:0.732 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.001, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:4.277 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.398 AVG Test Loss:1.089 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.060 AVG Test Loss:0.845 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:1.559 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.941 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.588 AVG Test Loss:0.905 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.234 AVG Test Loss:0.842 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1.068 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.791 AVG Test Loss:0.690 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.648 AVG Test Loss:0.729 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.698 AVG Test Loss:0.796 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.872 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.837 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.734 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.673 AVG Test Loss:0.727 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.684 AVG Test Loss:0.761 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.750 AVG Test Loss:0.765 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.764 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.725 AVG Test Loss:0.726 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.688 AVG Test Loss:0.736 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.683 AVG Test Loss:0.764 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.709 AVG Test Loss:0.779 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.723 AVG Test Loss:0.768 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.708 AVG Test Loss:0.761 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.687 AVG Test Loss:0.769 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.681 AVG Test Loss:0.785 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.692 AVG Test Loss:0.792 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.698 AVG Test Loss:0.786 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.688 AVG Test Loss:0.782 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.677 AVG Test Loss:0.790 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.675 AVG Test Loss:0.801 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.679 AVG Test Loss:0.803 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.678 AVG Test Loss:0.799 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.670 AVG Test Loss:0.801 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.664 AVG Test Loss:0.809 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.664 AVG Test Loss:0.814 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.664 AVG Test Loss:0.813 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.659 AVG Test Loss:0.815 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.653 AVG Test Loss:0.820 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.651 AVG Test Loss:0.825 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.649 AVG Test Loss:0.827 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.645 AVG Test Loss:0.829 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.640 AVG Test Loss:0.834 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.637 AVG Test Loss:0.838 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:45/50 AVG Training Loss:0.635 AVG Test Loss:0.840 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:46/50 AVG Training Loss:0.630 AVG Test Loss:0.844 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.626 AVG Test Loss:0.849 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:48/50 AVG Training Loss:0.622 AVG Test Loss:0.853 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:49/50 AVG Training Loss:0.619 AVG Test Loss:0.856 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:50/50 AVG Training Loss:0.614 AVG Test Loss:0.860 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:1/50 AVG Training Loss:4.196 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.389 AVG Test Loss:1.102 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.123 AVG Test Loss:0.861 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:1.563 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.925 AVG Test Loss:0.718 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.583 AVG Test Loss:0.977 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.247 AVG Test Loss:0.920 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1.071 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.782 AVG Test Loss:0.709 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.640 AVG Test Loss:0.793 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.688 AVG Test Loss:0.908 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.867 AVG Test Loss:0.887 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.836 AVG Test Loss:0.797 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.730 AVG Test Loss:0.761 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.666 AVG Test Loss:0.796 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.672 AVG Test Loss:0.863 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.739 AVG Test Loss:0.875 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.759 AVG Test Loss:0.827 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.720 AVG Test Loss:0.787 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.681 AVG Test Loss:0.785 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.673 AVG Test Loss:0.807 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.697 AVG Test Loss:0.811 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.714 AVG Test Loss:0.776 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.701 AVG Test Loss:0.739 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.679 AVG Test Loss:0.730 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.671 AVG Test Loss:0.739 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.681 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.688 AVG Test Loss:0.722 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.680 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.667 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.664 AVG Test Loss:0.707 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.668 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.668 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.661 AVG Test Loss:0.692 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.654 AVG Test Loss:0.694 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.653 AVG Test Loss:0.696 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.653 AVG Test Loss:0.693 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.649 AVG Test Loss:0.690 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.643 AVG Test Loss:0.692 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.640 AVG Test Loss:0.694 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.638 AVG Test Loss:0.693 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.635 AVG Test Loss:0.692 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.629 AVG Test Loss:0.693 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.626 AVG Test Loss:0.695 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.623 AVG Test Loss:0.695 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.619 AVG Test Loss:0.695 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.614 AVG Test Loss:0.696 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.611 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.607 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.602 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:4.272 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.398 AVG Test Loss:1.091 AVG Training Acc 90.91 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:3.092 AVG Test Loss:0.851 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:1.585 AVG Test Loss:0.709 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.942 AVG Test Loss:0.705 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.593 AVG Test Loss:0.917 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:1.247 AVG Test Loss:0.859 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:1.085 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.800 AVG Test Loss:0.693 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:10/50 AVG Training Loss:0.656 AVG Test Loss:0.742 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.705 AVG Test Loss:0.822 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.882 AVG Test Loss:0.797 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.852 AVG Test Loss:0.731 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.748 AVG Test Loss:0.710 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.686 AVG Test Loss:0.730 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.693 AVG Test Loss:0.773 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.759 AVG Test Loss:0.783 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.779 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.742 AVG Test Loss:0.732 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.704 AVG Test Loss:0.732 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.696 AVG Test Loss:0.752 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.719 AVG Test Loss:0.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.737 AVG Test Loss:0.750 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.727 AVG Test Loss:0.733 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.706 AVG Test Loss:0.732 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.697 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.705 AVG Test Loss:0.752 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.714 AVG Test Loss:0.746 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.709 AVG Test Loss:0.737 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.698 AVG Test Loss:0.737 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.692 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.696 AVG Test Loss:0.746 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.698 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.693 AVG Test Loss:0.738 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.686 AVG Test Loss:0.739 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.684 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.685 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.683 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.678 AVG Test Loss:0.739 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.674 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.673 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.671 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.667 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.663 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.661 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.658 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.655 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.651 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.648 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.645 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 35.714285714285715 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.85714285714286 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:1.396 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.557 AVG Test Loss:0.726 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.783 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.914 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.813 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.728 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:7/8 AVG Training Loss:0.684 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.717 AVG Test Loss:0.713 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.399 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.559 AVG Test Loss:0.725 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.786 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.919 AVG Test Loss:0.719 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.816 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:7/8 AVG Training Loss:0.686 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.719 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:1.397 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.557 AVG Test Loss:0.730 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.786 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.918 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.814 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/8 AVG Training Loss:0.728 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:7/8 AVG Training Loss:0.684 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.718 AVG Test Loss:0.717 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 40.00000000000001 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:1.396 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.557 AVG Test Loss:0.726 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.783 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.914 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.813 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.728 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.684 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.717 AVG Test Loss:0.713 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.751 AVG Test Loss:0.702 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.745 AVG Test Loss:0.696 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.716 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.721 AVG Test Loss:0.700 AVG Training Acc 18.18 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.728 AVG Test Loss:0.697 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.728 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.723 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.720 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.720 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.721 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.721 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:1/20 AVG Training Loss:1.399 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.559 AVG Test Loss:0.725 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.786 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.919 AVG Test Loss:0.719 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.816 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:0.686 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.719 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.753 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.748 AVG Test Loss:0.685 AVG Training Acc 4.55 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.685 AVG Training Acc 31.82 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.718 AVG Test Loss:0.689 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.723 AVG Test Loss:0.693 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.730 AVG Test Loss:0.689 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.730 AVG Test Loss:0.685 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.726 AVG Test Loss:0.685 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:0.723 AVG Test Loss:0.686 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:1/20 AVG Training Loss:1.397 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.557 AVG Test Loss:0.730 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.786 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.918 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.814 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.728 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.684 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.718 AVG Test Loss:0.717 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.752 AVG Test Loss:0.718 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.717 AVG Test Loss:0.699 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.722 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.729 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.724 AVG Test Loss:0.700 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.721 AVG Test Loss:0.702 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.721 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.722 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.722 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 48.18181818181817 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:1.396 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.557 AVG Test Loss:0.726 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.783 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.914 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.813 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.728 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:7/50 AVG Training Loss:0.684 AVG Test Loss:0.703 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.717 AVG Test Loss:0.713 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.751 AVG Test Loss:0.702 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.745 AVG Test Loss:0.696 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.726 AVG Test Loss:0.701 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.716 AVG Test Loss:0.702 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:13/50 AVG Training Loss:0.721 AVG Test Loss:0.700 AVG Training Acc 18.18 % AVG Test Acc 36.36 %\n",
            "Epoch:14/50 AVG Training Loss:0.728 AVG Test Loss:0.697 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.728 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 54.55 %\n",
            "Epoch:16/50 AVG Training Loss:0.723 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.720 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.720 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:0.721 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:20/50 AVG Training Loss:0.721 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.719 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:22/50 AVG Training Loss:0.718 AVG Test Loss:0.695 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:0.717 AVG Test Loss:0.695 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:0.717 AVG Test Loss:0.695 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.716 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.715 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.714 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.713 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.713 AVG Test Loss:0.696 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.712 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.711 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.710 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.708 AVG Test Loss:0.697 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.708 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.707 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.706 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.705 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.704 AVG Test Loss:0.698 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.704 AVG Test Loss:0.699 AVG Training Acc 22.73 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.703 AVG Test Loss:0.699 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.702 AVG Test Loss:0.699 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.701 AVG Test Loss:0.699 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.700 AVG Test Loss:0.699 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.700 AVG Test Loss:0.699 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.699 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.698 AVG Test Loss:0.700 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.697 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:1.399 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.559 AVG Test Loss:0.725 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.786 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.919 AVG Test Loss:0.719 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.816 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:7/50 AVG Training Loss:0.686 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.719 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.753 AVG Test Loss:0.705 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.748 AVG Test Loss:0.685 AVG Training Acc 4.55 % AVG Test Acc 63.64 %\n",
            "Epoch:11/50 AVG Training Loss:0.729 AVG Test Loss:0.685 AVG Training Acc 31.82 % AVG Test Acc 63.64 %\n",
            "Epoch:12/50 AVG Training Loss:0.718 AVG Test Loss:0.689 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:13/50 AVG Training Loss:0.723 AVG Test Loss:0.693 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.730 AVG Test Loss:0.689 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.730 AVG Test Loss:0.685 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:16/50 AVG Training Loss:0.726 AVG Test Loss:0.685 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:17/50 AVG Training Loss:0.723 AVG Test Loss:0.686 AVG Training Acc 13.64 % AVG Test Acc 63.64 %\n",
            "Epoch:18/50 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:19/50 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:20/50 AVG Training Loss:0.723 AVG Test Loss:0.687 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:21/50 AVG Training Loss:0.721 AVG Test Loss:0.687 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:22/50 AVG Training Loss:0.720 AVG Test Loss:0.688 AVG Training Acc 18.18 % AVG Test Acc 63.64 %\n",
            "Epoch:23/50 AVG Training Loss:0.719 AVG Test Loss:0.689 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:24/50 AVG Training Loss:0.719 AVG Test Loss:0.689 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:25/50 AVG Training Loss:0.718 AVG Test Loss:0.689 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:26/50 AVG Training Loss:0.717 AVG Test Loss:0.690 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:27/50 AVG Training Loss:0.716 AVG Test Loss:0.690 AVG Training Acc 22.73 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.715 AVG Test Loss:0.691 AVG Training Acc 27.27 % AVG Test Acc 63.64 %\n",
            "Epoch:29/50 AVG Training Loss:0.715 AVG Test Loss:0.691 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.714 AVG Test Loss:0.691 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.713 AVG Test Loss:0.692 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.712 AVG Test Loss:0.692 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.711 AVG Test Loss:0.693 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.710 AVG Test Loss:0.693 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.710 AVG Test Loss:0.694 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.709 AVG Test Loss:0.694 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.708 AVG Test Loss:0.694 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.707 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.706 AVG Test Loss:0.695 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.705 AVG Test Loss:0.696 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.705 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.704 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.703 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.702 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.701 AVG Test Loss:0.697 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.701 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.700 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.699 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.698 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.697 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:1.397 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.557 AVG Test Loss:0.730 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.786 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.918 AVG Test Loss:0.721 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.814 AVG Test Loss:0.693 AVG Training Acc 13.64 % AVG Test Acc 54.55 %\n",
            "Epoch:6/50 AVG Training Loss:0.728 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:7/50 AVG Training Loss:0.684 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.718 AVG Test Loss:0.717 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.752 AVG Test Loss:0.718 AVG Training Acc 36.36 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.727 AVG Test Loss:0.696 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:12/50 AVG Training Loss:0.717 AVG Test Loss:0.699 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.722 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.729 AVG Test Loss:0.701 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.724 AVG Test Loss:0.700 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.721 AVG Test Loss:0.702 AVG Training Acc 13.64 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.721 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.722 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.722 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.720 AVG Test Loss:0.702 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.719 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.718 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.717 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.717 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.716 AVG Test Loss:0.703 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.715 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.713 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.712 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.712 AVG Test Loss:0.704 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.711 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.709 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:35/50 AVG Training Loss:0.708 AVG Test Loss:0.705 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:36/50 AVG Training Loss:0.707 AVG Test Loss:0.705 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:37/50 AVG Training Loss:0.707 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:38/50 AVG Training Loss:0.706 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:39/50 AVG Training Loss:0.705 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:40/50 AVG Training Loss:0.704 AVG Test Loss:0.706 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:41/50 AVG Training Loss:0.703 AVG Test Loss:0.706 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:42/50 AVG Training Loss:0.703 AVG Test Loss:0.706 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:43/50 AVG Training Loss:0.702 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:44/50 AVG Training Loss:0.701 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:45/50 AVG Training Loss:0.700 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:46/50 AVG Training Loss:0.699 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.698 AVG Test Loss:0.707 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:48/50 AVG Training Loss:0.698 AVG Test Loss:0.708 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:49/50 AVG Training Loss:0.697 AVG Test Loss:0.708 AVG Training Acc 45.45 % AVG Test Acc 36.36 %\n",
            "Epoch:50/50 AVG Training Loss:0.696 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.0 %\n",
            "Fold 2 acc: 35.0 %\n",
            " Average acc: 41.81818181818181 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:1.169 AVG Test Loss:0.687 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.665 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.632 AVG Test Loss:0.734 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.790 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.821 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.775 AVG Test Loss:0.698 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/8 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:1/8 AVG Training Loss:1.170 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.667 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.634 AVG Test Loss:0.732 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.824 AVG Test Loss:0.722 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.778 AVG Test Loss:0.700 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.738 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/8 AVG Training Loss:0.708 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:1/8 AVG Training Loss:1.170 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.665 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.633 AVG Test Loss:0.735 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.822 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.706 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            " Average acc: 39.393939393939384 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:1.169 AVG Test Loss:0.687 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.665 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.632 AVG Test Loss:0.734 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.790 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.821 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.775 AVG Test Loss:0.698 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.706 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.720 AVG Test Loss:0.707 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.721 AVG Test Loss:0.698 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.715 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.707 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.701 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.699 AVG Test Loss:0.704 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.705 AVG Test Loss:0.700 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.706 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:1.170 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.667 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.634 AVG Test Loss:0.732 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.824 AVG Test Loss:0.722 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.778 AVG Test Loss:0.700 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.738 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.708 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.687 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.690 AVG Test Loss:0.709 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.722 AVG Test Loss:0.712 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.724 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.717 AVG Test Loss:0.689 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.709 AVG Test Loss:0.681 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.703 AVG Test Loss:0.682 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.687 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:0.704 AVG Test Loss:0.688 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.707 AVG Test Loss:0.689 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.708 AVG Test Loss:0.687 AVG Training Acc 27.27 % AVG Test Acc 63.64 %\n",
            "Epoch:1/20 AVG Training Loss:1.170 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.665 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.633 AVG Test Loss:0.735 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.822 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.706 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.685 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.707 AVG Test Loss:0.704 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.721 AVG Test Loss:0.708 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.722 AVG Test Loss:0.711 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.715 AVG Test Loss:0.705 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.707 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.701 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.703 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.706 AVG Test Loss:0.700 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.707 AVG Test Loss:0.699 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 46.15384615384615 %\n",
            "Fold 2 acc: 42.30769230769231 %\n",
            " Average acc: 44.63869463869464 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:1.169 AVG Test Loss:0.687 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.665 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.632 AVG Test Loss:0.734 AVG Training Acc 68.18 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.790 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.821 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.775 AVG Test Loss:0.698 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/50 AVG Training Loss:0.706 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:9/50 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.688 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.706 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.720 AVG Test Loss:0.707 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.721 AVG Test Loss:0.698 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.715 AVG Test Loss:0.694 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.707 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:16/50 AVG Training Loss:0.701 AVG Test Loss:0.702 AVG Training Acc 40.91 % AVG Test Acc 36.36 %\n",
            "Epoch:17/50 AVG Training Loss:0.699 AVG Test Loss:0.704 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.702 AVG Test Loss:0.703 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.705 AVG Test Loss:0.700 AVG Training Acc 27.27 % AVG Test Acc 36.36 %\n",
            "Epoch:20/50 AVG Training Loss:0.706 AVG Test Loss:0.697 AVG Training Acc 27.27 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.705 AVG Test Loss:0.695 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.703 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:23/50 AVG Training Loss:0.701 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:24/50 AVG Training Loss:0.700 AVG Test Loss:0.695 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.700 AVG Test Loss:0.695 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:26/50 AVG Training Loss:0.700 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:27/50 AVG Training Loss:0.700 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:28/50 AVG Training Loss:0.700 AVG Test Loss:0.695 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.699 AVG Test Loss:0.695 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.698 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.696 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.696 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.695 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.695 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.693 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.693 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.692 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.692 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.691 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.689 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.689 AVG Test Loss:0.699 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.688 AVG Test Loss:0.699 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.688 AVG Test Loss:0.700 AVG Training Acc 63.64 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.687 AVG Test Loss:0.700 AVG Training Acc 68.18 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:1.170 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.667 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.634 AVG Test Loss:0.732 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.824 AVG Test Loss:0.722 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.778 AVG Test Loss:0.700 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.738 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/50 AVG Training Loss:0.708 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:9/50 AVG Training Loss:0.687 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.690 AVG Test Loss:0.709 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.722 AVG Test Loss:0.712 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.724 AVG Test Loss:0.704 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.717 AVG Test Loss:0.689 AVG Training Acc 18.18 % AVG Test Acc 54.55 %\n",
            "Epoch:15/50 AVG Training Loss:0.709 AVG Test Loss:0.681 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/50 AVG Training Loss:0.703 AVG Test Loss:0.682 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:17/50 AVG Training Loss:0.702 AVG Test Loss:0.687 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:18/50 AVG Training Loss:0.704 AVG Test Loss:0.688 AVG Training Acc 31.82 % AVG Test Acc 54.55 %\n",
            "Epoch:19/50 AVG Training Loss:0.707 AVG Test Loss:0.689 AVG Training Acc 27.27 % AVG Test Acc 54.55 %\n",
            "Epoch:20/50 AVG Training Loss:0.708 AVG Test Loss:0.687 AVG Training Acc 27.27 % AVG Test Acc 63.64 %\n",
            "Epoch:21/50 AVG Training Loss:0.708 AVG Test Loss:0.684 AVG Training Acc 31.82 % AVG Test Acc 63.64 %\n",
            "Epoch:22/50 AVG Training Loss:0.705 AVG Test Loss:0.682 AVG Training Acc 31.82 % AVG Test Acc 63.64 %\n",
            "Epoch:23/50 AVG Training Loss:0.703 AVG Test Loss:0.682 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:24/50 AVG Training Loss:0.702 AVG Test Loss:0.683 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:25/50 AVG Training Loss:0.702 AVG Test Loss:0.684 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:26/50 AVG Training Loss:0.702 AVG Test Loss:0.684 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:27/50 AVG Training Loss:0.702 AVG Test Loss:0.685 AVG Training Acc 31.82 % AVG Test Acc 63.64 %\n",
            "Epoch:28/50 AVG Training Loss:0.702 AVG Test Loss:0.684 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:29/50 AVG Training Loss:0.701 AVG Test Loss:0.684 AVG Training Acc 36.36 % AVG Test Acc 63.64 %\n",
            "Epoch:30/50 AVG Training Loss:0.700 AVG Test Loss:0.685 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:31/50 AVG Training Loss:0.699 AVG Test Loss:0.685 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:32/50 AVG Training Loss:0.699 AVG Test Loss:0.685 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:33/50 AVG Training Loss:0.698 AVG Test Loss:0.686 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:34/50 AVG Training Loss:0.698 AVG Test Loss:0.686 AVG Training Acc 40.91 % AVG Test Acc 63.64 %\n",
            "Epoch:35/50 AVG Training Loss:0.697 AVG Test Loss:0.686 AVG Training Acc 45.45 % AVG Test Acc 63.64 %\n",
            "Epoch:36/50 AVG Training Loss:0.697 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:37/50 AVG Training Loss:0.696 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:38/50 AVG Training Loss:0.695 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:39/50 AVG Training Loss:0.695 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:40/50 AVG Training Loss:0.694 AVG Test Loss:0.688 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:41/50 AVG Training Loss:0.694 AVG Test Loss:0.688 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:42/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:43/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:44/50 AVG Training Loss:0.692 AVG Test Loss:0.689 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:45/50 AVG Training Loss:0.691 AVG Test Loss:0.689 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:46/50 AVG Training Loss:0.691 AVG Test Loss:0.690 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:47/50 AVG Training Loss:0.690 AVG Test Loss:0.690 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:48/50 AVG Training Loss:0.690 AVG Test Loss:0.690 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:49/50 AVG Training Loss:0.689 AVG Test Loss:0.691 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:50/50 AVG Training Loss:0.688 AVG Test Loss:0.691 AVG Training Acc 59.09 % AVG Test Acc 63.64 %\n",
            "Epoch:1/50 AVG Training Loss:1.170 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.665 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.633 AVG Test Loss:0.735 AVG Training Acc 72.73 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.792 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.822 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 18.18 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.706 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:9/50 AVG Training Loss:0.685 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.689 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.707 AVG Test Loss:0.704 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.721 AVG Test Loss:0.708 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.722 AVG Test Loss:0.711 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.715 AVG Test Loss:0.705 AVG Training Acc 22.73 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.707 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.701 AVG Test Loss:0.696 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:17/50 AVG Training Loss:0.700 AVG Test Loss:0.697 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.703 AVG Test Loss:0.698 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.706 AVG Test Loss:0.700 AVG Training Acc 31.82 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.707 AVG Test Loss:0.699 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:21/50 AVG Training Loss:0.706 AVG Test Loss:0.698 AVG Training Acc 31.82 % AVG Test Acc 36.36 %\n",
            "Epoch:22/50 AVG Training Loss:0.704 AVG Test Loss:0.698 AVG Training Acc 36.36 % AVG Test Acc 36.36 %\n",
            "Epoch:23/50 AVG Training Loss:0.702 AVG Test Loss:0.698 AVG Training Acc 36.36 % AVG Test Acc 36.36 %\n",
            "Epoch:24/50 AVG Training Loss:0.701 AVG Test Loss:0.699 AVG Training Acc 36.36 % AVG Test Acc 54.55 %\n",
            "Epoch:25/50 AVG Training Loss:0.700 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.701 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.701 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.700 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:29/50 AVG Training Loss:0.699 AVG Test Loss:0.699 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.698 AVG Test Loss:0.699 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.698 AVG Test Loss:0.700 AVG Training Acc 40.91 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.697 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.697 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.696 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.695 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.694 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.693 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.693 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.692 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.692 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 59.09 % AVG Test Acc 36.36 %\n",
            "Epoch:44/50 AVG Training Loss:0.690 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 36.36 %\n",
            "Epoch:45/50 AVG Training Loss:0.690 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 36.36 %\n",
            "Epoch:46/50 AVG Training Loss:0.689 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 36.36 %\n",
            "Epoch:47/50 AVG Training Loss:0.689 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 36.36 %\n",
            "Epoch:48/50 AVG Training Loss:0.688 AVG Test Loss:0.701 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "Epoch:49/50 AVG Training Loss:0.688 AVG Test Loss:0.701 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "Epoch:50/50 AVG Training Loss:0.687 AVG Test Loss:0.701 AVG Training Acc 68.18 % AVG Test Acc 36.36 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 46.15384615384615 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            " Average acc: 45.6876456876457 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.919 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.714 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.850 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.878 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.827 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.764 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.723 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.912 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.715 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.854 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.884 AVG Test Loss:0.759 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.832 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.767 AVG Test Loss:0.726 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.724 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.919 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.637 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.717 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.857 AVG Test Loss:0.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.887 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.834 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.770 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.727 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.919 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.714 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.850 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.878 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.827 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.764 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.723 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.701 AVG Test Loss:0.714 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.695 AVG Test Loss:0.722 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.724 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.741 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.743 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.732 AVG Test Loss:0.730 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.721 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.710 AVG Test Loss:0.731 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.710 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:0.912 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.854 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.884 AVG Test Loss:0.759 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.832 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.767 AVG Test Loss:0.726 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.724 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.701 AVG Test Loss:0.725 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.695 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.705 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.725 AVG Test Loss:0.772 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.743 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.744 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.732 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.721 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.712 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.710 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/20 AVG Training Loss:0.919 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.637 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.717 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.857 AVG Test Loss:0.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.887 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.834 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.770 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.727 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.704 AVG Test Loss:0.716 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.698 AVG Test Loss:0.727 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.708 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.729 AVG Test Loss:0.746 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.747 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.754 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.750 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.739 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.727 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.719 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.716 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.717 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 0.0001, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.919 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.714 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.850 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.878 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.827 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.764 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.723 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.701 AVG Test Loss:0.714 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.695 AVG Test Loss:0.722 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.704 AVG Test Loss:0.732 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.724 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.741 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.748 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.743 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.732 AVG Test Loss:0.730 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.721 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.710 AVG Test Loss:0.731 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.710 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.714 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.717 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.719 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.718 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.715 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.711 AVG Test Loss:0.743 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.708 AVG Test Loss:0.743 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.706 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.705 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.705 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.705 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.705 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.704 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.702 AVG Test Loss:0.747 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.701 AVG Test Loss:0.747 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.699 AVG Test Loss:0.747 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.697 AVG Test Loss:0.748 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.696 AVG Test Loss:0.748 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.695 AVG Test Loss:0.749 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.694 AVG Test Loss:0.750 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.693 AVG Test Loss:0.750 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.692 AVG Test Loss:0.751 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.691 AVG Test Loss:0.751 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.690 AVG Test Loss:0.751 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.689 AVG Test Loss:0.752 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.687 AVG Test Loss:0.752 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.686 AVG Test Loss:0.753 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.685 AVG Test Loss:0.753 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.684 AVG Test Loss:0.754 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.683 AVG Test Loss:0.754 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:1/50 AVG Training Loss:0.912 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.638 AVG Test Loss:0.707 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.715 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.854 AVG Test Loss:0.763 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.884 AVG Test Loss:0.759 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.832 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.767 AVG Test Loss:0.726 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.724 AVG Test Loss:0.720 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.701 AVG Test Loss:0.725 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.695 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.705 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.725 AVG Test Loss:0.772 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.743 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.749 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.744 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.732 AVG Test Loss:0.760 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.721 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.712 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.709 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.710 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.713 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.716 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.718 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.716 AVG Test Loss:0.725 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.713 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.710 AVG Test Loss:0.713 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.706 AVG Test Loss:0.710 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.704 AVG Test Loss:0.706 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.703 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:30/50 AVG Training Loss:0.703 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:31/50 AVG Training Loss:0.702 AVG Test Loss:0.700 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:32/50 AVG Training Loss:0.702 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:33/50 AVG Training Loss:0.701 AVG Test Loss:0.696 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:34/50 AVG Training Loss:0.699 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:35/50 AVG Training Loss:0.697 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:36/50 AVG Training Loss:0.696 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:37/50 AVG Training Loss:0.694 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:38/50 AVG Training Loss:0.693 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:39/50 AVG Training Loss:0.692 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:40/50 AVG Training Loss:0.691 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:41/50 AVG Training Loss:0.690 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:42/50 AVG Training Loss:0.689 AVG Test Loss:0.686 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:43/50 AVG Training Loss:0.687 AVG Test Loss:0.685 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:44/50 AVG Training Loss:0.686 AVG Test Loss:0.685 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:45/50 AVG Training Loss:0.685 AVG Test Loss:0.684 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:46/50 AVG Training Loss:0.683 AVG Test Loss:0.683 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:47/50 AVG Training Loss:0.682 AVG Test Loss:0.683 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:48/50 AVG Training Loss:0.681 AVG Test Loss:0.682 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:49/50 AVG Training Loss:0.680 AVG Test Loss:0.682 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:50/50 AVG Training Loss:0.678 AVG Test Loss:0.681 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:1/50 AVG Training Loss:0.919 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.637 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.717 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.857 AVG Test Loss:0.764 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.887 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.834 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.770 AVG Test Loss:0.723 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.727 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.704 AVG Test Loss:0.716 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.698 AVG Test Loss:0.727 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.708 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:12/50 AVG Training Loss:0.729 AVG Test Loss:0.746 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:13/50 AVG Training Loss:0.747 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:14/50 AVG Training Loss:0.754 AVG Test Loss:0.742 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:15/50 AVG Training Loss:0.750 AVG Test Loss:0.733 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:16/50 AVG Training Loss:0.739 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:17/50 AVG Training Loss:0.727 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:18/50 AVG Training Loss:0.719 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:19/50 AVG Training Loss:0.716 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:20/50 AVG Training Loss:0.717 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:21/50 AVG Training Loss:0.721 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:22/50 AVG Training Loss:0.725 AVG Test Loss:0.743 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:23/50 AVG Training Loss:0.726 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:24/50 AVG Training Loss:0.726 AVG Test Loss:0.739 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:25/50 AVG Training Loss:0.723 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:26/50 AVG Training Loss:0.720 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:27/50 AVG Training Loss:0.717 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:28/50 AVG Training Loss:0.715 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:29/50 AVG Training Loss:0.714 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:30/50 AVG Training Loss:0.714 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:31/50 AVG Training Loss:0.714 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:32/50 AVG Training Loss:0.714 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:33/50 AVG Training Loss:0.713 AVG Test Loss:0.738 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:34/50 AVG Training Loss:0.712 AVG Test Loss:0.737 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:35/50 AVG Training Loss:0.711 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:36/50 AVG Training Loss:0.709 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:37/50 AVG Training Loss:0.708 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:38/50 AVG Training Loss:0.707 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:39/50 AVG Training Loss:0.706 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:40/50 AVG Training Loss:0.705 AVG Test Loss:0.736 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:41/50 AVG Training Loss:0.705 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:42/50 AVG Training Loss:0.704 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:43/50 AVG Training Loss:0.703 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:44/50 AVG Training Loss:0.702 AVG Test Loss:0.735 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:45/50 AVG Training Loss:0.701 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:46/50 AVG Training Loss:0.700 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:47/50 AVG Training Loss:0.699 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:48/50 AVG Training Loss:0.698 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:49/50 AVG Training Loss:0.697 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:50/50 AVG Training Loss:0.696 AVG Test Loss:0.734 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 45.23809523809524 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.741 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.696 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/8 AVG Training Loss:0.687 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:4/8 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.743 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.698 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:3/8 AVG Training Loss:0.689 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.686 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.688 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.693 AVG Test Loss:0.705 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/8 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 40.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 40.00000000000001 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.741 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.696 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.687 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.692 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.743 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.698 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.689 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.686 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.688 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.693 AVG Test Loss:0.705 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.696 AVG Test Loss:0.684 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.695 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 45.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.66666666666667 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 4, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.741 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.696 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/50 AVG Training Loss:0.687 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:4/50 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.692 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.694 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.743 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.698 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:3/50 AVG Training Loss:0.689 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.686 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.686 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.688 AVG Test Loss:0.706 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.690 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.693 AVG Test Loss:0.705 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.695 AVG Test Loss:0.696 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.696 AVG Test Loss:0.684 AVG Training Acc 45.45 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.697 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.688 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/50 AVG Training Loss:0.684 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.691 AVG Test Loss:0.701 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.695 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 40.0 %\n",
            "Fold 1 acc: 45.0 %\n",
            "Fold 2 acc: 40.0 %\n",
            " Average acc: 41.66666666666667 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.723 AVG Test Loss:0.691 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:2/8 AVG Training Loss:0.693 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/8 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.685 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.684 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/8 AVG Training Loss:0.695 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/8 AVG Training Loss:0.690 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/8 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:5/8 AVG Training Loss:0.686 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.687 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.688 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:1/8 AVG Training Loss:0.724 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/8 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:3/8 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/8 AVG Training Loss:0.686 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.686 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.723 AVG Test Loss:0.691 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:2/20 AVG Training Loss:0.693 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.685 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.684 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.686 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.688 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.689 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.695 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.690 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.686 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.687 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.688 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.689 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.690 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.691 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.724 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.686 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.686 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.687 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.689 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.690 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 6, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.723 AVG Test Loss:0.691 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:2/50 AVG Training Loss:0.693 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/50 AVG Training Loss:0.688 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.685 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.684 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.684 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.685 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.686 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.688 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.689 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.726 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/50 AVG Training Loss:0.695 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:3/50 AVG Training Loss:0.690 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:4/50 AVG Training Loss:0.688 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:5/50 AVG Training Loss:0.686 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.686 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.687 AVG Test Loss:0.699 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.688 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.689 AVG Test Loss:0.708 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.690 AVG Test Loss:0.702 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.691 AVG Test Loss:0.699 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.724 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 63.64 %\n",
            "Epoch:2/50 AVG Training Loss:0.694 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 27.27 %\n",
            "Epoch:3/50 AVG Training Loss:0.689 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 36.36 %\n",
            "Epoch:4/50 AVG Training Loss:0.686 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.685 AVG Test Loss:0.700 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.686 AVG Test Loss:0.701 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:9/50 AVG Training Loss:0.687 AVG Test Loss:0.698 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:10/50 AVG Training Loss:0.689 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:11/50 AVG Training Loss:0.690 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            " Average acc: 38.46153846153847 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 8}\n",
            "Epoch:1/8 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.682 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.688 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.698 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/8 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/8 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.683 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.691 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.696 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.701 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/8 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/8 AVG Training Loss:0.684 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/8 AVG Training Loss:0.682 AVG Test Loss:0.700 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/8 AVG Training Loss:0.682 AVG Test Loss:0.703 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/8 AVG Training Loss:0.685 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/8 AVG Training Loss:0.689 AVG Test Loss:0.711 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/8 AVG Training Loss:0.694 AVG Test Loss:0.716 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/8 AVG Training Loss:0.700 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.682 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.688 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.683 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.691 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.696 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.701 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/20 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.684 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.682 AVG Test Loss:0.700 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.682 AVG Test Loss:0.703 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.685 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.689 AVG Test Loss:0.711 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.694 AVG Test Loss:0.716 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.700 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "current p: {'learning_rate': 1e-05, 'batch_size': 10, 'num_epochs': 50}\n",
            "Epoch:1/50 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:0.684 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.682 AVG Test Loss:0.701 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.688 AVG Test Loss:0.708 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.693 AVG Test Loss:0.711 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.698 AVG Test Loss:0.715 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:2/50 AVG Training Loss:0.684 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.682 AVG Test Loss:0.697 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.683 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.686 AVG Test Loss:0.704 AVG Training Acc 59.09 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.691 AVG Test Loss:0.708 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.696 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.701 AVG Test Loss:0.716 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Epoch:1/50 AVG Training Loss:0.705 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 54.55 %\n",
            "Epoch:2/50 AVG Training Loss:0.684 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:3/50 AVG Training Loss:0.682 AVG Test Loss:0.700 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:4/50 AVG Training Loss:0.682 AVG Test Loss:0.703 AVG Training Acc 63.64 % AVG Test Acc 45.45 %\n",
            "Epoch:5/50 AVG Training Loss:0.685 AVG Test Loss:0.707 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/50 AVG Training Loss:0.689 AVG Test Loss:0.711 AVG Training Acc 54.55 % AVG Test Acc 45.45 %\n",
            "Epoch:7/50 AVG Training Loss:0.694 AVG Test Loss:0.716 AVG Training Acc 40.91 % AVG Test Acc 45.45 %\n",
            "Epoch:8/50 AVG Training Loss:0.700 AVG Test Loss:0.718 AVG Training Acc 45.45 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 42.857142857142854 %\n",
            "Fold 1 acc: 42.857142857142854 %\n",
            "Fold 2 acc: 42.857142857142854 %\n",
            " Average acc: 42.857142857142854 %\n",
            "grid_param: {'learning_rate': [0.1, 0.01, 0.001, 0.0001, 1e-05], 'batch_size': [4, 6, 10], 'num_epochs': [8, 20, 50]}  grid: [[[0.42318841 0.4115942  0.39710145]\n",
            "  [0.38461538 0.38461538 0.38461538]\n",
            "  [0.42857143 0.54545455 0.43939394]]\n",
            "\n",
            " [[0.43478261 0.4        0.41666667]\n",
            "  [0.38461538 0.38461538 0.38461538]\n",
            "  [0.54545455 0.42857143 0.45238095]]\n",
            "\n",
            " [[0.4        0.4        0.41818182]\n",
            "  [0.4137931  0.45454545 0.3974359 ]\n",
            "  [0.42857143 0.42857143 0.42857143]]\n",
            "\n",
            " [[0.4        0.48181818 0.41818182]\n",
            "  [0.39393939 0.44638695 0.45687646]\n",
            "  [0.42857143 0.42857143 0.45238095]]\n",
            "\n",
            " [[0.4        0.41666667 0.41666667]\n",
            "  [0.38461538 0.38461538 0.38461538]\n",
            "  [0.42857143 0.42857143 0.42857143]]]\n",
            "best: 0.5454545454545454 best_idx: (0, 2, 1)\n",
            "best params: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 20}\n",
            "Running final learning session for Fold(outher): 4  with best_params: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 20}\n",
            "Epoch:1/20 AVG Training Loss:1499.288 AVG Test Loss:576.468 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:2239.580 AVG Test Loss:215.744 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:341.779 AVG Test Loss:22.066 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:89.240 AVG Test Loss:93.927 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:186.635 AVG Test Loss:211.084 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:608.001 AVG Test Loss:170.298 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:201.077 AVG Test Loss:51.719 AVG Training Acc 33.33 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:45.707 AVG Test Loss:37.883 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:20.247 AVG Test Loss:30.205 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:84.650 AVG Test Loss:125.976 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:167.766 AVG Test Loss:36.853 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:43.574 AVG Test Loss:59.284 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:106.798 AVG Test Loss:7.981 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:15.324 AVG Test Loss:7.660 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:47.398 AVG Test Loss:55.150 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:51.821 AVG Test Loss:31.475 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:41.670 AVG Test Loss:53.983 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:21.783 AVG Test Loss:70.374 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:19/20 AVG Training Loss:59.767 AVG Test Loss:17.241 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:30.587 AVG Test Loss:23.853 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 53.63636363636364 %\n",
            "Final best params: {0: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}, 1: {'learning_rate': 0.0001, 'batch_size': 6, 'num_epochs': 8}, 2: {'learning_rate': 0.001, 'batch_size': 6, 'num_epochs': 20}, 3: {'learning_rate': 0.1, 'batch_size': 10, 'num_epochs': 20}}\n"
          ]
        }
      ],
      "source": [
        "#grid search (double cross validation)\n",
        "\n",
        "pretrained = False\n",
        "dropout = 0.0\n",
        "\n",
        "resnet_model = prepare_resnet_model(pretrained, dropout)\n",
        "\n",
        "dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "out_results, out_best_params, trained_models = folds_loop_double(dataset, criterion, grid_param, splits, True)\n",
        "print_and_save_folds_results(out_results, out_best_params, SPREEDSHEET_NAME_FINAL, {'resnet': True, 'pretrained': pretrained, 'dropout': dropout})\n",
        "print(\"Final best params:\", out_best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQvU9L2u02On"
      },
      "source": [
        "# [Heart images] Network with cross validation\n",
        "(network on hearts only)\n",
        "[Notebook used from heart extraction](https://colab.research.google.com/drive/1PtqREGfe-oRDVahObBPgkDkY7rt2Q08j?authuser=1#scrollTo=Lp-Yfm5tJHB-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0QwpM2u7QqN"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrWplvDl1Urk"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {\n",
        "    'learning_rate': [0.001],\n",
        "    'batch_size': [4], \n",
        "    'dropout': [0.0],\n",
        "    'num_epochs': [30],\n",
        "    'number_of_linear_layers': [2], \n",
        "    'l1_regularization_lambda': [0.0], \n",
        "    'l2_regularization_lambda': [0.0],\n",
        "    'number_of_conv_layers': [2], \n",
        "    'number_of_filers': [3], \n",
        "    'pooling': [True],\n",
        "    'batch_norm': [True],\n",
        "    'shape_info': [False]\n",
        "}\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjlsaeU51hdC"
      },
      "outputs": [],
      "source": [
        "#trianing (without grid search)\n",
        "\n",
        "dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, False)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "def model_getter():\n",
        "  return Net(current_params, 1, dataset.image_list[0].shape[0])\n",
        "\n",
        "results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q_GH0hLv0Rg"
      },
      "outputs": [],
      "source": [
        "#trianing (without grid search) a lot of times\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),                                  \n",
        "      #transforms.RandomHorizontalFlip(p=0.0),\n",
        "      #transforms.RandomRotation(degrees=(-1*30, 30)),\n",
        "      #transforms.RandomAffine(degrees=0, scale=(1.0-0.1, 1.0+0.1), shear=0),\n",
        "      #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "      #transforms.RandomVerticalFlip(p=0),\n",
        "      transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "times = 10\n",
        "final_acc = []\n",
        "\n",
        "for _ in range(times):\n",
        "  #trianing (without grid search)\n",
        "\n",
        "  dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, False)\n",
        "  print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "  splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "  def model_getter():\n",
        "    return Net(current_params, 1, dataset.image_list[0].shape[0])\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "  acc = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)\n",
        "  final_acc.append(acc)\n",
        "print(\"Runed \", times, \" times. Results:\", final_acc, \" avg:\", np.mean(final_acc), \" std:\", np.std(final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmrt0gf-CJsW"
      },
      "outputs": [],
      "source": [
        "#grid search (double cross validation)\n",
        "\n",
        "dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, False)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "out_results, out_best_params, trained_models = folds_loop_double(dataset, criterion, grid_param, splits)\n",
        "print_and_save_folds_results(out_results, out_best_params, SPREEDSHEET_NAME_FINAL)\n",
        "print(\"Final best params:\", out_best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrX1P3wuA_Qd"
      },
      "source": [
        "RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "intOyeLIBAsQ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {\n",
        "    'learning_rate': [0.000001],\n",
        "    'batch_size': [6], \n",
        "    'num_epochs': [20]\n",
        "}\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s60lph5D2nE1"
      },
      "outputs": [],
      "source": [
        "#trianing resnet (without grid search)\n",
        "\n",
        "dropout = 0.0\n",
        "pretrained = True\n",
        "resnet_model = prepare_resnet_model(pretrained, dropout)\n",
        "\n",
        "dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4)#, shuffle=True, random_state=42) \n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "def model_getter():\n",
        "  return copy.deepcopy(resnet_model)\n",
        "\n",
        "results = folds_loop(model_getter, dataset, criterion, current_params, splits, True)\n",
        "print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL, {'resnet': True, 'pretrained': pretrained, 'dropout': dropout})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trianing (without grid search) a lot of times\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),                                  \n",
        "      #transforms.RandomHorizontalFlip(p=0.0),\n",
        "      #transforms.RandomRotation(degrees=(-1*30, 30)),\n",
        "      #transforms.RandomAffine(degrees=0, scale=(1.0-0.4, 1.0+0.4), shear=0),\n",
        "      #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "      #transforms.RandomVerticalFlip(p=0),\n",
        "      transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "times = 10\n",
        "final_acc = []\n",
        "\n",
        "dropout = 0.0\n",
        "pretrained = False\n",
        "resnet_model = prepare_resnet_model(pretrained, dropout)\n",
        "\n",
        "dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "def model_getter():\n",
        "  return copy.deepcopy(resnet_model)\n",
        "\n",
        "for _ in range(times):\n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits, True)\n",
        "  acc = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL)\n",
        "  final_acc.append(acc)\n",
        "print(\"Runed \", times, \" times. Results:\", final_acc, \" avg:\", np.mean(final_acc), \" std:\", np.std(final_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpFuT6Cy_g3l",
        "outputId": "67ab8494-1755-4b35-84f0-3485c3e5833d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 43  img shape: (50, 50, 3)\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.708 AVG Test Loss:0.696 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.702 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.701 AVG Test Loss:0.701 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.700 AVG Test Loss:0.706 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.699 AVG Test Loss:0.683 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.699 AVG Test Loss:0.672 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.698 AVG Test Loss:0.682 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.698 AVG Test Loss:0.639 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.697 AVG Test Loss:0.632 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:0.697 AVG Test Loss:0.635 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.697 AVG Test Loss:0.629 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.696 AVG Test Loss:0.644 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:0.696 AVG Test Loss:0.653 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:0.696 AVG Test Loss:0.651 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:0.695 AVG Test Loss:0.650 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:0.695 AVG Test Loss:0.649 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 40.62 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:0.695 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:0.694 AVG Test Loss:0.648 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:0.694 AVG Test Loss:0.647 AVG Training Acc 37.50 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.715 AVG Test Loss:0.697 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.710 AVG Test Loss:0.705 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:3/20 AVG Training Loss:0.708 AVG Test Loss:0.709 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.707 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.707 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.706 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.706 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.705 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.705 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.705 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.704 AVG Test Loss:0.723 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.704 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.703 AVG Test Loss:0.740 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.703 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.702 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.702 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.712 AVG Test Loss:0.689 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:0.706 AVG Test Loss:0.687 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.705 AVG Test Loss:0.678 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.704 AVG Test Loss:0.675 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.704 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.703 AVG Test Loss:0.691 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.703 AVG Test Loss:0.674 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.703 AVG Test Loss:0.710 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.702 AVG Test Loss:0.706 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.702 AVG Test Loss:0.711 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.702 AVG Test Loss:0.730 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.701 AVG Test Loss:0.737 AVG Training Acc 34.38 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:0.701 AVG Test Loss:0.741 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.701 AVG Test Loss:0.744 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:0.700 AVG Test Loss:0.742 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.699 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.722 AVG Test Loss:0.695 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.716 AVG Test Loss:0.698 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.715 AVG Test Loss:0.702 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.714 AVG Test Loss:0.704 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.713 AVG Test Loss:0.725 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.713 AVG Test Loss:0.748 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.713 AVG Test Loss:0.750 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.712 AVG Test Loss:0.740 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.712 AVG Test Loss:0.693 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.711 AVG Test Loss:0.689 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.711 AVG Test Loss:0.686 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.711 AVG Test Loss:0.675 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.711 AVG Test Loss:0.685 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.710 AVG Test Loss:0.691 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.710 AVG Test Loss:0.695 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.710 AVG Test Loss:0.696 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.709 AVG Test Loss:0.698 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.709 AVG Test Loss:0.697 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 57.692307692307686 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 47.37762237762237 %\n",
            "Runed  10  times. Results: [0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375, 0.47377622377622375]  avg: 0.47377622377622364  std: 1.1102230246251565e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x-BZ_q03BO_j"
      },
      "outputs": [],
      "source": [
        "#grid search resnet (double cross validation)\n",
        "dropout = 0.0\n",
        "pretrained=False\n",
        "resnet_model = prepare_resnet_model(pretrained, dropout)\n",
        "\n",
        "dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, True)\n",
        "print(\"Train dataset size:\", len(dataset), \" img shape:\", dataset.image_list[0].shape)\n",
        "\n",
        "splitter = StratifiedKFold(n_splits=4) #, shuffle=True, random_state=42)\n",
        "splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "out_results, out_best_params, trained_models = folds_loop_double(dataset, criterion, grid_param, splits, True)\n",
        "print_and_save_folds_results(out_results, out_best_params, SPREEDSHEET_NAME_FINAL, {'resnet': True, 'pretrained': pretrained, 'dropout': dropout})\n",
        "print(\"Final best params:\", out_best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QiN_xhHvN1U"
      },
      "source": [
        "# 'Grid' on agumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vinlPXNq0jyZ"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L75TX5fTzGN"
      },
      "outputs": [],
      "source": [
        "grid_param = {\n",
        "   'learning_rate': [0.0001],\n",
        "   'batch_size': [6],\n",
        "   'dropout': [0.2],\n",
        "   'num_epochs': [50],\n",
        "   'number_of_linear_layers': [2],\n",
        "   'l1_regularization_lambda': [0.001],\n",
        "   'l2_regularization_lambda': [0.0001],\n",
        "   'number_of_conv_layers': [3],\n",
        "   'number_of_filers': [4],\n",
        "   'pooling': [False],\n",
        "   'batch_norm': [True],\n",
        "   'shape_info': [False]\n",
        "}\n",
        "\n",
        "\n",
        "grid_agumentations = {\n",
        "      'RandomHorizontalFlipProb': [0.0, 0.5],\n",
        "      'RandomRotation': [0, 30, 90],\n",
        "      'RandomAffineScale': [0.0, 0.1, 0.2],\n",
        "      #'GaussianBlurProb': [0.0, 0.5],\n",
        "      'RandomVerticalFlipProb': [0.0, 0.5]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7B4oEucd309"
      },
      "outputs": [],
      "source": [
        "# cnn, all\n",
        "\n",
        "model_type = Net\n",
        "dataset_type = PyTorchImageDataset\n",
        "print(\"model \", model_type)\n",
        "\n",
        "grid_on_agumentations(model_type, dataset_type, grid_agumentations, grid_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijV1iv4qWbVI"
      },
      "outputs": [],
      "source": [
        "# cnn, hearts\n",
        "\n",
        "model_type = Net\n",
        "dataset_type = HeartDataset\n",
        "\n",
        "grid_on_agumentations(model_type, dataset_type, grid_agumentations, grid_param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX-D6uBI01zn"
      },
      "source": [
        "RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D59jDTnzWW0a"
      },
      "outputs": [],
      "source": [
        "grid_param = {\n",
        "    'learning_rate': [0.001],\n",
        "    'batch_size': [6], \n",
        "    'num_epochs': [20]\n",
        "}\n",
        "\n",
        "grid_agumentations = {\n",
        "      'RandomHorizontalFlipProb': [0.0, 0.5],\n",
        "      'RandomRotation': [0, 30, 90],\n",
        "      'RandomAffineScale': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "      'RandomVerticalFlipProb': [0.0, 0.5]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7hnmmXaSqMK",
        "outputId": "1ccda008-f187-49ed-a65d-cb734245ed8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.664 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.200 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.059 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.661 AVG Test Loss:0.725 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.860 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.750 AVG Test Loss:0.700 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.723 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.710 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.766 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.738 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.732 AVG Test Loss:0.707 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.706 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.732 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.703 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.727 AVG Test Loss:0.703 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.685 AVG Test Loss:0.832 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.595 AVG Test Loss:1.200 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.642 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.662 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.860 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.751 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.721 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.712 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.766 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.731 AVG Test Loss:0.710 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.739 AVG Test Loss:0.710 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.740 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.732 AVG Test Loss:0.707 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.727 AVG Test Loss:0.708 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.726 AVG Test Loss:0.708 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.707 AVG Test Loss:0.831 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.597 AVG Test Loss:1.197 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.629 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.663 AVG Test Loss:0.726 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.861 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.752 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.718 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.768 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.733 AVG Test Loss:0.714 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.714 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.741 AVG Test Loss:0.710 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.734 AVG Test Loss:0.709 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.729 AVG Test Loss:0.711 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.711 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.797 AVG Test Loss:0.763 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.578 AVG Test Loss:1.302 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.627 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.896 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.152 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.663 AVG Test Loss:0.749 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.859 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.754 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.720 AVG Test Loss:0.719 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.764 AVG Test Loss:0.711 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.765 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.739 AVG Test Loss:0.696 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.730 AVG Test Loss:0.705 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.726 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.725 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.655 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.601 AVG Test Loss:1.203 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.161 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.713 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.710 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.602 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.591 AVG Test Loss:1.195 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.623 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.178 AVG Test Loss:0.758 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.757 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.722 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.765 AVG Test Loss:0.704 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.770 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.737 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.655 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.202 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.623 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.756 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.712 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.712 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.744 AVG Test Loss:0.699 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.720 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.721 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.742 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.737 AVG Test Loss:0.707 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.708 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.714 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.738 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.570 AVG Test Loss:1.290 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.639 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.145 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.678 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.803 AVG Test Loss:0.750 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.862 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.720 AVG Test Loss:0.714 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.762 AVG Test Loss:0.713 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.769 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.743 AVG Test Loss:0.694 AVG Training Acc 21.21 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.741 AVG Test Loss:0.708 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.688 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.195 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.847 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.731 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.716 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.680 AVG Test Loss:0.834 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.187 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.625 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.736 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.718 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.666 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.719 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.707 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.805 AVG Test Loss:0.765 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.574 AVG Test Loss:1.289 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.635 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.889 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.749 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.724 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.711 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.703 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.713 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.648 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.600 AVG Test Loss:1.193 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.611 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.729 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.707 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.608 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.198 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.619 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.694 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.657 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.194 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.847 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.717 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.703 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.759 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.560 AVG Test Loss:1.300 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.640 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.146 AVG Test Loss:0.788 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.082 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.745 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.801 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.694 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.722 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.713 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.679 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.191 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.704 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.685 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.676 AVG Test Loss:0.831 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.640 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.737 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.709 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.708 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.684 AVG Test Loss:0.831 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.592 AVG Test Loss:1.193 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.627 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.813 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.580 AVG Test Loss:1.302 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.629 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.894 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.167 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.082 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.754 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.723 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.718 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.700 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.642 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.595 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.595 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.159 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.700 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.710 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.609 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.592 AVG Test Loss:1.193 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.760 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.706 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.703 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.631 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.202 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.698 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.708 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.720 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.746 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.566 AVG Test Loss:1.288 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.611 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.882 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.145 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.750 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.804 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.693 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.720 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.709 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.692 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.689 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.702 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.754 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.675 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.827 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.181 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.731 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.704 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.703 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.675 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.593 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.733 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.826 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.757 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.714 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.714 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.749 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.791 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.280 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.884 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.077 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.744 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.740 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.719 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.714 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.699 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.709 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.660 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.600 AVG Test Loss:1.163 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.696 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.713 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.700 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.699 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.597 AVG Test Loss:0.828 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.614 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.635 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.801 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.701 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.709 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.714 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.693 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.662 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.617 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.695 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.685 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.707 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.781 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.572 AVG Test Loss:1.291 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.648 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.153 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.086 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.798 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.686 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.723 AVG Test Loss:0.713 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.764 AVG Test Loss:0.713 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.649 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.617 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.601 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.823 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.875 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.696 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.713 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.710 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.755 AVG Test Loss:0.689 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.623 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.592 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.193 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.712 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.704 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.652 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.158 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.608 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.714 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.692 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.789 AVG Test Loss:0.759 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.285 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.618 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.887 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.158 AVG Test Loss:0.777 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.080 AVG Test Loss:0.671 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.737 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.688 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.713 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.765 AVG Test Loss:0.712 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.614 AVG Test Loss:0.816 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.590 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.568 AVG Test Loss:0.738 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.170 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.831 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.876 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.697 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.736 AVG Test Loss:0.717 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.782 AVG Test Loss:0.712 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.635 AVG Test Loss:0.833 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.607 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.633 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.173 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.054 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.697 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.713 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.708 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.707 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.642 AVG Test Loss:0.833 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.590 AVG Test Loss:1.184 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.614 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.689 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.703 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.703 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.773 AVG Test Loss:0.757 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.581 AVG Test Loss:1.273 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.628 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.869 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.144 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.082 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.714 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.711 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.711 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.690 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.730 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.716 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.677 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.197 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.732 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.713 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.702 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.754 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.692 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.194 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.793 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.281 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.618 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.895 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.773 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.714 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.709 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 9.09 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.711 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.657 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.605 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.757 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.735 AVG Test Loss:0.711 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.685 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.749 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.629 AVG Test Loss:0.829 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.634 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.828 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.710 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.707 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.659 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.176 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.607 AVG Test Loss:0.762 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.189 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.754 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.577 AVG Test Loss:1.286 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.607 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.884 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.156 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.079 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.745 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.696 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.712 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.711 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.690 AVG Training Acc 6.06 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.704 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.709 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.693 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.691 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.614 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.600 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.733 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.824 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.697 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.715 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.780 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.703 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.693 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.186 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.628 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.718 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.707 AVG Test Loss:0.831 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.597 AVG Test Loss:1.184 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.697 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.697 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.805 AVG Test Loss:0.763 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.574 AVG Test Loss:1.280 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.891 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.158 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.082 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 20.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.717 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.709 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.661 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.618 AVG Test Loss:1.191 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.585 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.848 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.712 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.691 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.574 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.593 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.059 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.696 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.640 AVG Test Loss:0.828 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.592 AVG Test Loss:1.195 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.611 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.689 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.716 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.712 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.694 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.781 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.586 AVG Test Loss:1.290 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.607 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.081 AVG Test Loss:0.678 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.749 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.690 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.715 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.712 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.704 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 30.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.674 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.627 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.824 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.708 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.700 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.682 AVG Test Loss:0.833 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.202 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.653 AVG Test Loss:0.760 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.635 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.697 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.678 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.616 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.613 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.191 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.689 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.715 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.692 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.792 AVG Test Loss:0.759 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.577 AVG Test Loss:1.286 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.617 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.883 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.155 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.748 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.714 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.709 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.706 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.602 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.604 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.614 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.056 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.724 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.823 AVG Test Loss:0.720 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.685 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.713 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.705 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.738 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.631 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.187 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.649 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.678 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.692 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.699 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.641 AVG Test Loss:0.828 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.593 AVG Test Loss:1.198 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.629 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.811 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.710 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.690 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.729 AVG Test Loss:0.756 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.581 AVG Test Loss:1.273 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.595 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.885 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.154 AVG Test Loss:0.777 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.746 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.769 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.720 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.715 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.701 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.684 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.618 AVG Test Loss:1.159 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.582 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.191 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.681 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.727 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.655 AVG Test Loss:0.833 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.581 AVG Test Loss:1.189 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.628 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.178 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.699 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.692 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.676 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.595 AVG Test Loss:1.193 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.624 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.707 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.707 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.788 AVG Test Loss:0.757 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.585 AVG Test Loss:1.282 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.629 AVG Test Loss:0.712 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.633 AVG Test Loss:0.870 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.166 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.739 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.717 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.715 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.696 AVG Training Acc 3.03 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.623 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.606 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.167 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.769 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.709 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.711 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.594 AVG Test Loss:0.829 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.195 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.635 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.639 AVG Test Loss:0.826 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.710 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.669 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.595 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.745 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.717 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.693 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.733 AVG Test Loss:0.759 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.576 AVG Test Loss:1.281 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.627 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.877 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.139 AVG Test Loss:0.777 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.670 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.744 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.726 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.723 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.624 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.607 AVG Test Loss:1.156 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.606 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.739 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.688 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.711 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.698 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.690 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.616 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.169 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.646 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.608 AVG Test Loss:0.854 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.201 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.698 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.711 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.633 AVG Test Loss:0.816 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.619 AVG Test Loss:1.166 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.604 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.195 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.695 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.715 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.779 AVG Test Loss:0.701 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.700 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.687 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.827 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.290 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.648 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.890 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.804 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.874 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.723 AVG Test Loss:0.720 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.719 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.694 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.601 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.593 AVG Test Loss:1.150 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.825 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.170 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.077 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.875 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.689 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.692 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.701 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.614 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.591 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.649 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.696 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.699 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.706 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.663 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.636 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.729 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.697 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.737 AVG Test Loss:0.708 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.709 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.762 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.570 AVG Test Loss:1.278 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.637 AVG Test Loss:0.712 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.640 AVG Test Loss:0.875 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.152 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.089 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.800 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.694 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.721 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.712 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 30.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.639 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.599 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.712 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.667 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.724 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.703 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.662 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.715 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.710 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.745 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.267 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.608 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.890 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.777 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.747 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.719 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.713 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.700 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.712 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.666 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.188 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.597 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.700 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.706 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.745 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.693 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.640 AVG Test Loss:0.829 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.591 AVG Test Loss:1.201 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.632 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.726 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.701 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.704 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.638 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.189 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.623 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.781 AVG Test Loss:0.759 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.282 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.883 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.163 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.678 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.717 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.714 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.666 AVG Test Loss:0.828 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.594 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.191 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.732 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.823 AVG Test Loss:0.723 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.709 AVG Training Acc 31.25 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.657 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.613 AVG Test Loss:1.163 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.611 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.198 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.696 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.692 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.615 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.601 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.849 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.731 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.716 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.693 AVG Training Acc 3.12 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.751 AVG Test Loss:0.756 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.576 AVG Test Loss:1.288 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.895 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.166 AVG Test Loss:0.779 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.753 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.698 AVG Training Acc 51.52 % AVG Test Acc 20.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.727 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.714 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.700 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.650 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.597 AVG Test Loss:1.194 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.599 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.700 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.714 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.706 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.612 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.585 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.634 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.718 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.699 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.700 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.636 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.611 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.696 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.719 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.751 AVG Test Loss:0.756 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.577 AVG Test Loss:1.284 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.632 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.624 AVG Test Loss:0.888 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.779 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.084 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.745 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.800 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.693 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.716 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.717 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.704 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.681 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.620 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.606 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.189 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.638 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.632 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.706 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.706 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.650 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.615 AVG Test Loss:1.185 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.604 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.846 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.736 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.690 AVG Training Acc 6.25 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.790 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.577 AVG Test Loss:1.285 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.879 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.078 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.712 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.705 AVG Training Acc 9.09 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.641 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.620 AVG Test Loss:1.167 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.583 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.606 AVG Test Loss:0.847 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.197 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.724 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.713 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.708 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.589 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.619 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.702 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.717 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.700 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.631 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.633 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.682 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.703 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.722 AVG Test Loss:0.754 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.586 AVG Test Loss:1.269 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.598 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.612 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.773 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.078 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.746 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.804 AVG Test Loss:0.759 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.688 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.716 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.718 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 6.06 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.707 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.667 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.624 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.716 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.689 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.669 AVG Test Loss:0.836 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.600 AVG Test Loss:1.186 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.626 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.829 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.698 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.693 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.624 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.743 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.731 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.698 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.735 AVG Test Loss:0.716 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.705 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.688 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.747 AVG Test Loss:0.749 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.584 AVG Test Loss:1.252 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.881 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.161 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.745 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.721 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.719 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.702 AVG Training Acc 9.09 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.698 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.623 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.619 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.580 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.195 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.720 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.711 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.708 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.692 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.574 AVG Test Loss:0.817 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.150 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.720 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.620 AVG Test Loss:0.827 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.584 AVG Test Loss:1.164 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.746 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.638 AVG Test Loss:0.824 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.079 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.720 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.874 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.712 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.715 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.759 AVG Test Loss:0.760 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.563 AVG Test Loss:1.278 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.875 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.145 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.723 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.708 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 40.909090909090914 %\n",
            " Average acc: 39.07342657342658 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.615 AVG Test Loss:0.815 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.626 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.847 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.187 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.688 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.706 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.755 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.692 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.649 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.189 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.589 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.827 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.874 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.706 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.699 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.674 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.612 AVG Test Loss:1.165 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.638 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.165 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.082 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.718 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.878 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.770 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.722 AVG Test Loss:0.714 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.709 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.689 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.768 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.576 AVG Test Loss:1.287 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.636 AVG Test Loss:0.867 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.152 AVG Test Loss:0.769 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.077 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.698 AVG Training Acc 51.52 % AVG Test Acc 20.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.724 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.709 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.699 AVG Training Acc 6.06 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.713 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.707 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.554 AVG Test Loss:0.816 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.604 AVG Test Loss:1.154 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.590 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.826 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.719 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.697 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.600 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.593 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.624 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.633 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.079 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.703 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.765 AVG Test Loss:0.707 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.756 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.696 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.591 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.583 AVG Test Loss:1.191 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.813 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.162 AVG Test Loss:0.738 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.728 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.826 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.706 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.779 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.760 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.566 AVG Test Loss:1.282 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.628 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.638 AVG Test Loss:0.869 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.143 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.749 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.746 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.684 AVG Training Acc 0.00 % AVG Test Acc 80.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.698 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.717 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.716 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.695 AVG Training Acc 9.09 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.742 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.665 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.615 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.616 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.194 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.060 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.664 AVG Test Loss:0.726 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.823 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.754 AVG Test Loss:0.704 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.705 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.737 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.664 AVG Test Loss:0.828 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.640 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.166 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.736 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.698 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.718 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.713 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.770 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 9.38 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.734 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.662 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.604 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.611 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.181 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.715 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.712 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.706 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.770 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.577 AVG Test Loss:1.297 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.611 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.154 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.741 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.860 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.722 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.706 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.766 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.705 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.736 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.731 AVG Test Loss:0.706 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.699 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.619 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.665 AVG Test Loss:0.729 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.589 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.618 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.803 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.612 AVG Test Loss:0.817 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.620 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.580 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.733 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.713 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.712 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.695 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.734 AVG Test Loss:0.705 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.729 AVG Test Loss:0.757 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.572 AVG Test Loss:1.281 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.593 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.881 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.155 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.669 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.745 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.748 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.861 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.691 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.723 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.704 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.716 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.696 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.657 AVG Test Loss:0.827 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.665 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.712 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.710 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.640 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.191 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.692 AVG Test Loss:0.829 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.595 AVG Test Loss:1.202 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.630 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.811 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.689 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.710 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.700 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.751 AVG Test Loss:0.752 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.276 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.605 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.897 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.170 AVG Test Loss:0.785 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.742 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.804 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.724 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.715 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.696 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.654 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.621 AVG Test Loss:1.176 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.590 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.611 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.726 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.689 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.702 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.596 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.187 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.845 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.059 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.699 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.623 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.185 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.600 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.691 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.749 AVG Test Loss:0.758 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.576 AVG Test Loss:1.297 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.621 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.636 AVG Test Loss:0.884 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.139 AVG Test Loss:0.784 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.681 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.791 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.862 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.773 AVG Test Loss:0.690 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.709 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.709 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.740 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.683 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.624 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.590 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.612 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.060 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.735 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.710 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.754 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.641 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.623 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.611 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.726 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.692 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.711 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.703 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.675 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.616 AVG Test Loss:1.166 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.578 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.730 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.821 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.716 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.779 AVG Test Loss:0.706 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.704 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.755 AVG Test Loss:0.754 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.579 AVG Test Loss:1.290 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.624 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.153 AVG Test Loss:0.787 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.696 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.725 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.715 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.588 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.585 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.613 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.050 AVG Test Loss:0.683 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.724 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.709 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.708 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.738 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.610 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.601 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.178 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.697 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.711 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.609 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.629 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.875 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.711 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.708 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.694 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.653 AVG Test Loss:0.749 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.261 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.604 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.880 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.152 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.671 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.796 AVG Test Loss:0.744 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.769 AVG Test Loss:0.694 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.714 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.713 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.699 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.706 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.628 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.615 AVG Test Loss:1.188 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.603 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.200 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.059 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.622 AVG Test Loss:0.814 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.629 AVG Test Loss:1.162 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.586 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.846 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.736 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.712 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.710 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.694 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.645 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.173 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.608 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.626 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.700 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.692 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.742 AVG Test Loss:0.754 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.270 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.569 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.608 AVG Test Loss:0.893 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.753 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.741 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.700 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.722 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.716 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.708 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.707 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.638 AVG Test Loss:0.815 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.601 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.176 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.728 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.712 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.713 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.689 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.531 AVG Test Loss:0.810 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.196 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.604 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.609 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.700 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.706 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.700 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.598 AVG Test Loss:0.810 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.631 AVG Test Loss:1.156 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.575 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.707 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.717 AVG Test Loss:0.748 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.589 AVG Test Loss:1.272 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.616 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.154 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.745 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.753 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.875 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.719 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.716 AVG Training Acc 33.33 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.691 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 42.30769230769231 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 38.89860139860139 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.628 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.631 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.594 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.726 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.824 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.618 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.623 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.593 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.605 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.821 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.874 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.711 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.700 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.613 AVG Test Loss:0.810 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.149 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.589 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.613 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.702 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.693 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.702 AVG Test Loss:0.746 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.253 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.604 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.887 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.157 AVG Test Loss:0.774 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.079 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.805 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.687 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.720 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.720 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.713 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.697 AVG Training Acc 3.03 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.636 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.167 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.583 AVG Test Loss:0.745 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.158 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.722 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.685 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.697 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.714 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.780 AVG Test Loss:0.705 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.533 AVG Test Loss:0.814 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.600 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.173 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.060 AVG Test Loss:0.699 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.874 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.709 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.711 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.607 AVG Test Loss:0.817 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.582 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.743 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.166 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.055 AVG Test Loss:0.677 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.687 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.718 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.718 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.701 AVG Training Acc 6.25 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.636 AVG Test Loss:0.741 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.591 AVG Test Loss:1.239 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.567 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.606 AVG Test Loss:0.896 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.080 AVG Test Loss:0.670 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.665 AVG Test Loss:0.749 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.692 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.720 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.762 AVG Test Loss:0.715 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.683 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.618 AVG Test Loss:1.176 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.608 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.612 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.820 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.699 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.713 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.704 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.637 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.590 AVG Test Loss:1.189 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.623 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.712 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.712 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.661 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.611 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.849 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.185 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.689 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.744 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.740 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.268 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.628 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.890 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.163 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.682 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.716 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.710 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.582 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.189 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.849 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.189 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.697 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.707 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.706 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.618 AVG Test Loss:0.817 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.179 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.764 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.703 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.624 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.185 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.605 AVG Test Loss:0.751 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.717 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.704 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.723 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.588 AVG Test Loss:1.266 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.154 AVG Test Loss:0.780 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.797 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.720 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.762 AVG Test Loss:0.717 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.685 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.614 AVG Test Loss:1.190 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.612 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.722 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.696 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.708 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.707 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.671 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.596 AVG Test Loss:1.187 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.620 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.653 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.601 AVG Test Loss:1.188 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.633 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.808 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.709 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:0.736 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.775 AVG Test Loss:0.761 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.584 AVG Test Loss:1.282 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.634 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.888 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.161 AVG Test Loss:0.779 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.081 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.748 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.700 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.716 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.715 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.692 AVG Training Acc 9.09 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.712 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.645 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.563 AVG Test Loss:0.746 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.851 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.189 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.692 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.608 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.631 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.715 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.709 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.585 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.601 AVG Test Loss:1.181 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.585 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.757 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.686 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.704 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.708 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.755 AVG Test Loss:0.689 AVG Training Acc 3.12 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.687 AVG Test Loss:0.747 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.587 AVG Test Loss:1.258 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.599 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.893 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.782 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.743 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.804 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.694 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.723 AVG Test Loss:0.721 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.716 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.695 AVG Training Acc 12.12 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.734 AVG Test Loss:0.705 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.702 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.642 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.635 AVG Test Loss:1.169 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.579 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.605 AVG Test Loss:0.854 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.193 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.692 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.709 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.738 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.600 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.615 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.743 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.818 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.698 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.658 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.607 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.595 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.849 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.686 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.728 AVG Test Loss:0.747 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.261 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.600 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.886 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.162 AVG Test Loss:0.776 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.080 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.752 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.750 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.691 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.718 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.714 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 6.06 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.600 AVG Test Loss:0.815 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.615 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.588 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.624 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.696 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.699 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.704 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.691 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.567 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.174 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.607 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.697 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.707 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.710 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.706 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.605 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.579 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.625 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.166 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.701 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.770 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.727 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.580 AVG Test Loss:1.278 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.622 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.883 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.149 AVG Test Loss:0.783 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.077 AVG Test Loss:0.665 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.681 AVG Test Loss:0.736 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.792 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.861 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.770 AVG Test Loss:0.691 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.715 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.763 AVG Test Loss:0.712 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.683 AVG Training Acc 3.03 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.714 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.650 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.625 AVG Test Loss:1.192 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.584 AVG Test Loss:0.745 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.609 AVG Test Loss:0.846 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.198 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.682 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.665 AVG Test Loss:0.731 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.831 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.699 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.615 AVG Test Loss:0.816 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.185 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.636 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.828 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.165 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.810 AVG Test Loss:0.724 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.708 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.695 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.706 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.631 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.590 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.630 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.632 AVG Test Loss:0.821 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.173 AVG Test Loss:0.743 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.720 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.688 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.711 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.707 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.743 AVG Test Loss:0.757 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.568 AVG Test Loss:1.299 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.652 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.641 AVG Test Loss:0.868 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.137 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.738 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.799 AVG Test Loss:0.749 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.692 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.711 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.713 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.697 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.666 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.171 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.572 AVG Test Loss:0.746 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.633 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.173 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.826 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.680 AVG Training Acc 0.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.757 AVG Test Loss:0.697 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.715 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.782 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.749 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.750 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.737 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.507 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.581 AVG Test Loss:1.180 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.637 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.627 AVG Test Loss:0.826 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.173 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.706 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.700 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.691 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.616 AVG Test Loss:0.808 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.616 AVG Test Loss:1.175 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.602 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.691 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.811 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.690 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.715 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.712 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.693 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.699 AVG Test Loss:0.750 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.583 AVG Test Loss:1.272 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.595 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.890 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.777 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.084 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.674 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.757 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.770 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.715 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.710 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.695 AVG Training Acc 6.06 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 40.909090909090914 %\n",
            " Average acc: 38.548951048951054 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.657 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.623 AVG Test Loss:1.167 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.595 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.607 AVG Test Loss:0.850 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.197 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.667 AVG Test Loss:0.724 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.829 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.697 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.737 AVG Test Loss:0.708 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.701 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.692 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.585 AVG Test Loss:0.812 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.619 AVG Test Loss:1.150 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.603 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.196 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.696 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.690 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.770 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.652 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.617 AVG Test Loss:1.177 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.609 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.639 AVG Test Loss:0.829 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.170 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:0.696 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.715 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.802 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.685 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.708 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.707 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.717 AVG Test Loss:0.751 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.578 AVG Test Loss:1.275 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.880 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.087 AVG Test Loss:0.669 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.736 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.799 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.689 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.718 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.765 AVG Test Loss:0.714 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.698 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.613 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.618 AVG Test Loss:1.172 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.557 AVG Test Loss:0.749 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.829 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.181 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.824 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.777 AVG Test Loss:0.710 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.746 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.566 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.616 AVG Test Loss:1.169 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.577 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.841 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.188 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.687 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.725 AVG Test Loss:0.710 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.711 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.693 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.600 AVG Test Loss:0.812 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.600 AVG Test Loss:1.160 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.585 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.734 AVG Test Loss:0.746 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.585 AVG Test Loss:1.259 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.873 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.151 AVG Test Loss:0.767 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.674 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.677 AVG Test Loss:0.738 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.746 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.862 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.713 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.722 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.714 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.631 AVG Test Loss:0.826 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.601 AVG Test Loss:1.172 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.588 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.835 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.187 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.057 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.726 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.735 AVG Test Loss:0.710 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.705 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.588 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.180 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.699 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.652 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.193 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.602 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.683 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.714 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.705 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.760 AVG Test Loss:0.754 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.583 AVG Test Loss:1.291 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.614 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.628 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.157 AVG Test Loss:0.775 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.078 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.801 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.724 AVG Test Loss:0.723 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.716 AVG Training Acc 30.30 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 30.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.695 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.706 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.632 AVG Test Loss:0.816 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.627 AVG Test Loss:1.173 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.589 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.614 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.178 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.694 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.705 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.702 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.687 AVG Training Acc 12.50 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.618 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.611 AVG Test Loss:1.164 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.586 AVG Test Loss:0.760 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.827 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.747 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.692 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.732 AVG Test Loss:0.708 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.710 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.652 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.606 AVG Test Loss:1.186 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.754 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.170 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.064 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.736 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.721 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.698 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.736 AVG Test Loss:0.752 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.283 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.890 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.157 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.740 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.800 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.692 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.711 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.772 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.689 AVG Training Acc 6.06 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.708 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.645 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.621 AVG Test Loss:1.157 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.575 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.605 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.197 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.714 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.750 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.640 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.176 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.813 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.704 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.623 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.611 AVG Test Loss:1.169 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.591 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.847 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.196 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.687 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:0.726 AVG Test Loss:0.713 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.715 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.696 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.718 AVG Test Loss:0.756 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.578 AVG Test Loss:1.273 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.622 AVG Test Loss:0.889 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.157 AVG Test Loss:0.773 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.071 AVG Test Loss:0.676 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.744 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.801 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.691 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.718 AVG Training Acc 15.15 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.767 AVG Test Loss:0.714 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.698 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.740 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.614 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.616 AVG Test Loss:1.175 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.597 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.618 AVG Test Loss:0.836 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.198 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.821 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.761 AVG Test Loss:0.693 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.712 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.705 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.696 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.616 AVG Test Loss:0.824 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.598 AVG Test Loss:1.182 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.631 AVG Test Loss:0.761 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.629 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.167 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:0.694 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.811 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.711 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.711 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.700 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.594 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.608 AVG Test Loss:1.187 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.596 AVG Test Loss:0.748 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.770 AVG Test Loss:0.688 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.701 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.699 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.702 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.740 AVG Test Loss:0.759 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.573 AVG Test Loss:1.284 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.629 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.634 AVG Test Loss:0.879 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.157 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.078 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.737 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.795 AVG Test Loss:0.755 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.769 AVG Test Loss:0.689 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.720 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.764 AVG Test Loss:0.710 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.754 AVG Test Loss:0.694 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.741 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.743 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.638 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.617 AVG Test Loss:1.166 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.598 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.623 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.724 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.692 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.773 AVG Test Loss:0.705 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.689 AVG Training Acc 9.38 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.579 AVG Test Loss:0.825 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.594 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.651 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.827 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.743 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.673 AVG Test Loss:0.727 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.814 AVG Test Loss:0.734 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.715 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.710 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.694 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.692 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.639 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.609 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.589 AVG Test Loss:0.747 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.612 AVG Test Loss:0.839 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.184 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.729 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.732 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.694 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.715 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.707 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.691 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.710 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.738 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.704 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.737 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.604 AVG Test Loss:1.262 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.590 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.610 AVG Test Loss:0.889 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:0.779 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.672 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.741 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.809 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.713 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.769 AVG Test Loss:0.717 AVG Training Acc 24.24 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.699 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.706 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.663 AVG Test Loss:0.820 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.623 AVG Test Loss:1.156 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.594 AVG Test Loss:0.759 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.675 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.807 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.872 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.771 AVG Test Loss:0.710 AVG Training Acc 28.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.708 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.703 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.583 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.173 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.613 AVG Test Loss:0.756 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.629 AVG Test Loss:0.830 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.176 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.689 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.721 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.863 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.693 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.715 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.703 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.628 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.623 AVG Test Loss:1.151 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.576 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.608 AVG Test Loss:0.842 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.745 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.683 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.726 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.824 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.758 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.721 AVG Training Acc 21.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.705 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.701 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.692 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.761 AVG Test Loss:0.753 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.259 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.598 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.621 AVG Test Loss:0.888 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.155 AVG Test Loss:0.771 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:0.675 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.748 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.747 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.693 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.713 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.714 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.771 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.703 AVG Training Acc 9.09 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.703 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.744 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 30.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.642 AVG Test Loss:0.823 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.613 AVG Test Loss:1.172 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.572 AVG Test Loss:0.750 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.608 AVG Test Loss:0.844 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.186 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.670 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.729 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.692 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.711 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.782 AVG Test Loss:0.703 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.698 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.742 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.633 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.599 AVG Test Loss:1.188 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.599 AVG Test Loss:0.746 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.613 AVG Test Loss:0.840 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.178 AVG Test Loss:0.750 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.067 AVG Test Loss:0.693 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.825 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.735 AVG Test Loss:0.717 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.704 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.778 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.748 AVG Test Loss:0.700 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.748 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.648 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.178 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.589 AVG Test Loss:0.746 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.633 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.172 AVG Test Loss:0.751 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.688 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.822 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.689 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.772 AVG Test Loss:0.709 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.699 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.742 AVG Test Loss:0.755 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.573 AVG Test Loss:1.279 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.601 AVG Test Loss:0.707 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.617 AVG Test Loss:0.879 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.162 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.075 AVG Test Loss:0.671 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.749 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.763 AVG Test Loss:0.697 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.716 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.709 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.691 AVG Training Acc 6.06 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.706 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.748 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:7.618 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.611 AVG Test Loss:1.172 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.553 AVG Test Loss:0.744 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.827 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.174 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.061 AVG Test Loss:0.684 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.671 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.827 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.687 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.691 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.708 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.778 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.780 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.691 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.709 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.749 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.593 AVG Test Loss:0.822 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.602 AVG Test Loss:1.155 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.606 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:0.746 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.059 AVG Test Loss:0.690 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.691 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.712 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.776 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.691 AVG Training Acc 6.25 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.743 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.695 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.578 AVG Test Loss:0.814 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.600 AVG Test Loss:1.183 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.603 AVG Test Loss:0.757 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.620 AVG Test Loss:0.831 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.169 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.682 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.815 AVG Test Loss:0.728 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.864 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.765 AVG Test Loss:0.696 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.709 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.712 AVG Training Acc 25.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.775 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.691 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.744 AVG Test Loss:0.708 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.738 AVG Test Loss:0.753 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.587 AVG Test Loss:1.289 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.610 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.630 AVG Test Loss:0.880 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.139 AVG Test Loss:0.781 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.086 AVG Test Loss:0.679 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.680 AVG Test Loss:0.733 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.797 AVG Test Loss:0.752 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.866 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.767 AVG Test Loss:0.694 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.727 AVG Test Loss:0.719 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.766 AVG Test Loss:0.711 AVG Training Acc 21.21 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.692 AVG Training Acc 9.09 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.735 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.742 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.642 AVG Test Loss:0.821 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.619 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.755 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.619 AVG Test Loss:0.843 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.190 AVG Test Loss:0.756 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.681 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.731 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.870 AVG Test Loss:0.686 AVG Training Acc 0.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.695 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.728 AVG Test Loss:0.707 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.708 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.746 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.736 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.734 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.627 AVG Test Loss:0.819 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.610 AVG Test Loss:1.170 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.615 AVG Test Loss:0.752 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.612 AVG Test Loss:0.838 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.183 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:0.687 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.819 AVG Test Loss:0.727 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.759 AVG Test Loss:0.695 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.707 AVG Training Acc 12.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.704 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.774 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.751 AVG Test Loss:0.702 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.737 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.744 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.729 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.538 AVG Test Loss:0.814 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.603 AVG Test Loss:1.131 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.575 AVG Test Loss:0.745 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.611 AVG Test Loss:0.834 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.741 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.056 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.672 AVG Test Loss:0.723 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.730 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.867 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.762 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.731 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.712 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.779 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.749 AVG Test Loss:0.693 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.740 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.746 AVG Test Loss:0.694 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.735 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.756 AVG Test Loss:0.747 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.617 AVG Test Loss:1.265 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.566 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.603 AVG Test Loss:0.899 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.768 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.673 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.750 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.816 AVG Test Loss:0.745 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.869 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.734 AVG Test Loss:0.718 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.774 AVG Test Loss:0.713 AVG Training Acc 12.12 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.767 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.747 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.745 AVG Test Loss:0.700 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.740 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.738 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.732 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1/20 AVG Training Loss:7.582 AVG Test Loss:0.814 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.605 AVG Test Loss:1.173 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.592 AVG Test Loss:0.742 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.625 AVG Test Loss:0.837 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.748 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:0.686 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.669 AVG Test Loss:0.725 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.817 AVG Test Loss:0.740 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.691 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.760 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.733 AVG Test Loss:0.709 AVG Training Acc 9.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.775 AVG Test Loss:0.708 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.741 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.747 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.738 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.732 AVG Test Loss:0.689 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.735 AVG Test Loss:0.695 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:7.492 AVG Test Loss:0.799 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.654 AVG Test Loss:1.121 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.557 AVG Test Loss:0.758 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.600 AVG Test Loss:0.833 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.207 AVG Test Loss:0.742 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:0.692 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.668 AVG Test Loss:0.718 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.799 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.871 AVG Test Loss:0.692 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.768 AVG Test Loss:0.688 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.720 AVG Test Loss:0.710 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.762 AVG Test Loss:0.708 AVG Training Acc 34.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.773 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.752 AVG Test Loss:0.690 AVG Training Acc 3.12 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.734 AVG Test Loss:0.697 AVG Training Acc 6.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.739 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.741 AVG Test Loss:0.696 AVG Training Acc 3.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.741 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.733 AVG Test Loss:0.693 AVG Training Acc 3.12 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.728 AVG Test Loss:0.696 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:7.582 AVG Test Loss:0.818 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.604 AVG Test Loss:1.164 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:2.598 AVG Test Loss:0.753 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.635 AVG Test Loss:0.829 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.171 AVG Test Loss:0.749 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.685 AVG Training Acc 18.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.676 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.806 AVG Test Loss:0.741 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.868 AVG Test Loss:0.688 AVG Training Acc 0.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.766 AVG Test Loss:0.689 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.729 AVG Test Loss:0.714 AVG Training Acc 18.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.768 AVG Test Loss:0.709 AVG Training Acc 15.62 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.776 AVG Test Loss:0.697 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.753 AVG Test Loss:0.691 AVG Training Acc 6.25 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.739 AVG Test Loss:0.705 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.745 AVG Test Loss:0.701 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.699 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.742 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.734 AVG Test Loss:0.698 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:0.730 AVG Test Loss:0.693 AVG Training Acc 0.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:7.699 AVG Test Loss:0.740 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.613 AVG Test Loss:1.235 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:2.561 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.599 AVG Test Loss:0.894 AVG Training Acc 63.64 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.179 AVG Test Loss:0.770 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.079 AVG Test Loss:0.677 AVG Training Acc 18.18 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.666 AVG Test Loss:0.747 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.812 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.865 AVG Test Loss:0.690 AVG Training Acc 0.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.764 AVG Test Loss:0.695 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.730 AVG Test Loss:0.708 AVG Training Acc 18.18 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.770 AVG Test Loss:0.710 AVG Training Acc 27.27 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.777 AVG Test Loss:0.704 AVG Training Acc 0.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.750 AVG Test Loss:0.703 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.738 AVG Test Loss:0.713 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.743 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.747 AVG Test Loss:0.702 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.739 AVG Test Loss:0.703 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.737 AVG Test Loss:0.701 AVG Training Acc 3.03 % AVG Test Acc 30.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.731 AVG Test Loss:0.700 AVG Training Acc 3.03 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 38.46153846153847 %\n",
            "Fold 1 acc: 38.46153846153847 %\n",
            "Fold 2 acc: 38.46153846153847 %\n",
            "Fold 3 acc: 36.36363636363637 %\n",
            " Average acc: 37.93706293706294 %\n",
            "grid_param: {'RandomHorizontalFlipProb': [0.0, 0.5], 'RandomRotation': [0, 30, 90], 'RandomAffineScale': [0.0, 0.1, 0.2, 0.3, 0.4], 'RandomVerticalFlipProb': [0.0, 0.5]}  grid: [[[[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]]\n",
            "\n",
            "  [[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]]\n",
            "\n",
            "  [[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.39073427]\n",
            "   [0.37937063 0.37937063]]]\n",
            "\n",
            "\n",
            " [[[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.38898601]\n",
            "   [0.37937063 0.37937063]]\n",
            "\n",
            "  [[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.38548951]\n",
            "   [0.37937063 0.37937063]]\n",
            "\n",
            "  [[0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]\n",
            "   [0.37937063 0.37937063]]]]\n",
            "best: 0.3907342657342658 best_idx: (0, 2, 3, 1)\n",
            "best params: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n",
            "best params: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'RandomVerticalFlipProb': 0.5}\n"
          ]
        }
      ],
      "source": [
        "# resnet, all\n",
        "\n",
        "resnet_model = prepare_resnet_model(False, 0.0)\n",
        "\n",
        "model_type = resnet_model\n",
        "dataset_type = PyTorchImageDataset\n",
        "\n",
        "grid_on_agumentations(model_type, dataset_type, grid_agumentations, grid_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIqqNKsQSrwE",
        "outputId": "f48f77be-913e-456b-9c1f-fef1bfa08595"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.037 AVG Test Loss:1.512 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.031 AVG Test Loss:1.224 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.028 AVG Test Loss:1.052 AVG Training Acc 65.62 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.026 AVG Test Loss:0.998 AVG Training Acc 65.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.025 AVG Test Loss:0.819 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.023 AVG Test Loss:0.624 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.021 AVG Test Loss:0.651 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.019 AVG Test Loss:0.874 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.018 AVG Test Loss:1.245 AVG Training Acc 65.62 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.016 AVG Test Loss:1.701 AVG Training Acc 65.62 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.014 AVG Test Loss:1.689 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:1.013 AVG Test Loss:1.621 AVG Training Acc 62.50 % AVG Test Acc 18.18 %\n",
            "Epoch:13/20 AVG Training Loss:1.011 AVG Test Loss:1.409 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.010 AVG Test Loss:1.305 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.008 AVG Test Loss:1.306 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:1.007 AVG Test Loss:1.510 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.005 AVG Test Loss:1.677 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.004 AVG Test Loss:1.782 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:1.002 AVG Test Loss:1.880 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.001 AVG Test Loss:1.937 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.127 AVG Test Loss:1.144 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.121 AVG Test Loss:0.935 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:1.119 AVG Test Loss:0.998 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.118 AVG Test Loss:1.162 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.116 AVG Test Loss:1.391 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.115 AVG Test Loss:1.542 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:7/20 AVG Training Loss:1.114 AVG Test Loss:1.915 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.113 AVG Test Loss:2.297 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.111 AVG Test Loss:2.254 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.110 AVG Test Loss:2.142 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.109 AVG Test Loss:2.137 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.108 AVG Test Loss:2.147 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:1.106 AVG Test Loss:2.339 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.105 AVG Test Loss:2.533 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.104 AVG Test Loss:2.670 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:1.103 AVG Test Loss:2.761 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:1.102 AVG Test Loss:2.811 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:1.101 AVG Test Loss:2.731 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:1.099 AVG Test Loss:2.657 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.098 AVG Test Loss:2.632 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.062 AVG Test Loss:1.059 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:0.783 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.053 AVG Test Loss:0.616 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.051 AVG Test Loss:0.518 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.049 AVG Test Loss:0.553 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.047 AVG Test Loss:0.670 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.045 AVG Test Loss:0.623 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.044 AVG Test Loss:0.907 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.042 AVG Test Loss:1.242 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.040 AVG Test Loss:1.157 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.039 AVG Test Loss:0.902 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.037 AVG Test Loss:0.670 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.036 AVG Test Loss:0.621 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:1.034 AVG Test Loss:0.730 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:1.032 AVG Test Loss:0.834 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.031 AVG Test Loss:0.900 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.029 AVG Test Loss:0.918 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.028 AVG Test Loss:0.994 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.027 AVG Test Loss:1.057 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.025 AVG Test Loss:1.098 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:1.269 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.067 AVG Test Loss:1.223 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.064 AVG Test Loss:1.233 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.062 AVG Test Loss:1.072 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.060 AVG Test Loss:0.820 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.678 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.056 AVG Test Loss:0.950 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.054 AVG Test Loss:1.197 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.052 AVG Test Loss:1.338 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.051 AVG Test Loss:1.446 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.049 AVG Test Loss:1.561 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.047 AVG Test Loss:1.514 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.045 AVG Test Loss:1.670 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.044 AVG Test Loss:1.949 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.042 AVG Test Loss:2.327 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.040 AVG Test Loss:2.518 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.039 AVG Test Loss:2.619 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.037 AVG Test Loss:2.638 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.035 AVG Test Loss:2.639 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.034 AVG Test Loss:2.634 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 41.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.975 AVG Test Loss:1.425 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.049 AVG Test Loss:1.362 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.023 AVG Test Loss:1.332 AVG Training Acc 40.62 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:1.034 AVG Test Loss:1.125 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.090 AVG Test Loss:1.678 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.070 AVG Test Loss:0.882 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.162 AVG Test Loss:1.214 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.165 AVG Test Loss:0.928 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.055 AVG Test Loss:1.199 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.035 AVG Test Loss:0.688 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.026 AVG Test Loss:0.600 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:0.631 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.135 AVG Test Loss:0.361 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.055 AVG Test Loss:1.118 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.012 AVG Test Loss:0.774 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.065 AVG Test Loss:0.756 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.032 AVG Test Loss:0.840 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.907 AVG Test Loss:0.927 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.991 AVG Test Loss:0.975 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.121 AVG Test Loss:1.294 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 81.81818181818183 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 55.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.037 AVG Test Loss:1.512 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.031 AVG Test Loss:1.224 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.028 AVG Test Loss:1.052 AVG Training Acc 65.62 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.026 AVG Test Loss:0.998 AVG Training Acc 65.62 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.025 AVG Test Loss:0.819 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.023 AVG Test Loss:0.624 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.021 AVG Test Loss:0.651 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.019 AVG Test Loss:0.874 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.018 AVG Test Loss:1.245 AVG Training Acc 65.62 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.016 AVG Test Loss:1.701 AVG Training Acc 65.62 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.014 AVG Test Loss:1.689 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:1.013 AVG Test Loss:1.621 AVG Training Acc 62.50 % AVG Test Acc 18.18 %\n",
            "Epoch:13/20 AVG Training Loss:1.011 AVG Test Loss:1.409 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.010 AVG Test Loss:1.305 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.008 AVG Test Loss:1.306 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:1.007 AVG Test Loss:1.510 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.005 AVG Test Loss:1.677 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.004 AVG Test Loss:1.782 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:19/20 AVG Training Loss:1.002 AVG Test Loss:1.880 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.001 AVG Test Loss:1.937 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.127 AVG Test Loss:1.144 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.121 AVG Test Loss:0.935 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:1.119 AVG Test Loss:0.998 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.118 AVG Test Loss:1.162 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.116 AVG Test Loss:1.391 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.115 AVG Test Loss:1.542 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:7/20 AVG Training Loss:1.114 AVG Test Loss:1.915 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.113 AVG Test Loss:2.297 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.111 AVG Test Loss:2.254 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.110 AVG Test Loss:2.142 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.109 AVG Test Loss:2.137 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.108 AVG Test Loss:2.147 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:1.106 AVG Test Loss:2.339 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.105 AVG Test Loss:2.533 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.104 AVG Test Loss:2.670 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:1.103 AVG Test Loss:2.761 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:1.102 AVG Test Loss:2.811 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:1.101 AVG Test Loss:2.731 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:1.099 AVG Test Loss:2.657 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.098 AVG Test Loss:2.632 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.062 AVG Test Loss:1.059 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:0.783 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.053 AVG Test Loss:0.616 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.051 AVG Test Loss:0.518 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.049 AVG Test Loss:0.553 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.047 AVG Test Loss:0.670 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.045 AVG Test Loss:0.623 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.044 AVG Test Loss:0.907 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.042 AVG Test Loss:1.242 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.040 AVG Test Loss:1.157 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.039 AVG Test Loss:0.902 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.037 AVG Test Loss:0.670 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.036 AVG Test Loss:0.621 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:1.034 AVG Test Loss:0.730 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:1.032 AVG Test Loss:0.834 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.031 AVG Test Loss:0.900 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.029 AVG Test Loss:0.918 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.028 AVG Test Loss:0.994 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.027 AVG Test Loss:1.057 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.025 AVG Test Loss:1.098 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:1.269 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.067 AVG Test Loss:1.223 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.064 AVG Test Loss:1.233 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.062 AVG Test Loss:1.072 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.060 AVG Test Loss:0.820 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:0.678 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.056 AVG Test Loss:0.950 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.054 AVG Test Loss:1.197 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.052 AVG Test Loss:1.338 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.051 AVG Test Loss:1.446 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.049 AVG Test Loss:1.561 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.047 AVG Test Loss:1.514 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.045 AVG Test Loss:1.670 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.044 AVG Test Loss:1.949 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.042 AVG Test Loss:2.327 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.040 AVG Test Loss:2.518 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.039 AVG Test Loss:2.619 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.037 AVG Test Loss:2.638 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.035 AVG Test Loss:2.639 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.034 AVG Test Loss:2.634 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 41.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.083 AVG Test Loss:1.678 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.072 AVG Test Loss:1.258 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.301 AVG Test Loss:1.039 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.073 AVG Test Loss:1.287 AVG Training Acc 37.50 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.054 AVG Test Loss:0.915 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.117 AVG Test Loss:0.939 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.001 AVG Test Loss:1.359 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.968 AVG Test Loss:1.174 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.998 AVG Test Loss:1.621 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.202 AVG Test Loss:1.565 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.181 AVG Test Loss:0.948 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.910 AVG Test Loss:0.861 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.165 AVG Test Loss:1.906 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.100 AVG Test Loss:0.986 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.102 AVG Test Loss:1.268 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.109 AVG Test Loss:1.119 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.152 AVG Test Loss:1.318 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.073 AVG Test Loss:0.791 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.111 AVG Test Loss:0.711 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.120 AVG Test Loss:1.109 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.920 AVG Test Loss:1.281 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.170 AVG Test Loss:1.162 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.006 AVG Test Loss:1.055 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.024 AVG Test Loss:0.472 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.101 AVG Test Loss:0.934 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 35.45454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.210 AVG Test Loss:1.442 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.155 AVG Test Loss:1.325 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.167 AVG Test Loss:1.222 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.959 AVG Test Loss:1.085 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.071 AVG Test Loss:0.940 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.200 AVG Test Loss:0.639 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.089 AVG Test Loss:1.127 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.149 AVG Test Loss:1.412 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.142 AVG Test Loss:1.380 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.007 AVG Test Loss:1.696 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.107 AVG Test Loss:1.382 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.045 AVG Test Loss:1.316 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.061 AVG Test Loss:1.987 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Epoch:8/20 AVG Training Loss:0.972 AVG Test Loss:1.966 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.023 AVG Test Loss:1.734 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.164 AVG Test Loss:0.932 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.226 AVG Test Loss:0.850 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.961 AVG Test Loss:0.540 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:1.134 AVG Test Loss:0.502 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.993 AVG Test Loss:0.630 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.021 AVG Test Loss:1.214 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.085 AVG Test Loss:1.226 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.119 AVG Test Loss:1.184 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.163 AVG Test Loss:1.012 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.040 AVG Test Loss:0.775 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.088 AVG Test Loss:1.084 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.035 AVG Test Loss:1.035 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.111 AVG Test Loss:0.860 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.972 AVG Test Loss:1.083 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.012 AVG Test Loss:1.003 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.088 AVG Test Loss:0.938 AVG Training Acc 39.39 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 65.45454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.039 AVG Test Loss:1.463 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.999 AVG Test Loss:1.086 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.022 AVG Test Loss:1.109 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:0.474 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.075 AVG Test Loss:1.154 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.060 AVG Test Loss:1.144 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.957 AVG Test Loss:1.231 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.026 AVG Test Loss:1.164 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.111 AVG Test Loss:0.799 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.210 AVG Test Loss:0.826 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.113 AVG Test Loss:0.808 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.899 AVG Test Loss:1.134 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.017 AVG Test Loss:1.626 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.978 AVG Test Loss:1.474 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.117 AVG Test Loss:1.033 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.096 AVG Test Loss:1.041 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.184 AVG Test Loss:1.078 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.033 AVG Test Loss:0.969 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.166 AVG Test Loss:1.350 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.019 AVG Test Loss:0.959 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:1.076 AVG Test Loss:0.780 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:1.122 AVG Test Loss:0.322 AVG Training Acc 56.25 % AVG Test Acc 90.91 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:0.932 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.948 AVG Test Loss:0.921 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.124 AVG Test Loss:0.999 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.983 AVG Test Loss:1.017 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.138 AVG Test Loss:0.532 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.995 AVG Test Loss:1.044 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.033 AVG Test Loss:0.833 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.057 AVG Test Loss:1.234 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.001 AVG Test Loss:1.270 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:0.808 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.112 AVG Test Loss:0.701 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 55.172413793103445 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 42.857142857142854 %\n",
            " Average acc: 58.598298253470674 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.042 AVG Test Loss:1.696 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.022 AVG Test Loss:1.269 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.249 AVG Test Loss:1.096 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.088 AVG Test Loss:0.971 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.944 AVG Test Loss:0.637 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.950 AVG Test Loss:0.832 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.078 AVG Test Loss:0.591 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.059 AVG Test Loss:1.532 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.934 AVG Test Loss:1.106 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.946 AVG Test Loss:1.121 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.191 AVG Test Loss:1.227 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.187 AVG Test Loss:0.786 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.146 AVG Test Loss:0.859 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.971 AVG Test Loss:0.729 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.151 AVG Test Loss:0.911 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.043 AVG Test Loss:1.316 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.978 AVG Test Loss:1.005 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.057 AVG Test Loss:1.557 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:1.006 AVG Test Loss:0.856 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.039 AVG Test Loss:2.027 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.971 AVG Test Loss:0.140 AVG Training Acc 46.88 % AVG Test Acc 100.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.023 AVG Test Loss:1.062 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.136 AVG Test Loss:0.762 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.121 AVG Test Loss:1.072 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.167 AVG Test Loss:1.104 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.915 AVG Test Loss:0.962 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.086 AVG Test Loss:0.930 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.005 AVG Test Loss:0.802 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.964 AVG Test Loss:0.600 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.130 AVG Test Loss:0.974 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.079 AVG Test Loss:1.462 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.157 AVG Test Loss:1.724 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.003 AVG Test Loss:1.503 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.120 AVG Test Loss:1.013 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.982 AVG Test Loss:1.430 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.147 AVG Test Loss:1.480 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.041 AVG Test Loss:1.748 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.065 AVG Test Loss:1.006 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.112 AVG Test Loss:1.409 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 48.63636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.060 AVG Test Loss:1.535 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.982 AVG Test Loss:1.729 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.032 AVG Test Loss:1.010 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.936 AVG Test Loss:1.573 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.101 AVG Test Loss:1.072 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.084 AVG Test Loss:1.029 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.094 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.003 AVG Test Loss:0.770 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.059 AVG Test Loss:1.093 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.054 AVG Test Loss:1.316 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.917 AVG Test Loss:0.974 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.150 AVG Test Loss:1.039 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.985 AVG Test Loss:0.899 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.062 AVG Test Loss:0.983 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.033 AVG Test Loss:2.962 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:1.046 AVG Test Loss:1.408 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:1.076 AVG Test Loss:0.482 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.083 AVG Test Loss:1.046 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.092 AVG Test Loss:0.922 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.122 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.125 AVG Test Loss:1.100 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.997 AVG Test Loss:0.745 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.088 AVG Test Loss:0.705 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.926 AVG Test Loss:0.661 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.083 AVG Test Loss:0.812 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.092 AVG Test Loss:0.757 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.081 AVG Test Loss:1.168 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.977 AVG Test Loss:0.659 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.007 AVG Test Loss:1.060 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.998 AVG Test Loss:0.609 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.088 AVG Test Loss:1.026 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:1.066 AVG Training Acc 39.39 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.037 AVG Test Loss:0.343 AVG Training Acc 45.45 % AVG Test Acc 100.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.022 AVG Test Loss:0.786 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.949 AVG Test Loss:1.224 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.257 AVG Test Loss:1.094 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.126 AVG Test Loss:1.037 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.897 AVG Test Loss:0.814 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.978 AVG Test Loss:0.917 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.029 AVG Test Loss:1.130 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 48.275862068965516 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 56.159874608150474 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.231 AVG Test Loss:1.298 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.944 AVG Test Loss:0.684 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.990 AVG Test Loss:0.855 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:0.855 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.016 AVG Test Loss:0.856 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.150 AVG Test Loss:0.729 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.090 AVG Test Loss:1.207 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.069 AVG Test Loss:0.569 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:1.053 AVG Test Loss:1.670 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.004 AVG Test Loss:1.042 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.932 AVG Test Loss:1.034 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.938 AVG Test Loss:1.679 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.967 AVG Test Loss:1.032 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.008 AVG Test Loss:1.220 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.948 AVG Test Loss:0.504 AVG Training Acc 62.50 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:1.215 AVG Test Loss:0.494 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.985 AVG Test Loss:0.604 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.007 AVG Test Loss:0.985 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.929 AVG Test Loss:1.125 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.078 AVG Test Loss:0.642 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.019 AVG Test Loss:1.145 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.997 AVG Test Loss:0.624 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.924 AVG Test Loss:1.187 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.121 AVG Test Loss:0.718 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:1.206 AVG Test Loss:1.056 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.112 AVG Test Loss:1.538 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.966 AVG Test Loss:1.079 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.096 AVG Test Loss:0.778 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.116 AVG Test Loss:0.698 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 54.090909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.166 AVG Test Loss:1.290 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.045 AVG Test Loss:1.107 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.905 AVG Test Loss:1.126 AVG Training Acc 59.38 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:1.037 AVG Test Loss:1.013 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.958 AVG Test Loss:1.061 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.193 AVG Test Loss:1.907 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:7/20 AVG Training Loss:1.022 AVG Test Loss:0.736 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.050 AVG Test Loss:1.476 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.952 AVG Test Loss:1.615 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.115 AVG Test Loss:1.754 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.454 AVG Test Loss:1.907 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.056 AVG Test Loss:1.149 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.874 AVG Test Loss:1.120 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.111 AVG Test Loss:1.421 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.992 AVG Test Loss:2.037 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.160 AVG Test Loss:0.799 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.864 AVG Test Loss:1.797 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.998 AVG Test Loss:0.463 AVG Training Acc 62.50 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:0.849 AVG Test Loss:1.322 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.997 AVG Test Loss:1.166 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.895 AVG Test Loss:1.486 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.145 AVG Test Loss:1.000 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:1.135 AVG Test Loss:1.563 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.033 AVG Test Loss:1.491 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.986 AVG Test Loss:2.006 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.941 AVG Test Loss:1.270 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:1.074 AVG Test Loss:1.581 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:1.121 AVG Test Loss:1.351 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.077 AVG Test Loss:1.099 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:1.044 AVG Test Loss:0.824 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.981 AVG Test Loss:0.823 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.118 AVG Test Loss:0.763 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.972 AVG Test Loss:0.518 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.049 AVG Test Loss:1.002 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.136 AVG Test Loss:1.258 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.106 AVG Test Loss:1.230 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.989 AVG Test Loss:0.996 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.074 AVG Test Loss:0.546 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.105 AVG Test Loss:0.739 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 58.18181818181818 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.989 AVG Test Loss:1.482 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.047 AVG Test Loss:0.816 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.901 AVG Test Loss:0.754 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.969 AVG Test Loss:0.977 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.121 AVG Test Loss:0.565 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.987 AVG Test Loss:1.158 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.974 AVG Test Loss:1.639 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.826 AVG Test Loss:1.238 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:1.138 AVG Test Loss:1.489 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.012 AVG Test Loss:0.477 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.085 AVG Test Loss:0.930 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.939 AVG Test Loss:1.981 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:8/20 AVG Training Loss:1.036 AVG Test Loss:1.341 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.077 AVG Test Loss:0.993 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.105 AVG Test Loss:1.057 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.154 AVG Test Loss:0.930 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.138 AVG Test Loss:0.374 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.152 AVG Test Loss:0.568 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.002 AVG Test Loss:1.091 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.951 AVG Test Loss:1.155 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.028 AVG Test Loss:0.861 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:1.035 AVG Test Loss:0.918 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.146 AVG Test Loss:0.929 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.223 AVG Test Loss:1.210 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.075 AVG Test Loss:0.780 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.198 AVG Test Loss:1.045 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.247 AVG Test Loss:0.426 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 46.42857142857143 %\n",
            " Average acc: 50.243506493506494 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.071 AVG Test Loss:1.318 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.239 AVG Test Loss:0.962 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.041 AVG Test Loss:0.954 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.028 AVG Test Loss:0.855 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.922 AVG Test Loss:1.058 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.866 AVG Test Loss:0.666 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:0.918 AVG Test Loss:1.218 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.871 AVG Test Loss:1.414 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.107 AVG Test Loss:1.059 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.112 AVG Test Loss:0.584 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.115 AVG Test Loss:1.140 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.075 AVG Test Loss:1.257 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.145 AVG Test Loss:0.968 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.941 AVG Test Loss:1.749 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.024 AVG Test Loss:1.495 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.025 AVG Test Loss:1.711 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.121 AVG Test Loss:0.987 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.930 AVG Test Loss:0.943 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.987 AVG Test Loss:0.684 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.058 AVG Test Loss:0.857 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.144 AVG Test Loss:1.537 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.060 AVG Test Loss:0.839 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.116 AVG Test Loss:0.556 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.106 AVG Test Loss:0.969 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.021 AVG Test Loss:1.133 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.077 AVG Test Loss:0.586 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.034 AVG Test Loss:0.551 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.894 AVG Test Loss:0.543 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.009 AVG Test Loss:1.094 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.955 AVG Test Loss:2.154 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.951 AVG Test Loss:2.124 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.019 AVG Test Loss:1.063 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.003 AVG Test Loss:1.735 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.257 AVG Test Loss:0.503 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.049 AVG Test Loss:1.148 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.202 AVG Test Loss:1.709 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.001 AVG Test Loss:0.438 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.034 AVG Test Loss:0.995 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.884 AVG Test Loss:0.967 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.951 AVG Test Loss:0.343 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 63.18181818181819 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.026 AVG Test Loss:1.146 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.085 AVG Test Loss:0.845 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.060 AVG Test Loss:0.771 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.044 AVG Test Loss:0.995 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.132 AVG Test Loss:1.645 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.047 AVG Test Loss:0.933 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.005 AVG Test Loss:1.058 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:1.202 AVG Test Loss:0.744 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.081 AVG Test Loss:0.759 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.000 AVG Test Loss:1.490 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:1.006 AVG Test Loss:1.491 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.258 AVG Test Loss:1.035 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.979 AVG Test Loss:1.436 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.021 AVG Test Loss:2.012 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.052 AVG Test Loss:0.881 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.124 AVG Test Loss:0.657 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.116 AVG Test Loss:0.658 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.031 AVG Test Loss:0.646 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.973 AVG Test Loss:0.674 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.145 AVG Test Loss:0.798 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.984 AVG Test Loss:1.073 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.921 AVG Test Loss:0.801 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:0.903 AVG Test Loss:0.803 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.065 AVG Test Loss:1.278 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.082 AVG Test Loss:1.734 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.126 AVG Test Loss:0.817 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.234 AVG Test Loss:0.916 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.034 AVG Test Loss:1.061 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.130 AVG Test Loss:0.883 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.037 AVG Test Loss:0.467 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:0.758 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.064 AVG Test Loss:1.373 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.120 AVG Test Loss:0.581 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.203 AVG Test Loss:1.205 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 48.63636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.890 AVG Test Loss:1.244 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.935 AVG Test Loss:0.831 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.084 AVG Test Loss:0.921 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.102 AVG Test Loss:1.352 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.924 AVG Test Loss:1.208 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.057 AVG Test Loss:1.120 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.024 AVG Test Loss:2.055 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.221 AVG Test Loss:1.102 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.085 AVG Test Loss:1.295 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.201 AVG Test Loss:1.366 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.067 AVG Test Loss:0.613 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:0.938 AVG Test Loss:0.973 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.211 AVG Test Loss:1.845 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.199 AVG Test Loss:1.947 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:0.981 AVG Test Loss:0.741 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:1.037 AVG Test Loss:1.141 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:1.073 AVG Test Loss:1.212 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.029 AVG Test Loss:1.060 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.072 AVG Test Loss:0.746 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.118 AVG Test Loss:0.713 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.141 AVG Test Loss:1.376 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.009 AVG Test Loss:1.259 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.187 AVG Test Loss:0.932 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.081 AVG Test Loss:0.852 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.104 AVG Test Loss:0.778 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.030 AVG Test Loss:1.186 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.955 AVG Test Loss:0.977 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.107 AVG Test Loss:1.171 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.992 AVG Test Loss:0.840 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.008 AVG Test Loss:1.119 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.930 AVG Test Loss:2.038 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.087 AVG Test Loss:1.141 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.050 AVG Test Loss:0.979 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.023 AVG Test Loss:2.157 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.178 AVG Test Loss:1.211 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.091 AVG Test Loss:0.686 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.943 AVG Test Loss:0.539 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.127 AVG Test Loss:1.032 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.160 AVG Test Loss:1.790 AVG Training Acc 51.52 % AVG Test Acc 20.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 44.827586206896555 %\n",
            "Fold 3 acc: 20.0 %\n",
            " Average acc: 41.206896551724135 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.049 AVG Test Loss:1.347 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.979 AVG Test Loss:1.047 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.198 AVG Test Loss:0.701 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.051 AVG Test Loss:0.830 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.115 AVG Test Loss:0.723 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.008 AVG Test Loss:1.738 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.084 AVG Test Loss:0.947 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.106 AVG Test Loss:1.860 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.003 AVG Test Loss:1.561 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.088 AVG Test Loss:1.064 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.986 AVG Test Loss:1.565 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.035 AVG Test Loss:1.178 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.972 AVG Test Loss:1.387 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.118 AVG Test Loss:0.943 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.087 AVG Test Loss:0.941 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.090 AVG Test Loss:1.335 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.957 AVG Test Loss:1.541 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.025 AVG Test Loss:1.168 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.006 AVG Test Loss:1.022 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.123 AVG Test Loss:1.679 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.092 AVG Test Loss:1.483 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.998 AVG Test Loss:0.924 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.100 AVG Test Loss:1.745 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.064 AVG Test Loss:1.002 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.012 AVG Test Loss:0.998 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.876 AVG Test Loss:1.187 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.065 AVG Test Loss:2.134 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.929 AVG Test Loss:1.327 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.153 AVG Test Loss:1.126 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.964 AVG Test Loss:1.065 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:0.604 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.059 AVG Test Loss:0.685 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.092 AVG Test Loss:1.730 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.092 AVG Test Loss:1.082 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.117 AVG Test Loss:0.595 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.052 AVG Test Loss:0.804 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.013 AVG Test Loss:0.730 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.143 AVG Test Loss:0.566 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.147 AVG Test Loss:0.542 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 53.86363636363636 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.182 AVG Test Loss:1.135 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.998 AVG Test Loss:0.926 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.957 AVG Test Loss:0.654 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.139 AVG Test Loss:0.396 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.009 AVG Test Loss:0.509 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:1.180 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.127 AVG Test Loss:1.553 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:1.160 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.969 AVG Test Loss:1.072 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.933 AVG Test Loss:1.813 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.009 AVG Test Loss:1.576 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.048 AVG Test Loss:1.286 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.139 AVG Test Loss:1.090 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:1.024 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.210 AVG Test Loss:0.860 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.914 AVG Test Loss:0.599 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.970 AVG Test Loss:0.737 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.138 AVG Test Loss:1.830 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.094 AVG Test Loss:1.364 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.129 AVG Test Loss:1.165 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.049 AVG Test Loss:1.055 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.129 AVG Test Loss:0.835 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.199 AVG Test Loss:0.505 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 41.37931034482759 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 46.2539184952978 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.228 AVG Test Loss:1.536 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.048 AVG Test Loss:1.098 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.052 AVG Test Loss:0.861 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.083 AVG Test Loss:1.031 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.998 AVG Test Loss:1.280 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.273 AVG Test Loss:1.044 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.977 AVG Test Loss:0.469 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.995 AVG Test Loss:1.627 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.080 AVG Test Loss:1.611 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.233 AVG Test Loss:1.131 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.951 AVG Test Loss:1.333 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.471 AVG Training Acc 37.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.012 AVG Test Loss:0.946 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.076 AVG Test Loss:1.136 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.942 AVG Test Loss:1.282 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.999 AVG Test Loss:1.305 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.098 AVG Test Loss:1.178 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.030 AVG Test Loss:1.462 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.060 AVG Test Loss:1.102 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.993 AVG Test Loss:0.900 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.157 AVG Test Loss:0.327 AVG Training Acc 45.45 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.993 AVG Test Loss:0.550 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.994 AVG Test Loss:1.140 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.013 AVG Test Loss:0.496 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 67.72727272727272 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.044 AVG Test Loss:1.409 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.001 AVG Test Loss:1.031 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.120 AVG Test Loss:1.437 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.977 AVG Test Loss:0.809 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.952 AVG Test Loss:0.717 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.163 AVG Test Loss:0.679 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:1.127 AVG Test Loss:1.330 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.001 AVG Test Loss:0.650 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:0.929 AVG Test Loss:1.265 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.964 AVG Test Loss:1.259 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.999 AVG Test Loss:2.313 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.934 AVG Test Loss:1.855 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.975 AVG Test Loss:1.120 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.004 AVG Test Loss:1.692 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.972 AVG Test Loss:1.083 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.928 AVG Test Loss:0.853 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.993 AVG Test Loss:0.627 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.034 AVG Test Loss:1.560 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.018 AVG Test Loss:1.225 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:1.026 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.017 AVG Test Loss:0.840 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.354 AVG Test Loss:0.760 AVG Training Acc 33.33 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 44.827586206896555 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 46.661442006269596 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.135 AVG Test Loss:1.434 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:1.104 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.020 AVG Test Loss:1.198 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.155 AVG Test Loss:1.074 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.211 AVG Test Loss:0.666 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.113 AVG Test Loss:1.415 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.112 AVG Test Loss:2.000 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.950 AVG Test Loss:0.801 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.977 AVG Test Loss:1.271 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.005 AVG Test Loss:0.908 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.031 AVG Test Loss:1.164 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.080 AVG Test Loss:0.466 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.902 AVG Test Loss:0.655 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.100 AVG Test Loss:0.882 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.027 AVG Test Loss:0.958 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.953 AVG Test Loss:1.496 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.008 AVG Test Loss:1.333 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.992 AVG Test Loss:1.317 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.957 AVG Test Loss:0.644 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.107 AVG Test Loss:1.108 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.927 AVG Test Loss:0.848 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:1.085 AVG Test Loss:1.084 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.200 AVG Test Loss:2.427 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.144 AVG Test Loss:1.686 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.024 AVG Test Loss:1.373 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.124 AVG Test Loss:1.237 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.938 AVG Test Loss:1.024 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.987 AVG Test Loss:0.594 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.311 AVG Test Loss:0.742 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 53.63636363636364 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.025 AVG Test Loss:1.435 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.214 AVG Test Loss:1.217 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.142 AVG Test Loss:0.981 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:0.999 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.136 AVG Test Loss:1.310 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.123 AVG Test Loss:0.532 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:0.928 AVG Test Loss:1.979 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.127 AVG Test Loss:1.104 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.011 AVG Test Loss:0.686 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.967 AVG Test Loss:1.257 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.115 AVG Test Loss:1.577 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.944 AVG Test Loss:2.943 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.067 AVG Test Loss:1.143 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:1.000 AVG Test Loss:1.366 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.193 AVG Test Loss:2.230 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:16/20 AVG Training Loss:0.961 AVG Test Loss:1.899 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.074 AVG Test Loss:1.661 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:1.170 AVG Test Loss:1.259 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.003 AVG Test Loss:1.552 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.090 AVG Test Loss:1.369 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.978 AVG Test Loss:1.145 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.014 AVG Test Loss:1.386 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.109 AVG Test Loss:1.511 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:0.923 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:0.727 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.003 AVG Test Loss:0.838 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.977 AVG Test Loss:0.694 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.062 AVG Test Loss:0.731 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:0.974 AVG Test Loss:0.616 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:0.960 AVG Test Loss:1.413 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.951 AVG Test Loss:1.161 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.037 AVG Test Loss:0.639 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.147 AVG Test Loss:1.208 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.185 AVG Test Loss:1.211 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.031 AVG Test Loss:1.177 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.005 AVG Test Loss:1.439 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.003 AVG Test Loss:0.949 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.952 AVG Test Loss:1.529 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.223 AVG Test Loss:0.965 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.997 AVG Test Loss:0.792 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.994 AVG Test Loss:1.274 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.935 AVG Test Loss:1.496 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.170 AVG Test Loss:0.578 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.974 AVG Test Loss:0.646 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.045 AVG Test Loss:0.488 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.984 AVG Test Loss:0.476 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.035 AVG Test Loss:0.673 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.922 AVG Test Loss:1.426 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.098 AVG Test Loss:1.094 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.039 AVG Test Loss:0.703 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.902 AVG Test Loss:0.717 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.145 AVG Test Loss:0.711 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.050 AVG Test Loss:0.836 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.985 AVG Test Loss:1.732 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.074 AVG Test Loss:1.045 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.115 AVG Test Loss:0.733 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.013 AVG Test Loss:0.916 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.047 AVG Test Loss:0.921 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.060 AVG Test Loss:1.320 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.996 AVG Test Loss:0.941 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.024 AVG Test Loss:0.899 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:0.817 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.218 AVG Test Loss:1.265 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.987 AVG Test Loss:0.838 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.011 AVG Test Loss:1.149 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.028 AVG Test Loss:1.139 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 53.40909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.990 AVG Test Loss:1.271 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.142 AVG Test Loss:1.119 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.153 AVG Test Loss:1.549 AVG Training Acc 68.75 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.011 AVG Test Loss:1.053 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.989 AVG Test Loss:1.023 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.090 AVG Test Loss:1.350 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.008 AVG Test Loss:1.144 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:1.290 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.975 AVG Test Loss:0.791 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.081 AVG Test Loss:0.971 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.158 AVG Test Loss:1.785 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.043 AVG Test Loss:0.989 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.190 AVG Test Loss:1.029 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.945 AVG Test Loss:0.886 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.027 AVG Test Loss:1.351 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.979 AVG Test Loss:1.050 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.204 AVG Test Loss:2.124 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.942 AVG Test Loss:1.274 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.020 AVG Test Loss:1.296 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.026 AVG Test Loss:1.277 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.234 AVG Test Loss:1.131 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.834 AVG Test Loss:1.403 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.167 AVG Test Loss:1.152 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.127 AVG Test Loss:1.066 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.225 AVG Test Loss:0.599 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.951 AVG Test Loss:0.974 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.999 AVG Test Loss:1.076 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.943 AVG Test Loss:2.385 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.141 AVG Test Loss:1.522 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.064 AVG Test Loss:1.625 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.278 AVG Test Loss:0.830 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.071 AVG Test Loss:0.492 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:13/20 AVG Training Loss:0.987 AVG Test Loss:1.034 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.909 AVG Test Loss:1.343 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.071 AVG Test Loss:1.695 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.069 AVG Test Loss:1.069 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.146 AVG Test Loss:0.834 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.904 AVG Test Loss:1.975 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.098 AVG Test Loss:1.560 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.348 AVG Test Loss:1.142 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 56.136363636363626 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.075 AVG Test Loss:1.368 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.090 AVG Test Loss:0.964 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.215 AVG Test Loss:1.004 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.048 AVG Test Loss:1.112 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.369 AVG Test Loss:0.950 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.112 AVG Test Loss:0.831 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.167 AVG Test Loss:0.756 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.058 AVG Test Loss:1.217 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:1.396 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.063 AVG Test Loss:1.253 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.064 AVG Test Loss:1.388 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.227 AVG Test Loss:1.159 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.971 AVG Test Loss:0.683 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.290 AVG Test Loss:1.883 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.964 AVG Test Loss:0.804 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.066 AVG Test Loss:1.250 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.169 AVG Test Loss:1.388 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.174 AVG Test Loss:1.108 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.991 AVG Test Loss:0.956 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.086 AVG Test Loss:0.853 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.090 AVG Test Loss:0.688 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 46.42857142857143 %\n",
            " Average acc: 41.1525974025974 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.952 AVG Test Loss:1.117 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.944 AVG Test Loss:1.279 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.122 AVG Test Loss:0.572 AVG Training Acc 59.38 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.107 AVG Test Loss:0.697 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.114 AVG Test Loss:0.681 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.017 AVG Test Loss:1.316 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.066 AVG Test Loss:1.218 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.097 AVG Test Loss:1.316 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.069 AVG Test Loss:1.040 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.037 AVG Test Loss:1.364 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:0.987 AVG Test Loss:0.939 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.095 AVG Test Loss:0.719 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.064 AVG Test Loss:0.800 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.999 AVG Test Loss:1.654 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.031 AVG Test Loss:1.834 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:0.899 AVG Test Loss:1.564 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.090 AVG Test Loss:1.893 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.119 AVG Test Loss:1.477 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.094 AVG Test Loss:0.957 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.973 AVG Test Loss:1.038 AVG Training Acc 65.62 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.164 AVG Test Loss:0.853 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.066 AVG Test Loss:0.892 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.930 AVG Test Loss:0.953 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.975 AVG Test Loss:1.004 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.960 AVG Test Loss:2.983 AVG Training Acc 53.12 % AVG Test Acc 9.09 %\n",
            "Epoch:8/20 AVG Training Loss:0.944 AVG Test Loss:2.760 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.098 AVG Test Loss:1.339 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.144 AVG Test Loss:2.035 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.083 AVG Test Loss:0.939 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.120 AVG Test Loss:0.800 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:1.136 AVG Training Acc 36.36 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.094 AVG Test Loss:0.843 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.019 AVG Test Loss:1.461 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.102 AVG Test Loss:1.327 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.074 AVG Test Loss:1.394 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.000 AVG Test Loss:0.954 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.006 AVG Test Loss:0.522 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.001 AVG Test Loss:1.260 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.164 AVG Test Loss:2.057 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.993 AVG Test Loss:0.754 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.167 AVG Test Loss:2.420 AVG Training Acc 48.48 % AVG Test Acc 10.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.043 AVG Test Loss:1.109 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.912 AVG Test Loss:0.839 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.021 AVG Test Loss:0.864 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.163 AVG Test Loss:0.709 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 44.54545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.128 AVG Test Loss:1.092 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.999 AVG Test Loss:1.149 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.204 AVG Test Loss:1.087 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.193 AVG Test Loss:0.488 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.923 AVG Test Loss:1.033 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.011 AVG Test Loss:0.794 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.046 AVG Test Loss:0.505 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.072 AVG Test Loss:1.595 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.077 AVG Test Loss:0.964 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.079 AVG Test Loss:1.438 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.009 AVG Test Loss:0.789 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.013 AVG Test Loss:0.775 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.988 AVG Test Loss:1.304 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.932 AVG Test Loss:0.739 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.112 AVG Test Loss:0.839 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.011 AVG Test Loss:1.335 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.978 AVG Test Loss:1.390 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.930 AVG Test Loss:1.372 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.143 AVG Test Loss:1.182 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.237 AVG Test Loss:1.398 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.053 AVG Test Loss:1.487 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.036 AVG Test Loss:0.875 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.024 AVG Test Loss:1.350 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.060 AVG Test Loss:0.666 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.926 AVG Test Loss:1.058 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.145 AVG Test Loss:0.927 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.040 AVG Test Loss:1.558 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.128 AVG Test Loss:1.401 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.164 AVG Test Loss:1.364 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 50.0 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 57.04545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.205 AVG Test Loss:1.391 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.935 AVG Test Loss:0.615 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.108 AVG Test Loss:1.261 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:0.982 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.044 AVG Test Loss:0.968 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.122 AVG Test Loss:0.563 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.018 AVG Test Loss:1.309 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.091 AVG Test Loss:1.288 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.953 AVG Test Loss:1.182 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.982 AVG Test Loss:1.271 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.239 AVG Test Loss:2.583 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.994 AVG Test Loss:1.469 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:1.246 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.041 AVG Test Loss:1.460 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.938 AVG Test Loss:1.437 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.260 AVG Test Loss:1.429 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.153 AVG Test Loss:0.807 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.007 AVG Test Loss:1.580 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.027 AVG Test Loss:0.894 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.873 AVG Test Loss:0.810 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.999 AVG Test Loss:2.049 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.401 AVG Test Loss:1.216 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.134 AVG Test Loss:1.198 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.033 AVG Test Loss:1.150 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.223 AVG Test Loss:0.699 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.002 AVG Test Loss:1.107 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.138 AVG Test Loss:1.118 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.027 AVG Test Loss:0.578 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.899 AVG Test Loss:1.046 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.208 AVG Test Loss:1.013 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.075 AVG Test Loss:1.276 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.025 AVG Test Loss:0.570 AVG Training Acc 63.64 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.826 AVG Test Loss:0.770 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.958 AVG Test Loss:2.134 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.130 AVG Test Loss:1.507 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 18.181818181818183 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 44.09090909090909 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.026 AVG Test Loss:1.193 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.176 AVG Test Loss:0.877 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:1.337 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.054 AVG Test Loss:1.014 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.076 AVG Test Loss:0.551 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:1.011 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.071 AVG Test Loss:0.736 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.994 AVG Test Loss:0.493 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.094 AVG Test Loss:0.569 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.022 AVG Test Loss:1.287 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.992 AVG Test Loss:0.859 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.044 AVG Test Loss:1.028 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.974 AVG Test Loss:0.725 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:1.028 AVG Test Loss:1.085 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:1.088 AVG Test Loss:1.567 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.971 AVG Test Loss:1.391 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.135 AVG Test Loss:1.215 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.282 AVG Test Loss:1.024 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.186 AVG Test Loss:0.787 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:1.219 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.062 AVG Test Loss:1.174 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.972 AVG Test Loss:1.421 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.072 AVG Test Loss:1.065 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.940 AVG Test Loss:0.918 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.006 AVG Test Loss:1.568 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:1.155 AVG Test Loss:1.013 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.069 AVG Test Loss:1.386 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.001 AVG Test Loss:1.106 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.167 AVG Test Loss:1.106 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.009 AVG Test Loss:0.569 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.149 AVG Test Loss:1.590 AVG Training Acc 54.55 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.003 AVG Test Loss:1.065 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.124 AVG Test Loss:0.980 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.004 AVG Test Loss:1.238 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.053 AVG Test Loss:1.458 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.146 AVG Test Loss:1.069 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 49.31818181818181 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.031 AVG Test Loss:1.346 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.973 AVG Test Loss:0.921 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.112 AVG Test Loss:0.810 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.122 AVG Test Loss:0.853 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.334 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.086 AVG Test Loss:1.143 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.918 AVG Test Loss:1.369 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.107 AVG Test Loss:0.898 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.032 AVG Test Loss:1.914 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.131 AVG Test Loss:1.604 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.921 AVG Test Loss:1.060 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.946 AVG Test Loss:1.645 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.019 AVG Test Loss:1.008 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.964 AVG Test Loss:0.930 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.098 AVG Test Loss:1.100 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.137 AVG Test Loss:0.483 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.098 AVG Test Loss:1.298 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:0.970 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.165 AVG Test Loss:1.114 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.027 AVG Test Loss:1.008 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.065 AVG Test Loss:1.440 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.029 AVG Test Loss:1.074 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.070 AVG Test Loss:0.749 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.958 AVG Test Loss:0.821 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.026 AVG Test Loss:1.554 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.951 AVG Test Loss:1.297 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.112 AVG Test Loss:1.145 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.098 AVG Test Loss:0.781 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.025 AVG Test Loss:1.001 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.969 AVG Test Loss:2.000 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.130 AVG Test Loss:1.227 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.086 AVG Test Loss:0.623 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.074 AVG Test Loss:1.587 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.023 AVG Test Loss:0.482 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.149 AVG Test Loss:0.908 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.022 AVG Test Loss:1.604 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 48.275862068965516 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 56.159874608150474 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.907 AVG Test Loss:1.395 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:1.435 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.022 AVG Test Loss:0.913 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:0.991 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.088 AVG Test Loss:0.825 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:1.032 AVG Test Loss:1.367 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.073 AVG Test Loss:0.768 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.972 AVG Test Loss:1.247 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.081 AVG Test Loss:1.025 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.072 AVG Test Loss:1.033 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.918 AVG Test Loss:1.163 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.039 AVG Test Loss:1.326 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.189 AVG Test Loss:1.565 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.101 AVG Test Loss:0.865 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.034 AVG Test Loss:0.857 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.904 AVG Test Loss:0.668 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.133 AVG Test Loss:0.520 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:0.985 AVG Test Loss:1.487 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.146 AVG Test Loss:1.321 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.980 AVG Test Loss:0.673 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.059 AVG Test Loss:0.679 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.031 AVG Test Loss:1.880 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.058 AVG Test Loss:1.179 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.112 AVG Test Loss:0.557 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.116 AVG Test Loss:1.113 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.161 AVG Test Loss:0.701 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:0.972 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.114 AVG Test Loss:0.964 AVG Training Acc 36.36 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.155 AVG Test Loss:0.649 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 50.0 %\n",
            "Fold 3 acc: 54.54545454545454 %\n",
            " Average acc: 51.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.103 AVG Test Loss:1.350 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.038 AVG Test Loss:1.262 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.962 AVG Test Loss:1.018 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.029 AVG Test Loss:0.655 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.837 AVG Test Loss:0.572 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.171 AVG Test Loss:1.101 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.935 AVG Test Loss:1.067 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.048 AVG Test Loss:0.836 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.904 AVG Test Loss:1.717 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.178 AVG Test Loss:2.193 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.143 AVG Test Loss:1.762 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.030 AVG Test Loss:1.366 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.153 AVG Test Loss:1.244 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.961 AVG Test Loss:1.572 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.045 AVG Test Loss:1.041 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.961 AVG Test Loss:1.766 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.166 AVG Test Loss:1.566 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:1.112 AVG Test Loss:2.674 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:19/20 AVG Training Loss:0.968 AVG Test Loss:0.676 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:1.174 AVG Test Loss:1.232 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.109 AVG Test Loss:1.160 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.069 AVG Test Loss:1.025 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.046 AVG Test Loss:0.920 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.989 AVG Test Loss:0.738 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.085 AVG Test Loss:1.962 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:6/20 AVG Training Loss:1.076 AVG Test Loss:0.540 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.091 AVG Test Loss:1.010 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.203 AVG Test Loss:1.587 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.219 AVG Test Loss:1.123 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.006 AVG Test Loss:1.135 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.043 AVG Test Loss:0.989 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.004 AVG Test Loss:0.877 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.022 AVG Test Loss:0.857 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.096 AVG Test Loss:1.212 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.007 AVG Test Loss:1.133 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.053 AVG Test Loss:0.892 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.988 AVG Test Loss:1.034 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.968 AVG Test Loss:0.673 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.136 AVG Test Loss:1.582 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.018 AVG Test Loss:0.442 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.113 AVG Test Loss:1.008 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.018 AVG Test Loss:1.760 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.175 AVG Test Loss:0.700 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.113 AVG Test Loss:0.726 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.251 AVG Test Loss:1.406 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.971 AVG Test Loss:0.389 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.112 AVG Test Loss:1.301 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.090 AVG Test Loss:0.768 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.209 AVG Test Loss:0.357 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.113 AVG Test Loss:0.745 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.977 AVG Test Loss:0.574 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.981 AVG Test Loss:0.844 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.915 AVG Test Loss:0.877 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.053 AVG Test Loss:1.641 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 46.36363636363636 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.134 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.978 AVG Test Loss:0.931 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.951 AVG Test Loss:0.434 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.992 AVG Test Loss:1.127 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.995 AVG Test Loss:1.474 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.097 AVG Test Loss:1.214 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.190 AVG Test Loss:1.421 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.985 AVG Test Loss:0.767 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.967 AVG Test Loss:1.488 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:0.778 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.932 AVG Test Loss:0.981 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.144 AVG Test Loss:1.896 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.972 AVG Test Loss:1.119 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.057 AVG Test Loss:1.084 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.974 AVG Test Loss:0.733 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.067 AVG Test Loss:0.701 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:1.029 AVG Test Loss:1.075 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:0.957 AVG Test Loss:1.267 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.027 AVG Test Loss:1.221 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:0.927 AVG Test Loss:1.187 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:0.990 AVG Test Loss:1.696 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:17/20 AVG Training Loss:1.167 AVG Test Loss:2.225 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.116 AVG Test Loss:1.342 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.140 AVG Test Loss:0.667 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.198 AVG Test Loss:1.317 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.058 AVG Test Loss:1.024 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.206 AVG Test Loss:1.077 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.091 AVG Test Loss:0.703 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.230 AVG Test Loss:1.283 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.058 AVG Test Loss:1.514 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.934 AVG Test Loss:0.868 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.981 AVG Test Loss:1.566 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.980 AVG Test Loss:0.906 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.057 AVG Test Loss:1.231 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.023 AVG Test Loss:1.133 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.049 AVG Test Loss:1.760 AVG Training Acc 39.39 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.973 AVG Test Loss:0.905 AVG Training Acc 42.42 % AVG Test Acc 80.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.104 AVG Test Loss:1.356 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.149 AVG Test Loss:1.505 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 18.181818181818183 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 30.227272727272727 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.908 AVG Test Loss:1.452 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.081 AVG Test Loss:1.012 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.953 AVG Test Loss:0.707 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.162 AVG Test Loss:0.882 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.077 AVG Test Loss:1.592 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.885 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.951 AVG Test Loss:0.861 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.988 AVG Test Loss:1.051 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.072 AVG Test Loss:0.781 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.029 AVG Test Loss:0.989 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.105 AVG Test Loss:1.022 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.968 AVG Test Loss:1.134 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.957 AVG Test Loss:1.126 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.047 AVG Test Loss:1.150 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.044 AVG Test Loss:0.790 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.019 AVG Test Loss:1.745 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.181 AVG Test Loss:1.743 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.061 AVG Test Loss:0.989 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.120 AVG Test Loss:1.251 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.919 AVG Test Loss:0.933 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:1.075 AVG Test Loss:1.148 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:0.941 AVG Test Loss:0.999 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:1.010 AVG Test Loss:1.683 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.975 AVG Test Loss:0.996 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.021 AVG Test Loss:0.675 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:1.002 AVG Test Loss:1.464 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.082 AVG Test Loss:1.406 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:19/20 AVG Training Loss:0.993 AVG Test Loss:0.950 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.144 AVG Test Loss:1.021 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.057 AVG Test Loss:1.449 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.071 AVG Test Loss:1.130 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.040 AVG Test Loss:1.030 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.214 AVG Test Loss:0.783 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.019 AVG Test Loss:0.960 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.018 AVG Test Loss:1.486 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.065 AVG Test Loss:2.094 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.148 AVG Test Loss:0.839 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.043 AVG Test Loss:1.128 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.017 AVG Test Loss:0.985 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.968 AVG Test Loss:0.508 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.966 AVG Test Loss:1.684 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.076 AVG Test Loss:1.367 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.176 AVG Test Loss:1.268 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 58.18181818181818 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.087 AVG Test Loss:1.141 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.994 AVG Test Loss:1.450 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.091 AVG Test Loss:0.879 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.127 AVG Test Loss:0.779 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.147 AVG Test Loss:1.239 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.058 AVG Test Loss:0.825 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.077 AVG Test Loss:0.590 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.028 AVG Test Loss:0.870 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.935 AVG Test Loss:0.928 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.162 AVG Test Loss:0.854 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.910 AVG Test Loss:2.653 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.046 AVG Test Loss:1.761 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.006 AVG Test Loss:1.789 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:0.962 AVG Test Loss:1.122 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.088 AVG Test Loss:0.937 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.025 AVG Test Loss:0.812 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:1.110 AVG Test Loss:1.289 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:0.988 AVG Test Loss:2.302 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.111 AVG Test Loss:1.043 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:1.075 AVG Test Loss:1.914 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.946 AVG Test Loss:1.866 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:0.922 AVG Test Loss:1.639 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:1.108 AVG Test Loss:1.208 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:1.183 AVG Test Loss:0.655 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.979 AVG Test Loss:0.937 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.054 AVG Test Loss:0.885 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.941 AVG Test Loss:0.741 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.956 AVG Test Loss:1.007 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.917 AVG Test Loss:1.598 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.120 AVG Test Loss:1.263 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.958 AVG Test Loss:1.618 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.058 AVG Test Loss:0.448 AVG Training Acc 53.12 % AVG Test Acc 90.91 %\n",
            "Epoch:9/20 AVG Training Loss:0.971 AVG Test Loss:0.720 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.012 AVG Test Loss:1.560 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.906 AVG Test Loss:1.442 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:0.987 AVG Test Loss:1.157 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.152 AVG Test Loss:2.044 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.981 AVG Test Loss:1.182 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.071 AVG Test Loss:1.173 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.140 AVG Test Loss:1.302 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 53.40909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.031 AVG Test Loss:1.599 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.957 AVG Test Loss:1.084 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:0.947 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.048 AVG Test Loss:0.388 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.006 AVG Test Loss:1.232 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.889 AVG Test Loss:0.965 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.002 AVG Test Loss:0.789 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.849 AVG Test Loss:0.646 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.974 AVG Test Loss:1.808 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.160 AVG Test Loss:0.942 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.988 AVG Test Loss:1.325 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.952 AVG Test Loss:0.862 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.999 AVG Test Loss:0.853 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.079 AVG Test Loss:1.137 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.045 AVG Test Loss:0.742 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.995 AVG Test Loss:1.019 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.954 AVG Test Loss:0.767 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.005 AVG Test Loss:0.838 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.976 AVG Test Loss:2.442 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:0.900 AVG Test Loss:1.357 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.966 AVG Test Loss:1.075 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.122 AVG Test Loss:0.512 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.068 AVG Test Loss:1.231 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.947 AVG Test Loss:1.088 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.084 AVG Test Loss:1.310 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.211 AVG Test Loss:1.324 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 57.72727272727273 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.024 AVG Test Loss:1.125 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.070 AVG Test Loss:1.096 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.053 AVG Test Loss:0.694 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.960 AVG Test Loss:0.797 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.093 AVG Test Loss:1.183 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:0.924 AVG Test Loss:0.772 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.046 AVG Test Loss:0.799 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.957 AVG Test Loss:0.953 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.062 AVG Test Loss:1.267 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.085 AVG Test Loss:0.580 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.993 AVG Test Loss:0.957 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.005 AVG Test Loss:1.064 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.048 AVG Test Loss:1.728 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.960 AVG Test Loss:0.990 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.952 AVG Test Loss:1.398 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.941 AVG Test Loss:0.854 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.946 AVG Test Loss:0.509 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.042 AVG Test Loss:1.115 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.075 AVG Test Loss:0.829 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.998 AVG Test Loss:1.076 AVG Training Acc 66.67 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.010 AVG Test Loss:0.805 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.026 AVG Test Loss:0.892 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 51.36363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.939 AVG Test Loss:1.312 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.112 AVG Test Loss:1.152 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.018 AVG Test Loss:0.446 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.055 AVG Test Loss:0.819 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.939 AVG Test Loss:0.782 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.135 AVG Test Loss:0.219 AVG Training Acc 50.00 % AVG Test Acc 90.91 %\n",
            "Epoch:7/20 AVG Training Loss:1.044 AVG Test Loss:1.988 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.945 AVG Test Loss:0.603 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.153 AVG Test Loss:2.276 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.048 AVG Test Loss:1.609 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.953 AVG Test Loss:1.163 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.121 AVG Test Loss:2.073 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:1.100 AVG Test Loss:2.153 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:1.024 AVG Test Loss:1.535 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:1.071 AVG Test Loss:2.165 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:16/20 AVG Training Loss:1.048 AVG Test Loss:1.277 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.962 AVG Test Loss:0.758 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:0.978 AVG Test Loss:1.239 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.928 AVG Test Loss:0.771 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:0.863 AVG Test Loss:1.563 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.139 AVG Test Loss:0.721 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.995 AVG Test Loss:0.891 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.953 AVG Test Loss:0.708 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.928 AVG Test Loss:1.234 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.005 AVG Test Loss:0.982 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:1.093 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.026 AVG Test Loss:1.075 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.127 AVG Test Loss:1.066 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.094 AVG Test Loss:1.224 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.897 AVG Test Loss:1.964 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.996 AVG Test Loss:0.964 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.080 AVG Test Loss:1.109 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.128 AVG Test Loss:1.026 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.227 AVG Test Loss:1.607 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.034 AVG Test Loss:0.706 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.065 AVG Test Loss:1.196 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.052 AVG Test Loss:1.431 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.044 AVG Test Loss:0.870 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.116 AVG Test Loss:0.866 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.170 AVG Test Loss:0.481 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 58.4090909090909 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:1.073 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.158 AVG Test Loss:0.722 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.033 AVG Test Loss:1.187 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.052 AVG Test Loss:1.191 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.027 AVG Test Loss:0.721 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.179 AVG Test Loss:1.196 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.136 AVG Test Loss:0.867 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.057 AVG Test Loss:1.274 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.059 AVG Test Loss:1.676 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.195 AVG Test Loss:1.294 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.196 AVG Test Loss:1.201 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.318 AVG Test Loss:1.822 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.081 AVG Test Loss:1.136 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.992 AVG Test Loss:0.321 AVG Training Acc 53.12 % AVG Test Acc 90.91 %\n",
            "Epoch:5/20 AVG Training Loss:0.993 AVG Test Loss:0.755 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:1.088 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.102 AVG Test Loss:0.688 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.947 AVG Test Loss:0.987 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.042 AVG Test Loss:1.207 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.978 AVG Test Loss:0.894 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.153 AVG Test Loss:1.158 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.019 AVG Test Loss:1.542 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.938 AVG Test Loss:1.620 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.177 AVG Test Loss:1.008 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.063 AVG Test Loss:0.595 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.983 AVG Test Loss:0.695 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.171 AVG Test Loss:0.831 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.028 AVG Test Loss:0.673 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:1.158 AVG Test Loss:1.575 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.030 AVG Test Loss:2.403 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:15/20 AVG Training Loss:1.092 AVG Test Loss:0.526 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:0.917 AVG Test Loss:1.703 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.074 AVG Test Loss:1.637 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.076 AVG Test Loss:0.567 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.071 AVG Test Loss:1.545 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.227 AVG Test Loss:0.644 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.226 AVG Test Loss:1.110 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.147 AVG Test Loss:0.812 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.024 AVG Test Loss:1.630 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.034 AVG Test Loss:1.363 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.104 AVG Test Loss:1.096 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 81.81818181818183 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 50.68181818181819 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.173 AVG Test Loss:1.290 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.975 AVG Test Loss:0.871 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.077 AVG Test Loss:1.210 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.103 AVG Test Loss:0.557 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.063 AVG Test Loss:0.831 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:1.138 AVG Test Loss:0.791 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.002 AVG Test Loss:0.704 AVG Training Acc 37.50 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.199 AVG Test Loss:0.945 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.060 AVG Test Loss:0.896 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.091 AVG Test Loss:0.970 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.108 AVG Test Loss:0.572 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.100 AVG Test Loss:1.549 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.076 AVG Test Loss:0.897 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:0.848 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.171 AVG Test Loss:0.538 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.033 AVG Test Loss:1.447 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.112 AVG Test Loss:0.914 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.137 AVG Test Loss:1.463 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.055 AVG Test Loss:1.118 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.936 AVG Test Loss:1.014 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:0.776 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.018 AVG Test Loss:0.962 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 53.84615384615385 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 53.46153846153846 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.127 AVG Test Loss:1.266 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.124 AVG Test Loss:0.921 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.931 AVG Test Loss:0.685 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.057 AVG Test Loss:0.718 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.130 AVG Test Loss:1.018 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.111 AVG Test Loss:1.280 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.015 AVG Test Loss:1.162 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.091 AVG Test Loss:1.239 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.050 AVG Test Loss:1.328 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.021 AVG Test Loss:1.179 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.110 AVG Test Loss:1.527 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.025 AVG Test Loss:1.552 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.041 AVG Test Loss:1.690 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.953 AVG Test Loss:0.827 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.042 AVG Test Loss:0.895 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.949 AVG Test Loss:1.821 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.034 AVG Test Loss:1.674 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.037 AVG Test Loss:1.809 AVG Training Acc 62.50 % AVG Test Acc 18.18 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.174 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.018 AVG Test Loss:0.858 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.932 AVG Test Loss:1.357 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.020 AVG Test Loss:1.164 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.116 AVG Test Loss:0.951 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.969 AVG Test Loss:1.295 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.167 AVG Test Loss:0.494 AVG Training Acc 54.55 % AVG Test Acc 90.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.131 AVG Test Loss:0.684 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.953 AVG Test Loss:1.034 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.997 AVG Test Loss:1.134 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.085 AVG Test Loss:1.050 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 18.181818181818183 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 46.81818181818181 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.187 AVG Test Loss:1.162 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.104 AVG Test Loss:1.084 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.101 AVG Test Loss:0.640 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.925 AVG Test Loss:1.408 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.024 AVG Test Loss:1.686 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:1.006 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.008 AVG Test Loss:1.211 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.021 AVG Test Loss:0.965 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.014 AVG Test Loss:0.623 AVG Training Acc 34.38 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.093 AVG Test Loss:0.754 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.266 AVG Test Loss:1.586 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.063 AVG Test Loss:1.091 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.980 AVG Test Loss:0.842 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.947 AVG Test Loss:1.327 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.084 AVG Test Loss:1.002 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.311 AVG Test Loss:1.859 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.908 AVG Test Loss:0.886 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.962 AVG Test Loss:0.873 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.908 AVG Test Loss:1.597 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.278 AVG Test Loss:1.249 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.918 AVG Test Loss:1.113 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.040 AVG Test Loss:0.779 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.057 AVG Test Loss:0.822 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 42.04545454545454 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.167 AVG Test Loss:0.893 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.092 AVG Test Loss:1.187 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.093 AVG Test Loss:0.751 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.000 AVG Test Loss:0.643 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.940 AVG Test Loss:0.430 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.080 AVG Test Loss:1.076 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.163 AVG Test Loss:1.231 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.164 AVG Test Loss:1.032 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.174 AVG Test Loss:1.056 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.193 AVG Test Loss:0.993 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.998 AVG Test Loss:0.971 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.018 AVG Test Loss:1.496 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.019 AVG Test Loss:0.923 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.111 AVG Test Loss:1.140 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.922 AVG Test Loss:0.659 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.028 AVG Test Loss:1.222 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.040 AVG Test Loss:1.482 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 50.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.164 AVG Test Loss:1.245 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.965 AVG Test Loss:1.279 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.977 AVG Test Loss:0.900 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.013 AVG Test Loss:0.726 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.102 AVG Test Loss:1.089 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.002 AVG Test Loss:1.257 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.048 AVG Test Loss:0.848 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.026 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.003 AVG Test Loss:0.756 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.054 AVG Test Loss:1.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.016 AVG Test Loss:2.450 AVG Training Acc 53.12 % AVG Test Acc 9.09 %\n",
            "Epoch:8/20 AVG Training Loss:0.947 AVG Test Loss:0.837 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.925 AVG Test Loss:3.206 AVG Training Acc 40.62 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.157 AVG Test Loss:0.797 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.062 AVG Test Loss:1.220 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:0.946 AVG Test Loss:0.794 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:0.891 AVG Test Loss:0.727 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:1.209 AVG Test Loss:2.157 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:1.168 AVG Test Loss:1.005 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:16/20 AVG Training Loss:1.099 AVG Test Loss:2.124 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:0.977 AVG Test Loss:2.265 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:18/20 AVG Training Loss:1.083 AVG Test Loss:2.468 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:1.096 AVG Test Loss:1.794 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.000 AVG Test Loss:0.749 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.029 AVG Test Loss:1.148 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.994 AVG Test Loss:1.021 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.052 AVG Test Loss:1.394 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.093 AVG Test Loss:1.862 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.881 AVG Test Loss:1.147 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.069 AVG Test Loss:0.718 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.138 AVG Test Loss:0.638 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 44.827586206896555 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.16144200626959 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.117 AVG Test Loss:1.440 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:0.700 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.031 AVG Test Loss:0.772 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.100 AVG Test Loss:0.496 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.199 AVG Test Loss:1.004 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.161 AVG Test Loss:1.318 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.984 AVG Test Loss:1.102 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.174 AVG Test Loss:0.954 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.068 AVG Test Loss:1.302 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.127 AVG Test Loss:1.667 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.912 AVG Test Loss:1.002 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.939 AVG Test Loss:1.382 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.251 AVG Test Loss:2.144 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.997 AVG Test Loss:1.245 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.987 AVG Test Loss:1.403 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:1.136 AVG Test Loss:0.810 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.069 AVG Test Loss:0.946 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.000 AVG Test Loss:1.608 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.051 AVG Test Loss:0.573 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:0.978 AVG Test Loss:0.898 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.054 AVG Test Loss:2.888 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.086 AVG Test Loss:0.942 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.087 AVG Test Loss:1.170 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.125 AVG Test Loss:1.150 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.088 AVG Test Loss:0.641 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.055 AVG Test Loss:1.530 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.164 AVG Test Loss:1.743 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.217 AVG Test Loss:0.905 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 42.27272727272727 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.053 AVG Test Loss:1.312 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.970 AVG Test Loss:1.273 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.092 AVG Test Loss:1.082 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.974 AVG Test Loss:0.895 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.857 AVG Test Loss:0.932 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.108 AVG Test Loss:1.243 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.100 AVG Test Loss:0.339 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.134 AVG Test Loss:0.969 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.072 AVG Test Loss:1.597 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.135 AVG Test Loss:1.449 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.995 AVG Test Loss:1.676 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.098 AVG Test Loss:1.895 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.080 AVG Test Loss:0.798 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:1.090 AVG Test Loss:1.128 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:0.984 AVG Test Loss:0.861 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.088 AVG Test Loss:2.055 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:1.040 AVG Test Loss:1.421 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:1.077 AVG Test Loss:0.861 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:0.986 AVG Test Loss:1.333 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:1.114 AVG Test Loss:3.181 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.169 AVG Test Loss:1.070 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.936 AVG Test Loss:1.550 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.148 AVG Test Loss:1.371 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.097 AVG Test Loss:1.407 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.001 AVG Test Loss:1.008 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.936 AVG Test Loss:1.636 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.153 AVG Test Loss:0.677 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.008 AVG Test Loss:1.649 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.002 AVG Test Loss:1.116 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.008 AVG Test Loss:1.193 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.124 AVG Test Loss:1.200 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.029 AVG Test Loss:0.756 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.035 AVG Test Loss:1.513 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.156 AVG Test Loss:1.242 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.039 AVG Test Loss:1.109 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.128 AVG Test Loss:0.835 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.136 AVG Test Loss:0.335 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 18.181818181818183 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 54.54545454545454 %\n",
            " Average acc: 45.45454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.081 AVG Test Loss:1.282 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.982 AVG Test Loss:1.170 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.072 AVG Test Loss:0.711 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.082 AVG Test Loss:0.822 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.002 AVG Test Loss:1.076 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.125 AVG Test Loss:1.242 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.120 AVG Test Loss:1.608 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.147 AVG Test Loss:1.331 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.988 AVG Test Loss:1.414 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.144 AVG Test Loss:1.695 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.956 AVG Test Loss:2.636 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.086 AVG Test Loss:1.780 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.020 AVG Test Loss:2.064 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.226 AVG Test Loss:0.912 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:1.076 AVG Test Loss:1.507 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.053 AVG Test Loss:1.294 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.054 AVG Test Loss:0.534 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:1.016 AVG Test Loss:1.808 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.032 AVG Test Loss:1.555 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:0.917 AVG Test Loss:1.733 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:0.999 AVG Test Loss:2.097 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:1.087 AVG Test Loss:0.575 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.151 AVG Test Loss:1.367 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.137 AVG Test Loss:1.485 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.035 AVG Test Loss:0.960 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.021 AVG Test Loss:1.195 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.126 AVG Test Loss:0.615 AVG Training Acc 40.62 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.034 AVG Test Loss:1.445 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.054 AVG Test Loss:1.197 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.112 AVG Test Loss:2.118 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.037 AVG Test Loss:1.081 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.220 AVG Test Loss:0.804 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.989 AVG Test Loss:0.994 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.189 AVG Test Loss:0.767 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.975 AVG Test Loss:1.552 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.087 AVG Test Loss:1.373 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.009 AVG Test Loss:1.389 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.104 AVG Test Loss:1.361 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.047 AVG Test Loss:1.660 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.058 AVG Test Loss:0.713 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.022 AVG Test Loss:1.490 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.071 AVG Test Loss:1.124 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.088 AVG Test Loss:0.939 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 46.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.981 AVG Test Loss:1.417 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.132 AVG Test Loss:0.861 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.241 AVG Test Loss:1.284 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.970 AVG Test Loss:1.520 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.906 AVG Test Loss:1.600 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.981 AVG Test Loss:0.684 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.918 AVG Test Loss:1.315 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.019 AVG Test Loss:1.466 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:0.969 AVG Test Loss:2.061 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.196 AVG Test Loss:1.681 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.126 AVG Test Loss:1.482 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.027 AVG Test Loss:2.172 AVG Training Acc 59.38 % AVG Test Acc 9.09 %\n",
            "Epoch:10/20 AVG Training Loss:1.020 AVG Test Loss:0.882 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:1.014 AVG Test Loss:2.379 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.019 AVG Test Loss:1.841 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.174 AVG Test Loss:1.800 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:1.389 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.024 AVG Test Loss:1.223 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.073 AVG Test Loss:1.249 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.119 AVG Test Loss:1.495 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.039 AVG Test Loss:1.067 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.190 AVG Test Loss:1.040 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:0.634 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.086 AVG Test Loss:0.829 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.077 AVG Test Loss:1.126 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.023 AVG Test Loss:0.920 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.034 AVG Test Loss:1.957 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.040 AVG Test Loss:0.821 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 44.827586206896555 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.43416927899686 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.132 AVG Test Loss:1.292 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.961 AVG Test Loss:1.006 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.127 AVG Test Loss:0.803 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.173 AVG Test Loss:1.442 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.157 AVG Test Loss:0.908 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.171 AVG Test Loss:1.164 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.942 AVG Test Loss:1.248 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.084 AVG Test Loss:0.797 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.917 AVG Test Loss:1.237 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.086 AVG Test Loss:1.142 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.004 AVG Test Loss:1.826 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.027 AVG Test Loss:1.096 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.070 AVG Test Loss:0.768 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.010 AVG Test Loss:1.043 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.061 AVG Test Loss:1.396 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.111 AVG Test Loss:1.190 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.983 AVG Test Loss:1.311 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.974 AVG Test Loss:1.110 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.019 AVG Test Loss:1.426 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.149 AVG Test Loss:1.213 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 48.86363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.109 AVG Test Loss:1.787 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.014 AVG Test Loss:1.072 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.043 AVG Test Loss:0.780 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.039 AVG Test Loss:0.657 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.978 AVG Test Loss:0.746 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.068 AVG Test Loss:0.532 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.111 AVG Test Loss:0.708 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.916 AVG Test Loss:0.762 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.005 AVG Test Loss:1.094 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:1.187 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.935 AVG Test Loss:0.865 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.033 AVG Test Loss:0.645 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.065 AVG Test Loss:1.569 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.100 AVG Test Loss:1.167 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.079 AVG Test Loss:0.574 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.016 AVG Test Loss:1.025 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.012 AVG Test Loss:0.650 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.146 AVG Test Loss:1.404 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.190 AVG Test Loss:1.106 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 51.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.040 AVG Test Loss:1.503 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.185 AVG Test Loss:1.260 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.967 AVG Test Loss:1.119 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.095 AVG Test Loss:1.130 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.057 AVG Test Loss:0.830 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.943 AVG Test Loss:1.562 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.147 AVG Test Loss:1.301 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:0.864 AVG Test Loss:0.780 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.016 AVG Test Loss:0.967 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:0.997 AVG Test Loss:1.410 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:1.053 AVG Test Loss:1.337 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.062 AVG Test Loss:0.752 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:0.966 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.031 AVG Test Loss:1.067 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.204 AVG Test Loss:1.410 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.111 AVG Test Loss:1.091 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.127 AVG Test Loss:1.214 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.936 AVG Test Loss:1.291 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.062 AVG Test Loss:1.462 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.992 AVG Test Loss:1.259 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.979 AVG Test Loss:1.917 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.001 AVG Test Loss:2.050 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.984 AVG Test Loss:1.464 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:1.161 AVG Test Loss:0.999 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:1.006 AVG Test Loss:1.252 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.004 AVG Test Loss:1.194 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.181 AVG Test Loss:1.812 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:1.094 AVG Test Loss:1.879 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Epoch:17/20 AVG Training Loss:1.031 AVG Test Loss:1.126 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:1.216 AVG Test Loss:1.469 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:1.080 AVG Test Loss:2.067 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:1.016 AVG Test Loss:1.351 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.935 AVG Test Loss:1.334 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.093 AVG Test Loss:0.833 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.026 AVG Test Loss:1.066 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.123 AVG Test Loss:1.410 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.041 AVG Test Loss:1.734 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.055 AVG Test Loss:1.283 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.983 AVG Test Loss:0.916 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.949 AVG Test Loss:2.667 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.178 AVG Test Loss:0.487 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.209 AVG Test Loss:1.211 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.118 AVG Test Loss:1.271 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.110 AVG Test Loss:1.079 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.132 AVG Test Loss:0.666 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.090 AVG Test Loss:0.854 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.088 AVG Test Loss:1.391 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.040 AVG Test Loss:1.300 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.101 AVG Test Loss:0.695 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.086 AVG Test Loss:1.974 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.036 AVG Test Loss:1.518 AVG Training Acc 48.48 % AVG Test Acc 10.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.085 AVG Test Loss:1.406 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.101 AVG Test Loss:1.123 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 55.68181818181818 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.112 AVG Test Loss:1.307 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.100 AVG Test Loss:1.102 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.877 AVG Test Loss:0.764 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.120 AVG Test Loss:0.705 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.058 AVG Test Loss:0.824 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.143 AVG Test Loss:0.792 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.947 AVG Test Loss:0.537 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.877 AVG Test Loss:1.781 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.998 AVG Test Loss:1.153 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.982 AVG Test Loss:1.769 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.943 AVG Test Loss:0.847 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.990 AVG Test Loss:1.252 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.065 AVG Test Loss:0.801 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.079 AVG Test Loss:1.512 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.869 AVG Test Loss:1.339 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.840 AVG Test Loss:1.183 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.977 AVG Test Loss:0.795 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.135 AVG Test Loss:1.133 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.139 AVG Test Loss:1.345 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.101 AVG Test Loss:0.820 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.031 AVG Test Loss:1.166 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.032 AVG Test Loss:1.056 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.023 AVG Test Loss:1.669 AVG Training Acc 40.62 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.038 AVG Test Loss:1.841 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.216 AVG Test Loss:1.556 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.120 AVG Test Loss:1.277 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.926 AVG Test Loss:1.469 AVG Training Acc 66.67 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:1.172 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.148 AVG Test Loss:0.456 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 53.86363636363636 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.107 AVG Test Loss:1.109 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.058 AVG Test Loss:1.095 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.054 AVG Test Loss:0.870 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.029 AVG Test Loss:1.221 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.129 AVG Test Loss:0.664 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.034 AVG Test Loss:0.848 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.000 AVG Test Loss:1.695 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.068 AVG Test Loss:1.313 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.946 AVG Test Loss:0.997 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.116 AVG Test Loss:0.832 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.118 AVG Test Loss:1.430 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.972 AVG Test Loss:1.450 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.138 AVG Test Loss:0.834 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.972 AVG Test Loss:1.415 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.929 AVG Test Loss:1.543 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.075 AVG Test Loss:1.340 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.907 AVG Test Loss:1.464 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.942 AVG Test Loss:0.896 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.202 AVG Test Loss:1.375 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.172 AVG Test Loss:1.031 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.078 AVG Test Loss:1.359 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.206 AVG Test Loss:1.090 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.006 AVG Test Loss:1.091 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.117 AVG Test Loss:0.883 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.974 AVG Test Loss:0.818 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.988 AVG Test Loss:1.173 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.968 AVG Test Loss:1.425 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.860 AVG Test Loss:0.750 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.994 AVG Test Loss:1.147 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.963 AVG Test Loss:0.874 AVG Training Acc 62.50 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:0.942 AVG Test Loss:1.186 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.966 AVG Test Loss:1.274 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:1.069 AVG Test Loss:0.880 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.969 AVG Test Loss:1.173 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.967 AVG Test Loss:0.714 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.146 AVG Test Loss:0.478 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.063 AVG Test Loss:0.895 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.081 AVG Test Loss:1.379 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.112 AVG Test Loss:1.352 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 50.0 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 54.54545454545454 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.085 AVG Test Loss:1.254 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.013 AVG Test Loss:1.352 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.019 AVG Test Loss:0.663 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.181 AVG Test Loss:0.762 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.326 AVG Test Loss:1.521 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.961 AVG Test Loss:1.017 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.972 AVG Test Loss:1.159 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.077 AVG Test Loss:1.140 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.986 AVG Test Loss:0.935 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.083 AVG Test Loss:0.704 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.013 AVG Test Loss:1.248 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.090 AVG Test Loss:0.941 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.182 AVG Test Loss:1.351 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.113 AVG Test Loss:0.796 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.049 AVG Test Loss:1.038 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.161 AVG Test Loss:1.157 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.011 AVG Test Loss:0.554 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.175 AVG Test Loss:1.198 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:1.312 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.884 AVG Test Loss:1.802 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.111 AVG Test Loss:1.188 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.029 AVG Test Loss:1.095 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.072 AVG Test Loss:1.561 AVG Training Acc 48.48 % AVG Test Acc 20.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.073 AVG Test Loss:2.372 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 48.63636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.029 AVG Test Loss:1.399 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.230 AVG Test Loss:1.359 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.150 AVG Test Loss:1.184 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:1.156 AVG Test Loss:0.904 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.940 AVG Test Loss:0.586 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:0.774 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.098 AVG Test Loss:1.367 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.295 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.835 AVG Test Loss:1.084 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.065 AVG Test Loss:1.442 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.152 AVG Test Loss:1.161 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.179 AVG Test Loss:0.746 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.976 AVG Test Loss:0.794 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.090 AVG Test Loss:1.587 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.953 AVG Test Loss:1.070 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.957 AVG Test Loss:1.680 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.219 AVG Test Loss:1.285 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.118 AVG Test Loss:1.056 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.973 AVG Test Loss:0.606 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.927 AVG Test Loss:0.960 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.996 AVG Test Loss:0.447 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.213 AVG Test Loss:1.041 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 39.77272727272727 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.004 AVG Test Loss:1.055 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.112 AVG Test Loss:1.271 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.102 AVG Test Loss:0.976 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.064 AVG Test Loss:1.182 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.034 AVG Test Loss:1.225 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.935 AVG Test Loss:1.041 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.018 AVG Test Loss:0.870 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.972 AVG Test Loss:1.800 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.908 AVG Test Loss:1.158 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.088 AVG Test Loss:2.219 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.998 AVG Test Loss:0.750 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.002 AVG Test Loss:1.988 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:13/20 AVG Training Loss:1.172 AVG Test Loss:1.665 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.072 AVG Test Loss:1.341 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.035 AVG Test Loss:1.136 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.182 AVG Test Loss:1.165 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.054 AVG Test Loss:1.710 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.062 AVG Test Loss:0.876 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.045 AVG Test Loss:1.224 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.172 AVG Test Loss:2.447 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.973 AVG Test Loss:1.306 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.943 AVG Test Loss:1.039 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.024 AVG Test Loss:1.880 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:1.066 AVG Test Loss:0.887 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.089 AVG Test Loss:1.339 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.985 AVG Test Loss:1.185 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.993 AVG Test Loss:1.137 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.955 AVG Test Loss:0.624 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.006 AVG Test Loss:1.153 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.163 AVG Test Loss:0.888 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.919 AVG Test Loss:1.103 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.004 AVG Test Loss:0.829 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.008 AVG Test Loss:0.412 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 51.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.964 AVG Test Loss:1.016 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.036 AVG Test Loss:0.855 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.048 AVG Test Loss:0.956 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.179 AVG Test Loss:1.120 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.153 AVG Test Loss:0.802 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.207 AVG Test Loss:1.379 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.993 AVG Test Loss:0.590 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.004 AVG Test Loss:1.400 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.186 AVG Test Loss:1.498 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.145 AVG Test Loss:1.295 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.082 AVG Test Loss:1.269 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.137 AVG Test Loss:1.275 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.975 AVG Test Loss:1.311 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.077 AVG Test Loss:0.897 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.221 AVG Test Loss:1.554 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.020 AVG Test Loss:1.147 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.123 AVG Test Loss:1.179 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.082 AVG Test Loss:0.740 AVG Training Acc 39.39 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.986 AVG Test Loss:1.103 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.189 AVG Test Loss:2.202 AVG Training Acc 60.61 % AVG Test Acc 20.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.938 AVG Test Loss:2.166 AVG Training Acc 48.48 % AVG Test Acc 20.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.016 AVG Test Loss:0.730 AVG Training Acc 42.42 % AVG Test Acc 80.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.062 AVG Test Loss:0.874 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.59090909090909 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.256 AVG Test Loss:1.254 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.049 AVG Test Loss:1.116 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.031 AVG Test Loss:0.993 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.907 AVG Test Loss:1.251 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.054 AVG Test Loss:0.462 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.020 AVG Test Loss:0.755 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:0.918 AVG Test Loss:1.010 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.877 AVG Test Loss:0.744 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.151 AVG Test Loss:1.442 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.022 AVG Test Loss:1.456 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.112 AVG Test Loss:1.394 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.103 AVG Test Loss:1.909 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.992 AVG Test Loss:1.115 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.026 AVG Test Loss:1.460 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.020 AVG Test Loss:0.834 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:0.897 AVG Test Loss:1.411 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.001 AVG Test Loss:0.855 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:1.053 AVG Test Loss:2.695 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.161 AVG Test Loss:1.127 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.207 AVG Test Loss:0.912 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.004 AVG Test Loss:0.702 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.068 AVG Test Loss:0.787 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.064 AVG Test Loss:1.985 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.946 AVG Test Loss:1.466 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:7/20 AVG Training Loss:1.097 AVG Test Loss:1.068 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.009 AVG Test Loss:0.545 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:1.032 AVG Test Loss:1.045 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:0.895 AVG Test Loss:0.821 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:1.054 AVG Test Loss:1.694 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:12/20 AVG Training Loss:0.969 AVG Test Loss:1.316 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.021 AVG Test Loss:2.166 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:14/20 AVG Training Loss:1.068 AVG Test Loss:1.230 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.053 AVG Test Loss:1.498 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.945 AVG Test Loss:1.110 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:1.436 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.164 AVG Test Loss:1.412 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.126 AVG Test Loss:1.210 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.062 AVG Test Loss:1.050 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.065 AVG Test Loss:0.928 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.940 AVG Test Loss:1.143 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.196 AVG Test Loss:0.596 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.058 AVG Test Loss:1.652 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.999 AVG Test Loss:1.774 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.085 AVG Test Loss:1.203 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.242 AVG Test Loss:1.076 AVG Training Acc 66.67 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.59090909090909 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.026 AVG Test Loss:1.207 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.963 AVG Test Loss:0.840 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.951 AVG Test Loss:0.665 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.105 AVG Test Loss:0.499 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.034 AVG Test Loss:0.772 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.002 AVG Test Loss:0.998 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.088 AVG Test Loss:0.768 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.993 AVG Test Loss:0.677 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.218 AVG Test Loss:2.684 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.982 AVG Test Loss:1.692 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:11/20 AVG Training Loss:1.187 AVG Test Loss:0.941 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.090 AVG Test Loss:2.183 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.103 AVG Test Loss:0.612 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:1.095 AVG Test Loss:0.859 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.971 AVG Test Loss:1.013 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:1.001 AVG Test Loss:0.896 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.018 AVG Test Loss:1.315 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.216 AVG Test Loss:1.264 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.415 AVG Test Loss:0.724 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.237 AVG Test Loss:1.553 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.987 AVG Test Loss:0.508 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.321 AVG Test Loss:0.782 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.947 AVG Test Loss:1.255 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.972 AVG Test Loss:0.433 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.960 AVG Test Loss:1.384 AVG Training Acc 68.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.014 AVG Test Loss:1.335 AVG Training Acc 59.38 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.105 AVG Test Loss:1.051 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.131 AVG Test Loss:1.145 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.948 AVG Test Loss:1.411 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:1.017 AVG Test Loss:1.170 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.068 AVG Test Loss:1.023 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.068 AVG Test Loss:1.294 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.057 AVG Test Loss:0.847 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:1.044 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.967 AVG Test Loss:1.052 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.069 AVG Test Loss:0.879 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.923 AVG Test Loss:0.416 AVG Training Acc 54.55 % AVG Test Acc 90.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.059 AVG Test Loss:0.794 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.942 AVG Test Loss:0.377 AVG Training Acc 60.61 % AVG Test Acc 90.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.137 AVG Test Loss:0.702 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.054 AVG Test Loss:1.951 AVG Training Acc 36.36 % AVG Test Acc 20.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.286 AVG Test Loss:1.772 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.081 AVG Test Loss:1.245 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.026 AVG Test Loss:1.486 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.115 AVG Test Loss:1.150 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.125 AVG Test Loss:1.533 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 55.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.974 AVG Test Loss:1.086 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.142 AVG Test Loss:1.047 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.050 AVG Test Loss:1.304 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.035 AVG Test Loss:0.728 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.924 AVG Test Loss:1.206 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.991 AVG Test Loss:0.711 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.050 AVG Test Loss:1.035 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.011 AVG Test Loss:1.783 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.002 AVG Test Loss:1.650 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.037 AVG Test Loss:0.832 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.218 AVG Test Loss:1.006 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.999 AVG Test Loss:1.389 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.122 AVG Test Loss:0.887 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.885 AVG Test Loss:1.200 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.944 AVG Test Loss:1.260 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.915 AVG Test Loss:0.807 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.036 AVG Test Loss:1.281 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.178 AVG Test Loss:2.505 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.087 AVG Test Loss:1.167 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.929 AVG Test Loss:1.740 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.077 AVG Test Loss:1.262 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.981 AVG Test Loss:0.953 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.021 AVG Test Loss:0.258 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.929 AVG Test Loss:0.865 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.036 AVG Test Loss:1.128 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.988 AVG Test Loss:2.918 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.024 AVG Test Loss:1.632 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.071 AVG Test Loss:0.951 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 44.827586206896555 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 51.206896551724135 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.839 AVG Test Loss:1.136 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.152 AVG Test Loss:1.171 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.187 AVG Test Loss:0.981 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.138 AVG Test Loss:1.383 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.174 AVG Test Loss:1.174 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.007 AVG Test Loss:1.665 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.045 AVG Test Loss:1.523 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.059 AVG Test Loss:0.806 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.165 AVG Test Loss:1.405 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.201 AVG Test Loss:0.893 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.062 AVG Test Loss:1.286 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.008 AVG Test Loss:1.286 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.914 AVG Test Loss:0.786 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.938 AVG Test Loss:1.569 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.983 AVG Test Loss:2.396 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.016 AVG Test Loss:1.132 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.942 AVG Test Loss:0.874 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.030 AVG Test Loss:0.823 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.287 AVG Test Loss:0.478 AVG Training Acc 51.52 % AVG Test Acc 90.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 59.09090909090909 %\n",
            " Average acc: 55.68181818181818 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.001 AVG Test Loss:1.040 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.164 AVG Test Loss:1.012 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.014 AVG Test Loss:0.850 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.108 AVG Test Loss:0.659 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.934 AVG Test Loss:1.570 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.029 AVG Test Loss:0.864 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.164 AVG Test Loss:1.422 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.022 AVG Test Loss:1.848 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.033 AVG Test Loss:0.816 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.921 AVG Test Loss:1.354 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.053 AVG Test Loss:2.138 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.101 AVG Test Loss:0.633 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.029 AVG Test Loss:1.097 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.004 AVG Test Loss:1.029 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.001 AVG Test Loss:1.474 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.989 AVG Test Loss:1.122 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.980 AVG Test Loss:1.511 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.052 AVG Test Loss:0.651 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.959 AVG Test Loss:2.052 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.978 AVG Test Loss:0.967 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.897 AVG Test Loss:2.009 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.038 AVG Test Loss:1.370 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.108 AVG Test Loss:1.807 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.094 AVG Test Loss:1.395 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.116 AVG Test Loss:1.139 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.971 AVG Test Loss:0.890 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:0.722 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.198 AVG Test Loss:0.920 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.674 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.913 AVG Test Loss:1.031 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.046 AVG Test Loss:1.315 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.070 AVG Test Loss:1.544 AVG Training Acc 45.45 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 50.68181818181817 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.159 AVG Test Loss:1.466 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.064 AVG Test Loss:1.225 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.045 AVG Test Loss:1.119 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.053 AVG Test Loss:1.286 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.229 AVG Test Loss:0.945 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.005 AVG Test Loss:0.956 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.105 AVG Test Loss:0.947 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.945 AVG Test Loss:1.053 AVG Training Acc 65.62 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.899 AVG Test Loss:1.203 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.955 AVG Test Loss:1.370 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.172 AVG Test Loss:1.873 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.241 AVG Test Loss:1.180 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.098 AVG Test Loss:0.714 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.076 AVG Test Loss:0.415 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.127 AVG Test Loss:0.984 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.953 AVG Test Loss:0.627 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.160 AVG Test Loss:0.910 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.175 AVG Test Loss:0.663 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.903 AVG Test Loss:1.113 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.922 AVG Test Loss:1.025 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.974 AVG Test Loss:1.353 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 48.86363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.007 AVG Test Loss:1.745 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.014 AVG Test Loss:1.313 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.079 AVG Test Loss:1.155 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.264 AVG Test Loss:1.114 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.071 AVG Test Loss:0.942 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.022 AVG Test Loss:0.924 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.067 AVG Test Loss:0.990 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.148 AVG Test Loss:1.791 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.040 AVG Test Loss:1.177 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.139 AVG Test Loss:1.086 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.051 AVG Test Loss:0.377 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.076 AVG Test Loss:0.727 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.052 AVG Test Loss:0.825 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.017 AVG Test Loss:0.725 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.016 AVG Test Loss:0.569 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.951 AVG Test Loss:1.339 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.002 AVG Test Loss:0.552 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.096 AVG Test Loss:1.055 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.039 AVG Test Loss:1.236 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.015 AVG Test Loss:1.244 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.116 AVG Test Loss:1.346 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.220 AVG Test Loss:0.938 AVG Training Acc 45.45 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.31818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.964 AVG Test Loss:1.943 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.033 AVG Test Loss:1.524 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.040 AVG Test Loss:1.126 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.077 AVG Test Loss:1.221 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.160 AVG Test Loss:1.052 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.923 AVG Test Loss:1.058 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.058 AVG Test Loss:1.440 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.071 AVG Test Loss:1.606 AVG Training Acc 65.62 % AVG Test Acc 9.09 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.051 AVG Test Loss:1.232 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.085 AVG Test Loss:0.795 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.051 AVG Test Loss:0.885 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.033 AVG Test Loss:0.343 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.177 AVG Test Loss:0.934 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:0.600 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.137 AVG Test Loss:0.530 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.219 AVG Test Loss:0.850 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.184 AVG Test Loss:1.391 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.072 AVG Test Loss:1.345 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.099 AVG Test Loss:1.461 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.067 AVG Test Loss:1.042 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.017 AVG Test Loss:0.943 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.005 AVG Test Loss:1.140 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.856 AVG Test Loss:0.916 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.055 AVG Test Loss:1.226 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.020 AVG Test Loss:1.527 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.932 AVG Test Loss:1.064 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.951 AVG Test Loss:1.801 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.014 AVG Test Loss:1.610 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 9.090909090909092 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 39.77272727272727 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.942 AVG Test Loss:1.721 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.094 AVG Test Loss:1.461 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.171 AVG Test Loss:1.229 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.141 AVG Test Loss:1.134 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.129 AVG Test Loss:0.868 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.099 AVG Test Loss:1.125 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.959 AVG Test Loss:1.647 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.027 AVG Test Loss:0.990 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.146 AVG Test Loss:0.559 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:0.956 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.180 AVG Test Loss:0.712 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.095 AVG Test Loss:0.583 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.132 AVG Test Loss:0.719 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.925 AVG Test Loss:0.419 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.053 AVG Test Loss:0.672 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.085 AVG Test Loss:0.970 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.006 AVG Test Loss:1.126 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.063 AVG Test Loss:0.736 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.112 AVG Test Loss:1.278 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 50.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.098 AVG Test Loss:1.699 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.012 AVG Test Loss:0.975 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.041 AVG Test Loss:0.810 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.092 AVG Test Loss:0.925 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.982 AVG Test Loss:1.377 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.093 AVG Test Loss:1.200 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.008 AVG Test Loss:0.882 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.959 AVG Test Loss:1.043 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.165 AVG Test Loss:1.272 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.084 AVG Test Loss:1.189 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.006 AVG Test Loss:1.098 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.991 AVG Test Loss:1.816 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.965 AVG Test Loss:1.606 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.140 AVG Test Loss:0.909 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.001 AVG Test Loss:1.365 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.011 AVG Test Loss:2.278 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.026 AVG Test Loss:1.116 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.145 AVG Test Loss:1.001 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.100 AVG Test Loss:0.802 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.940 AVG Test Loss:0.774 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.917 AVG Test Loss:0.714 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.980 AVG Test Loss:0.710 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.025 AVG Test Loss:1.954 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.078 AVG Test Loss:0.863 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.077 AVG Test Loss:1.316 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.093 AVG Test Loss:1.172 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.221 AVG Test Loss:1.188 AVG Training Acc 39.39 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 51.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.979 AVG Test Loss:1.250 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.921 AVG Test Loss:1.093 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.975 AVG Test Loss:1.284 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:0.792 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.109 AVG Test Loss:1.095 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.934 AVG Test Loss:1.136 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.909 AVG Test Loss:1.251 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.990 AVG Test Loss:0.984 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.055 AVG Test Loss:1.751 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.022 AVG Test Loss:0.940 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.006 AVG Test Loss:0.793 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.003 AVG Test Loss:0.476 AVG Training Acc 46.88 % AVG Test Acc 90.91 %\n",
            "Epoch:4/20 AVG Training Loss:1.007 AVG Test Loss:0.539 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.196 AVG Test Loss:0.893 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.038 AVG Test Loss:1.115 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.010 AVG Test Loss:0.868 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.005 AVG Test Loss:0.858 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.143 AVG Test Loss:0.767 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.141 AVG Test Loss:0.768 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.980 AVG Test Loss:1.153 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.058 AVG Test Loss:0.888 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.870 AVG Test Loss:1.473 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.015 AVG Test Loss:1.742 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.140 AVG Test Loss:1.308 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 45.45454545454545 %\n",
            " Average acc: 45.45454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.150 AVG Test Loss:1.698 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.155 AVG Test Loss:1.246 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.012 AVG Test Loss:0.837 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.132 AVG Test Loss:0.955 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.983 AVG Test Loss:1.083 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:1.033 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.051 AVG Test Loss:0.857 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.055 AVG Test Loss:0.848 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.074 AVG Test Loss:1.673 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.899 AVG Test Loss:1.248 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.913 AVG Test Loss:1.396 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.995 AVG Test Loss:1.222 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.006 AVG Test Loss:0.600 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:1.040 AVG Test Loss:0.637 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.138 AVG Test Loss:1.058 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.063 AVG Test Loss:0.903 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.996 AVG Test Loss:0.916 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.938 AVG Test Loss:0.936 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.149 AVG Test Loss:0.817 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.162 AVG Test Loss:0.809 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.31818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.025 AVG Test Loss:1.499 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.994 AVG Test Loss:1.267 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.010 AVG Test Loss:1.412 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.968 AVG Test Loss:0.777 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.978 AVG Test Loss:0.971 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.996 AVG Test Loss:1.492 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.974 AVG Test Loss:1.051 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.159 AVG Test Loss:0.837 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.062 AVG Test Loss:0.559 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.039 AVG Test Loss:0.987 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.063 AVG Test Loss:1.206 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.018 AVG Test Loss:2.422 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.085 AVG Test Loss:2.074 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:8/20 AVG Training Loss:1.022 AVG Test Loss:0.725 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.094 AVG Test Loss:2.054 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.119 AVG Test Loss:1.254 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.040 AVG Test Loss:0.756 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.000 AVG Test Loss:0.913 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.323 AVG Test Loss:0.748 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.002 AVG Test Loss:1.024 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.945 AVG Test Loss:1.138 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.128 AVG Test Loss:0.959 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.056 AVG Test Loss:0.929 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.953 AVG Test Loss:0.958 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.097 AVG Test Loss:0.781 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.119 AVG Test Loss:1.423 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.160 AVG Test Loss:0.978 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.067 AVG Test Loss:1.186 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.961 AVG Test Loss:0.893 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.009 AVG Test Loss:1.236 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.097 AVG Test Loss:1.071 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 48.275862068965516 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 47.523510971786834 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.210 AVG Test Loss:1.851 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.041 AVG Test Loss:1.106 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.986 AVG Test Loss:0.927 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.981 AVG Test Loss:0.753 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.103 AVG Test Loss:0.395 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:0.925 AVG Test Loss:1.456 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.002 AVG Test Loss:0.999 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.871 AVG Test Loss:2.221 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.058 AVG Test Loss:1.810 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.034 AVG Test Loss:2.112 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:1.268 AVG Test Loss:1.626 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.153 AVG Test Loss:0.658 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:1.015 AVG Test Loss:0.717 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:0.992 AVG Test Loss:1.487 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:1.124 AVG Test Loss:1.180 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.044 AVG Test Loss:2.043 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.893 AVG Test Loss:2.819 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:18/20 AVG Training Loss:1.001 AVG Test Loss:2.263 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.018 AVG Test Loss:1.007 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.944 AVG Test Loss:1.048 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.082 AVG Test Loss:1.206 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.954 AVG Test Loss:1.548 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.055 AVG Test Loss:1.364 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.106 AVG Test Loss:1.394 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.058 AVG Test Loss:1.093 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.066 AVG Test Loss:0.762 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.124 AVG Test Loss:0.504 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.099 AVG Test Loss:0.929 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.064 AVG Test Loss:0.952 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.106 AVG Test Loss:0.831 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.113 AVG Test Loss:1.488 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 51.724137931034484 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 52.70376175548589 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.991 AVG Test Loss:1.560 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.099 AVG Test Loss:1.168 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.093 AVG Test Loss:1.398 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.050 AVG Test Loss:1.291 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.092 AVG Test Loss:0.775 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:0.961 AVG Test Loss:0.621 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.964 AVG Test Loss:0.659 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.076 AVG Test Loss:1.256 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.019 AVG Test Loss:1.232 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.042 AVG Test Loss:0.780 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.991 AVG Test Loss:1.710 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.016 AVG Test Loss:1.398 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.070 AVG Test Loss:1.250 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.103 AVG Test Loss:1.204 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.083 AVG Test Loss:1.009 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.030 AVG Test Loss:0.485 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.068 AVG Test Loss:0.810 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.071 AVG Test Loss:0.538 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.174 AVG Test Loss:1.344 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.909 AVG Test Loss:1.295 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:1.080 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.189 AVG Test Loss:0.767 AVG Training Acc 36.36 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 51.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.622 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.069 AVG Test Loss:0.857 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.903 AVG Test Loss:1.165 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.937 AVG Test Loss:1.416 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.074 AVG Test Loss:0.991 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.052 AVG Test Loss:1.063 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.100 AVG Test Loss:1.179 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.132 AVG Test Loss:1.887 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.036 AVG Test Loss:1.287 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.839 AVG Test Loss:0.700 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.009 AVG Test Loss:0.530 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.042 AVG Test Loss:1.314 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.965 AVG Test Loss:1.068 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.222 AVG Test Loss:1.174 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.150 AVG Test Loss:1.226 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.122 AVG Test Loss:0.643 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.131 AVG Test Loss:1.563 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.991 AVG Test Loss:0.755 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.032 AVG Test Loss:0.965 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.967 AVG Test Loss:1.214 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.990 AVG Test Loss:0.542 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.095 AVG Test Loss:0.444 AVG Training Acc 42.42 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 63.18181818181819 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.033 AVG Test Loss:1.311 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.142 AVG Test Loss:1.046 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.047 AVG Test Loss:1.271 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.025 AVG Test Loss:0.870 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.073 AVG Test Loss:1.077 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.094 AVG Test Loss:1.626 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.001 AVG Test Loss:1.230 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.906 AVG Test Loss:1.339 AVG Training Acc 43.75 % AVG Test Acc 18.18 %\n",
            "Epoch:3/20 AVG Training Loss:1.062 AVG Test Loss:0.607 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.039 AVG Test Loss:1.130 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.083 AVG Test Loss:0.883 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.208 AVG Test Loss:2.027 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.206 AVG Test Loss:1.144 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.989 AVG Test Loss:0.833 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.085 AVG Test Loss:0.714 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.277 AVG Test Loss:0.754 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.059 AVG Test Loss:0.973 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.013 AVG Test Loss:1.203 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.970 AVG Test Loss:0.870 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.942 AVG Test Loss:1.582 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.037 AVG Test Loss:0.870 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.423 AVG Test Loss:0.939 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 44.54545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.190 AVG Test Loss:1.310 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.155 AVG Test Loss:1.540 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.095 AVG Test Loss:1.099 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.042 AVG Test Loss:0.469 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.081 AVG Test Loss:0.944 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.094 AVG Test Loss:1.242 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.085 AVG Test Loss:1.535 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.862 AVG Test Loss:0.923 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.193 AVG Test Loss:1.837 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.095 AVG Test Loss:1.541 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.087 AVG Test Loss:1.151 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.009 AVG Test Loss:1.830 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.950 AVG Test Loss:1.027 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.056 AVG Test Loss:1.656 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.974 AVG Test Loss:1.945 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.065 AVG Test Loss:1.246 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.916 AVG Test Loss:0.748 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.003 AVG Test Loss:1.336 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:0.942 AVG Test Loss:1.777 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.045 AVG Test Loss:1.012 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:1.041 AVG Test Loss:1.170 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.165 AVG Test Loss:1.297 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:1.061 AVG Test Loss:1.257 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:1.116 AVG Test Loss:0.471 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:1.147 AVG Test Loss:0.679 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.937 AVG Test Loss:0.818 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.905 AVG Test Loss:1.130 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.108 AVG Test Loss:0.996 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.089 AVG Test Loss:1.223 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.090 AVG Test Loss:0.648 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.051 AVG Test Loss:0.937 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.927 AVG Test Loss:1.136 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.044 AVG Test Loss:0.909 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.053 AVG Test Loss:1.872 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.003 AVG Test Loss:1.105 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.049 AVG Test Loss:1.080 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.153 AVG Test Loss:0.938 AVG Training Acc 39.39 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.31818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.012 AVG Test Loss:1.705 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.056 AVG Test Loss:1.350 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.915 AVG Test Loss:1.154 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.113 AVG Test Loss:1.302 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.238 AVG Test Loss:1.348 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.079 AVG Test Loss:1.348 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.948 AVG Test Loss:0.890 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.047 AVG Test Loss:1.036 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.059 AVG Test Loss:1.230 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.109 AVG Test Loss:1.003 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.085 AVG Test Loss:0.902 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.095 AVG Test Loss:0.740 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.068 AVG Test Loss:1.090 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.007 AVG Test Loss:1.108 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.022 AVG Test Loss:1.246 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.990 AVG Test Loss:0.553 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:0.952 AVG Test Loss:1.348 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.311 AVG Test Loss:1.035 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.193 AVG Test Loss:1.201 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.011 AVG Test Loss:0.763 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.054 AVG Test Loss:0.711 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.966 AVG Test Loss:1.452 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.969 AVG Test Loss:0.932 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:1.106 AVG Test Loss:1.553 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.187 AVG Test Loss:1.208 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.039 AVG Test Loss:1.377 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.023 AVG Test Loss:1.124 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.031 AVG Test Loss:1.688 AVG Training Acc 54.55 % AVG Test Acc 20.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.031 AVG Test Loss:1.387 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 50.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.080 AVG Test Loss:1.431 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.047 AVG Test Loss:0.853 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.870 AVG Test Loss:0.520 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.135 AVG Test Loss:1.491 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.001 AVG Test Loss:0.770 AVG Training Acc 37.50 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.940 AVG Test Loss:1.658 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.039 AVG Test Loss:1.637 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.920 AVG Test Loss:1.217 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.979 AVG Test Loss:0.892 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.001 AVG Test Loss:1.068 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.175 AVG Test Loss:1.187 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:0.707 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:1.049 AVG Test Loss:0.818 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.065 AVG Test Loss:1.097 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.940 AVG Test Loss:1.096 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.015 AVG Test Loss:1.077 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.011 AVG Test Loss:0.955 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.987 AVG Test Loss:0.588 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.046 AVG Test Loss:1.025 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.131 AVG Test Loss:1.975 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.980 AVG Test Loss:1.499 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.031 AVG Test Loss:1.378 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.066 AVG Test Loss:0.789 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 53.86363636363636 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.869 AVG Test Loss:1.840 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.038 AVG Test Loss:1.143 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.978 AVG Test Loss:1.263 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.149 AVG Test Loss:1.176 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.948 AVG Test Loss:1.935 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.163 AVG Test Loss:1.011 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.007 AVG Test Loss:0.999 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.039 AVG Test Loss:0.486 AVG Training Acc 59.38 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:1.143 AVG Test Loss:1.755 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.926 AVG Test Loss:1.517 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.005 AVG Test Loss:1.053 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.024 AVG Test Loss:1.084 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.961 AVG Test Loss:1.202 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.958 AVG Test Loss:0.962 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.956 AVG Test Loss:1.133 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.054 AVG Test Loss:0.489 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.088 AVG Test Loss:0.937 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.061 AVG Test Loss:1.149 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.935 AVG Test Loss:1.067 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.040 AVG Test Loss:1.327 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.007 AVG Test Loss:0.820 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.987 AVG Test Loss:0.569 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.001 AVG Test Loss:0.855 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.066 AVG Test Loss:1.050 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 44.827586206896555 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 53.479623824451416 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.194 AVG Test Loss:1.754 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:1.480 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.976 AVG Test Loss:0.516 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.076 AVG Test Loss:1.296 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.912 AVG Test Loss:0.962 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.087 AVG Test Loss:1.494 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.953 AVG Test Loss:2.179 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:0.918 AVG Test Loss:1.417 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.046 AVG Test Loss:2.605 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:0.962 AVG Test Loss:1.496 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.120 AVG Test Loss:1.621 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.067 AVG Test Loss:1.379 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.115 AVG Test Loss:0.707 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.967 AVG Test Loss:1.503 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.090 AVG Test Loss:1.131 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:1.013 AVG Test Loss:1.175 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:1.076 AVG Test Loss:1.246 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:18/20 AVG Training Loss:1.152 AVG Test Loss:2.436 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.102 AVG Test Loss:1.160 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.062 AVG Test Loss:0.686 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.163 AVG Test Loss:0.881 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.017 AVG Test Loss:0.867 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.069 AVG Test Loss:1.656 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:1.227 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.059 AVG Test Loss:1.140 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.292 AVG Test Loss:0.905 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.125 AVG Test Loss:0.840 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.125 AVG Test Loss:1.028 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.983 AVG Test Loss:0.863 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.122 AVG Test Loss:0.811 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.964 AVG Test Loss:0.885 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.048 AVG Test Loss:0.559 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.127 AVG Test Loss:1.217 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.054 AVG Test Loss:1.436 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.092 AVG Test Loss:1.197 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.033 AVG Test Loss:0.811 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.982 AVG Test Loss:0.689 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.994 AVG Test Loss:1.156 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.144 AVG Test Loss:1.299 AVG Training Acc 39.39 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 37.5 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.069 AVG Test Loss:1.728 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.014 AVG Test Loss:1.625 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.959 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.208 AVG Test Loss:0.911 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.030 AVG Test Loss:1.060 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:0.820 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.982 AVG Test Loss:0.983 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.934 AVG Test Loss:1.015 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.075 AVG Test Loss:2.403 AVG Training Acc 62.50 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.107 AVG Test Loss:1.712 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.942 AVG Test Loss:1.281 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.924 AVG Test Loss:0.636 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.910 AVG Test Loss:0.883 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.099 AVG Test Loss:1.112 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.934 AVG Test Loss:1.545 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.191 AVG Test Loss:0.597 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:1.125 AVG Test Loss:1.169 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.006 AVG Test Loss:0.754 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:1.101 AVG Test Loss:1.820 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.092 AVG Test Loss:0.573 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:1.040 AVG Test Loss:0.692 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.911 AVG Test Loss:0.959 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.090 AVG Test Loss:1.591 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:0.966 AVG Test Loss:1.034 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:15/20 AVG Training Loss:1.093 AVG Test Loss:0.794 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:1.187 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.001 AVG Test Loss:1.351 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.231 AVG Test Loss:1.000 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.102 AVG Test Loss:0.967 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.033 AVG Test Loss:1.164 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.040 AVG Test Loss:1.042 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.894 AVG Test Loss:1.079 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.969 AVG Test Loss:1.231 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.982 AVG Test Loss:0.707 AVG Training Acc 54.55 % AVG Test Acc 90.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 53.57142857142857 %\n",
            " Average acc: 49.756493506493506 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.189 AVG Test Loss:1.445 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.074 AVG Test Loss:0.778 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.022 AVG Test Loss:1.278 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.020 AVG Test Loss:0.840 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.964 AVG Test Loss:1.385 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.977 AVG Test Loss:0.731 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.030 AVG Test Loss:1.723 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.929 AVG Test Loss:1.372 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.010 AVG Test Loss:1.457 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.064 AVG Test Loss:0.989 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.085 AVG Test Loss:1.143 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.025 AVG Test Loss:0.881 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.962 AVG Test Loss:1.305 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.060 AVG Test Loss:0.958 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.159 AVG Test Loss:0.552 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.120 AVG Test Loss:1.251 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.147 AVG Test Loss:1.024 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.939 AVG Test Loss:1.447 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.132 AVG Test Loss:1.386 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.004 AVG Test Loss:0.838 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.996 AVG Test Loss:1.508 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.178 AVG Test Loss:1.320 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.110 AVG Test Loss:0.681 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.042 AVG Test Loss:0.685 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.111 AVG Test Loss:1.374 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.990 AVG Test Loss:0.476 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.062 AVG Test Loss:1.243 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.075 AVG Test Loss:1.874 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 27.27272727272727 %\n",
            "Fold 1 acc: 48.275862068965516 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 49.56896551724138 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.157 AVG Test Loss:1.090 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.102 AVG Test Loss:1.048 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.031 AVG Test Loss:1.016 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.190 AVG Test Loss:0.830 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.087 AVG Test Loss:1.878 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.952 AVG Test Loss:0.963 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.105 AVG Test Loss:1.336 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.984 AVG Test Loss:1.014 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.164 AVG Test Loss:0.925 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:0.964 AVG Test Loss:1.457 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.906 AVG Test Loss:0.779 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:1.063 AVG Test Loss:1.273 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.226 AVG Test Loss:1.371 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.925 AVG Test Loss:1.457 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.083 AVG Test Loss:0.647 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.028 AVG Test Loss:1.235 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.079 AVG Test Loss:1.191 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.991 AVG Test Loss:1.376 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.026 AVG Test Loss:1.475 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.187 AVG Test Loss:1.801 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.061 AVG Test Loss:1.112 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.975 AVG Test Loss:0.889 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.109 AVG Test Loss:0.865 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:0.852 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.107 AVG Test Loss:1.463 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.999 AVG Test Loss:0.674 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.142 AVG Test Loss:1.970 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.957 AVG Test Loss:0.524 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.112 AVG Test Loss:1.764 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.128 AVG Test Loss:0.303 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.921 AVG Test Loss:1.532 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.114 AVG Test Loss:1.164 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.040 AVG Test Loss:1.946 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.127 AVG Test Loss:1.673 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.001 AVG Test Loss:0.923 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.961 AVG Test Loss:1.577 AVG Training Acc 45.45 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.092 AVG Test Loss:1.153 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.021 AVG Test Loss:1.208 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.210 AVG Test Loss:1.470 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.129 AVG Test Loss:1.153 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.115 AVG Test Loss:1.591 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.080 AVG Test Loss:1.107 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.019 AVG Test Loss:0.481 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.156 AVG Test Loss:1.381 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:0.983 AVG Test Loss:0.378 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.082 AVG Test Loss:1.268 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.053 AVG Test Loss:1.058 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.974 AVG Test Loss:1.457 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.062 AVG Test Loss:1.123 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.200 AVG Test Loss:0.992 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 81.81818181818183 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 53.40909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.034 AVG Test Loss:1.582 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.130 AVG Test Loss:1.496 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.030 AVG Test Loss:1.183 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.036 AVG Test Loss:0.849 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.275 AVG Test Loss:0.520 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.094 AVG Test Loss:1.285 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.133 AVG Test Loss:1.534 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.931 AVG Test Loss:0.718 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.171 AVG Test Loss:1.177 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.231 AVG Test Loss:1.228 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.198 AVG Test Loss:1.437 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.171 AVG Test Loss:0.931 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.251 AVG Test Loss:1.028 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.980 AVG Test Loss:1.495 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.022 AVG Test Loss:1.088 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.099 AVG Test Loss:1.289 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.910 AVG Test Loss:1.079 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.060 AVG Test Loss:0.989 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.205 AVG Test Loss:1.207 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 58.18181818181818 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.032 AVG Test Loss:1.312 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.071 AVG Test Loss:1.123 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.008 AVG Test Loss:1.455 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.065 AVG Test Loss:0.765 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.990 AVG Test Loss:1.201 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.092 AVG Test Loss:1.346 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.146 AVG Test Loss:1.271 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.146 AVG Test Loss:1.111 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.174 AVG Test Loss:1.233 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.991 AVG Test Loss:0.892 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.045 AVG Test Loss:1.285 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.219 AVG Test Loss:1.902 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.935 AVG Test Loss:0.977 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.022 AVG Test Loss:0.926 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.058 AVG Test Loss:0.900 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.104 AVG Test Loss:1.204 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.094 AVG Test Loss:1.302 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.224 AVG Test Loss:1.352 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.008 AVG Test Loss:0.909 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.021 AVG Test Loss:0.968 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.021 AVG Test Loss:0.647 AVG Training Acc 45.45 % AVG Test Acc 80.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.947 AVG Test Loss:1.057 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.101 AVG Test Loss:1.339 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.085 AVG Test Loss:0.596 AVG Training Acc 57.58 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.102 AVG Test Loss:0.899 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.982 AVG Test Loss:2.139 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.209 AVG Test Loss:0.633 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.135 AVG Test Loss:1.640 AVG Training Acc 60.61 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.973 AVG Test Loss:0.903 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.076 AVG Test Loss:1.038 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.059 AVG Test Loss:1.395 AVG Training Acc 39.39 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:0.988 AVG Test Loss:0.918 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:18/20 AVG Training Loss:1.035 AVG Test Loss:1.648 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:1.027 AVG Test Loss:1.340 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:20/20 AVG Training Loss:0.870 AVG Test Loss:1.192 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 47.04545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.048 AVG Test Loss:1.355 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.151 AVG Test Loss:1.074 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.932 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.997 AVG Test Loss:1.342 AVG Training Acc 40.62 % AVG Test Acc 18.18 %\n",
            "Epoch:5/20 AVG Training Loss:1.088 AVG Test Loss:0.777 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.903 AVG Test Loss:1.438 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.124 AVG Test Loss:0.979 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.019 AVG Test Loss:0.748 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.037 AVG Test Loss:1.557 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.139 AVG Test Loss:1.028 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.125 AVG Test Loss:0.715 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.023 AVG Test Loss:0.906 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.996 AVG Test Loss:0.948 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.925 AVG Test Loss:0.684 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.010 AVG Test Loss:0.911 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.089 AVG Test Loss:1.044 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:1.236 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.103 AVG Test Loss:1.123 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.965 AVG Test Loss:0.898 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.057 AVG Test Loss:1.545 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.011 AVG Test Loss:1.192 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.070 AVG Test Loss:1.831 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.991 AVG Test Loss:0.947 AVG Training Acc 53.12 % AVG Test Acc 90.91 %\n",
            "Epoch:8/20 AVG Training Loss:1.051 AVG Test Loss:3.199 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.936 AVG Test Loss:1.589 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.931 AVG Test Loss:1.375 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:1.094 AVG Test Loss:2.724 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.025 AVG Test Loss:0.707 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:0.988 AVG Test Loss:1.719 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.930 AVG Test Loss:1.339 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.923 AVG Test Loss:0.617 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:1.019 AVG Test Loss:1.750 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:17/20 AVG Training Loss:1.085 AVG Test Loss:1.526 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.939 AVG Test Loss:1.142 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.233 AVG Test Loss:1.416 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.999 AVG Test Loss:1.379 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.070 AVG Test Loss:1.688 AVG Training Acc 39.39 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.052 AVG Test Loss:2.058 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.002 AVG Test Loss:1.472 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.016 AVG Test Loss:0.884 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.020 AVG Test Loss:1.461 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 50.68181818181819 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.963 AVG Test Loss:1.289 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.011 AVG Test Loss:1.001 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.117 AVG Test Loss:1.031 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.972 AVG Test Loss:1.124 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.092 AVG Test Loss:1.047 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.989 AVG Test Loss:1.003 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.989 AVG Test Loss:1.194 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.010 AVG Test Loss:1.282 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.038 AVG Test Loss:1.483 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.936 AVG Test Loss:0.898 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.165 AVG Test Loss:0.908 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.125 AVG Test Loss:1.533 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.044 AVG Test Loss:1.060 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.036 AVG Test Loss:1.285 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.934 AVG Test Loss:1.689 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.994 AVG Test Loss:1.562 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.074 AVG Test Loss:2.812 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.998 AVG Test Loss:0.979 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.095 AVG Test Loss:0.409 AVG Training Acc 54.55 % AVG Test Acc 90.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.195 AVG Test Loss:1.007 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 49.09090909090909 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.177 AVG Test Loss:1.293 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.098 AVG Test Loss:1.319 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.216 AVG Test Loss:1.617 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.078 AVG Test Loss:0.781 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.991 AVG Test Loss:0.766 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.065 AVG Test Loss:2.357 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.949 AVG Test Loss:0.824 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.051 AVG Test Loss:0.865 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.025 AVG Test Loss:0.847 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.046 AVG Test Loss:1.147 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.990 AVG Test Loss:0.650 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:1.064 AVG Test Loss:0.838 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.141 AVG Test Loss:1.163 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.228 AVG Test Loss:0.882 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.047 AVG Test Loss:1.150 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.996 AVG Test Loss:0.838 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.042 AVG Test Loss:0.904 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.927 AVG Test Loss:1.337 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.063 AVG Test Loss:0.675 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:0.935 AVG Test Loss:1.559 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:0.940 AVG Test Loss:0.882 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.038 AVG Test Loss:1.565 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.080 AVG Test Loss:1.239 AVG Training Acc 65.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.008 AVG Test Loss:0.691 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.016 AVG Test Loss:0.758 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.097 AVG Test Loss:1.210 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.106 AVG Test Loss:1.482 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.112 AVG Test Loss:0.968 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.027 AVG Test Loss:1.072 AVG Training Acc 60.61 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.955 AVG Test Loss:1.175 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.258 AVG Test Loss:1.062 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.052 AVG Test Loss:2.163 AVG Training Acc 51.52 % AVG Test Acc 20.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.958 AVG Test Loss:1.217 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.114 AVG Test Loss:1.045 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.083 AVG Test Loss:0.656 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:0.984 AVG Test Loss:1.083 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.118 AVG Test Loss:1.447 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.118 AVG Test Loss:1.903 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.045 AVG Test Loss:1.783 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:0.970 AVG Test Loss:0.609 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.012 AVG Test Loss:1.585 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:16/20 AVG Training Loss:1.024 AVG Test Loss:0.888 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 51.36363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.962 AVG Test Loss:1.327 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.052 AVG Test Loss:0.990 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.153 AVG Test Loss:0.759 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.094 AVG Test Loss:1.442 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.942 AVG Test Loss:1.126 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.995 AVG Test Loss:0.964 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.108 AVG Test Loss:1.456 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.176 AVG Test Loss:1.605 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.952 AVG Test Loss:0.791 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.113 AVG Test Loss:0.882 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.120 AVG Test Loss:1.074 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.170 AVG Test Loss:1.088 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.991 AVG Test Loss:1.455 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.081 AVG Test Loss:0.919 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.066 AVG Test Loss:1.155 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.033 AVG Test Loss:0.907 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.110 AVG Test Loss:1.098 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.195 AVG Test Loss:2.383 AVG Training Acc 57.58 % AVG Test Acc 10.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 10.0 %\n",
            " Average acc: 41.13636363636364 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.019 AVG Test Loss:1.572 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.038 AVG Test Loss:1.262 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.012 AVG Test Loss:1.138 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.078 AVG Test Loss:0.993 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.109 AVG Test Loss:0.621 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.950 AVG Test Loss:1.160 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.985 AVG Test Loss:0.841 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.955 AVG Test Loss:1.456 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.026 AVG Test Loss:0.875 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.118 AVG Test Loss:0.949 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.033 AVG Test Loss:0.944 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.969 AVG Test Loss:1.259 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.116 AVG Test Loss:1.087 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.133 AVG Test Loss:1.284 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.044 AVG Test Loss:1.365 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.246 AVG Test Loss:1.658 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.058 AVG Test Loss:1.326 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.947 AVG Test Loss:0.705 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.024 AVG Test Loss:0.647 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.054 AVG Test Loss:1.871 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 53.40909090909092 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.980 AVG Test Loss:1.523 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.035 AVG Test Loss:0.969 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.996 AVG Test Loss:0.871 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.217 AVG Test Loss:1.322 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.098 AVG Test Loss:1.207 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.926 AVG Test Loss:1.257 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.917 AVG Test Loss:1.486 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:0.888 AVG Test Loss:1.294 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.016 AVG Test Loss:1.190 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.055 AVG Test Loss:1.427 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.975 AVG Test Loss:1.574 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.037 AVG Test Loss:0.894 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.047 AVG Test Loss:1.094 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.996 AVG Test Loss:1.006 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.899 AVG Test Loss:0.836 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.983 AVG Test Loss:0.716 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.996 AVG Test Loss:0.818 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.071 AVG Test Loss:1.411 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.180 AVG Test Loss:1.211 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.162 AVG Test Loss:0.775 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.957 AVG Test Loss:0.577 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.963 AVG Test Loss:0.421 AVG Training Acc 39.39 % AVG Test Acc 80.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.300 AVG Test Loss:0.892 AVG Training Acc 63.64 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 44.827586206896555 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.43416927899686 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.021 AVG Test Loss:1.346 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.137 AVG Test Loss:0.775 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.000 AVG Test Loss:0.917 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.015 AVG Test Loss:1.723 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.047 AVG Test Loss:1.242 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.036 AVG Test Loss:1.565 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.223 AVG Test Loss:1.076 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.050 AVG Test Loss:1.341 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.109 AVG Test Loss:1.193 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.988 AVG Test Loss:1.348 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.914 AVG Test Loss:1.250 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.070 AVG Test Loss:0.807 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.375 AVG Test Loss:1.510 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.087 AVG Test Loss:1.087 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.163 AVG Test Loss:0.935 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.983 AVG Test Loss:1.077 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.920 AVG Test Loss:1.157 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.973 AVG Test Loss:1.179 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.039 AVG Test Loss:0.362 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.036 AVG Test Loss:0.855 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.205 AVG Test Loss:1.148 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:0.958 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.907 AVG Test Loss:0.869 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.096 AVG Test Loss:0.486 AVG Training Acc 51.52 % AVG Test Acc 90.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.243 AVG Test Loss:1.117 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 81.81818181818183 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 62.5 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.090 AVG Test Loss:1.216 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.992 AVG Test Loss:1.259 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.130 AVG Test Loss:0.999 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:1.928 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.984 AVG Test Loss:0.735 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.142 AVG Test Loss:1.204 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:0.979 AVG Test Loss:0.811 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.036 AVG Test Loss:0.895 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.102 AVG Test Loss:2.017 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.132 AVG Test Loss:1.237 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.998 AVG Test Loss:0.723 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.987 AVG Test Loss:1.030 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.005 AVG Test Loss:1.233 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.070 AVG Test Loss:1.331 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.191 AVG Test Loss:1.033 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.135 AVG Test Loss:1.092 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.208 AVG Test Loss:1.460 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.052 AVG Test Loss:1.974 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:0.925 AVG Test Loss:1.355 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.146 AVG Test Loss:1.702 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.947 AVG Test Loss:1.498 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.924 AVG Test Loss:1.082 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.906 AVG Test Loss:1.161 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.047 AVG Test Loss:1.050 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.985 AVG Test Loss:1.013 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.947 AVG Test Loss:1.336 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.089 AVG Test Loss:1.684 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:1.059 AVG Test Loss:1.108 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:15/20 AVG Training Loss:0.897 AVG Test Loss:1.826 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:16/20 AVG Training Loss:1.019 AVG Test Loss:1.633 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.973 AVG Test Loss:1.111 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:1.060 AVG Test Loss:2.231 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:19/20 AVG Training Loss:1.279 AVG Test Loss:1.065 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.090 AVG Test Loss:0.991 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.892 AVG Test Loss:1.019 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.945 AVG Test Loss:1.041 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:1.092 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 55.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.091 AVG Test Loss:1.247 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.035 AVG Test Loss:0.540 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.029 AVG Test Loss:0.880 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.087 AVG Test Loss:1.088 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.077 AVG Test Loss:1.456 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.172 AVG Test Loss:0.714 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.982 AVG Test Loss:1.937 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.995 AVG Test Loss:1.102 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.094 AVG Test Loss:1.348 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.114 AVG Test Loss:0.726 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.159 AVG Test Loss:1.020 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.084 AVG Test Loss:1.086 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.985 AVG Test Loss:1.067 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.095 AVG Test Loss:1.194 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.085 AVG Test Loss:1.358 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.003 AVG Test Loss:2.087 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:1.050 AVG Test Loss:1.614 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.006 AVG Test Loss:2.098 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.216 AVG Test Loss:0.821 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.918 AVG Test Loss:1.337 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.067 AVG Test Loss:1.112 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.171 AVG Test Loss:1.736 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.027 AVG Test Loss:0.996 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.036 AVG Test Loss:0.927 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.945 AVG Test Loss:0.888 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.936 AVG Test Loss:2.449 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:5/20 AVG Training Loss:1.032 AVG Test Loss:1.346 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.111 AVG Test Loss:1.401 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.980 AVG Test Loss:0.936 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.147 AVG Test Loss:1.435 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.943 AVG Test Loss:0.704 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.075 AVG Test Loss:0.924 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.000 AVG Test Loss:1.086 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.043 AVG Test Loss:0.506 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.078 AVG Test Loss:2.994 AVG Training Acc 57.58 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 39.31818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.231 AVG Test Loss:1.380 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.082 AVG Test Loss:1.334 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.025 AVG Test Loss:0.755 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.042 AVG Test Loss:1.107 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.994 AVG Test Loss:1.741 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.025 AVG Test Loss:0.755 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.059 AVG Test Loss:2.004 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.997 AVG Test Loss:1.055 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.001 AVG Test Loss:0.875 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.148 AVG Test Loss:1.250 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.084 AVG Test Loss:1.071 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.935 AVG Test Loss:0.989 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.068 AVG Test Loss:1.314 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.038 AVG Test Loss:0.627 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.102 AVG Test Loss:0.566 AVG Training Acc 62.50 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.060 AVG Test Loss:1.228 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.084 AVG Test Loss:1.217 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.034 AVG Test Loss:1.583 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.069 AVG Test Loss:1.981 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.116 AVG Test Loss:1.130 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.996 AVG Test Loss:0.874 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.954 AVG Test Loss:1.171 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:1.057 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.126 AVG Test Loss:1.532 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 41.81818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.096 AVG Test Loss:1.142 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.963 AVG Test Loss:1.033 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.954 AVG Test Loss:1.553 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:1.002 AVG Test Loss:0.626 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.202 AVG Test Loss:1.576 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.933 AVG Test Loss:0.590 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:1.182 AVG Test Loss:1.354 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.064 AVG Test Loss:1.298 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.255 AVG Test Loss:0.849 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.005 AVG Test Loss:2.281 AVG Training Acc 37.50 % AVG Test Acc 18.18 %\n",
            "Epoch:6/20 AVG Training Loss:1.101 AVG Test Loss:1.267 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.008 AVG Test Loss:1.928 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.162 AVG Test Loss:1.220 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.051 AVG Test Loss:2.348 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.082 AVG Test Loss:1.211 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:1.190 AVG Test Loss:1.574 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.233 AVG Test Loss:1.048 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.952 AVG Test Loss:0.782 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.989 AVG Test Loss:0.838 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.942 AVG Test Loss:0.890 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.092 AVG Test Loss:1.531 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.034 AVG Test Loss:1.840 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.063 AVG Test Loss:0.519 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.088 AVG Test Loss:2.051 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.916 AVG Test Loss:1.304 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.199 AVG Test Loss:1.601 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.129 AVG Test Loss:0.879 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.062 AVG Test Loss:0.915 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.017 AVG Test Loss:1.441 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.005 AVG Test Loss:2.217 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.146 AVG Test Loss:1.252 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.039 AVG Test Loss:1.631 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.028 AVG Test Loss:0.835 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.157 AVG Test Loss:0.994 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:1.070 AVG Test Loss:1.176 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:1.058 AVG Test Loss:1.166 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.097 AVG Test Loss:0.693 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:1.059 AVG Test Loss:1.373 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:1.032 AVG Test Loss:1.540 AVG Training Acc 42.42 % AVG Test Acc 20.00 %\n",
            "Epoch:16/20 AVG Training Loss:0.975 AVG Test Loss:1.900 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:1.017 AVG Test Loss:1.956 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:0.942 AVG Test Loss:1.194 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:0.951 AVG Test Loss:0.927 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:1.067 AVG Test Loss:2.315 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 39.54545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.197 AVG Test Loss:1.657 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.072 AVG Test Loss:1.467 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.983 AVG Test Loss:0.881 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.972 AVG Test Loss:0.361 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.015 AVG Test Loss:0.683 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.949 AVG Test Loss:0.396 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:0.976 AVG Test Loss:0.637 AVG Training Acc 62.50 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:1.241 AVG Test Loss:0.903 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.992 AVG Test Loss:0.779 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.887 AVG Test Loss:0.825 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.029 AVG Test Loss:0.675 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.974 AVG Test Loss:1.371 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.044 AVG Test Loss:1.295 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.062 AVG Test Loss:1.731 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.971 AVG Test Loss:1.032 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.027 AVG Test Loss:1.187 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.876 AVG Test Loss:0.667 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.043 AVG Test Loss:0.713 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.976 AVG Test Loss:1.570 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:0.879 AVG Test Loss:1.351 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.996 AVG Test Loss:0.536 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.057 AVG Test Loss:1.208 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.058 AVG Test Loss:1.698 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.192 AVG Test Loss:1.490 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.221 AVG Test Loss:0.664 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 42.857142857142854 %\n",
            " Average acc: 51.623376623376615 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.121 AVG Test Loss:1.247 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.153 AVG Test Loss:0.589 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.073 AVG Test Loss:1.086 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.113 AVG Test Loss:1.057 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.970 AVG Test Loss:0.638 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.023 AVG Test Loss:1.276 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.904 AVG Test Loss:1.365 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.084 AVG Test Loss:1.548 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:1.028 AVG Test Loss:1.595 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.086 AVG Test Loss:1.334 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.928 AVG Test Loss:1.390 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.104 AVG Test Loss:1.464 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:13/20 AVG Training Loss:1.196 AVG Test Loss:0.772 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.850 AVG Test Loss:0.953 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.955 AVG Test Loss:0.896 AVG Training Acc 37.50 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.143 AVG Test Loss:0.802 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.158 AVG Test Loss:1.050 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.065 AVG Test Loss:1.020 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.992 AVG Test Loss:1.101 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.169 AVG Test Loss:0.813 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.134 AVG Test Loss:1.610 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.033 AVG Test Loss:2.100 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.195 AVG Test Loss:0.823 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.143 AVG Test Loss:1.999 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:0.950 AVG Test Loss:1.096 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.045 AVG Test Loss:2.109 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:0.940 AVG Test Loss:1.393 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.089 AVG Test Loss:2.121 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.030 AVG Test Loss:1.788 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:14/20 AVG Training Loss:0.942 AVG Test Loss:1.296 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:15/20 AVG Training Loss:1.073 AVG Test Loss:1.374 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:16/20 AVG Training Loss:1.036 AVG Test Loss:2.012 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.044 AVG Test Loss:1.393 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:18/20 AVG Training Loss:1.009 AVG Test Loss:1.443 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.038 AVG Test Loss:1.606 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/20 AVG Training Loss:0.991 AVG Test Loss:1.816 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.098 AVG Test Loss:1.683 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.007 AVG Test Loss:1.564 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.134 AVG Test Loss:1.365 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.109 AVG Test Loss:1.327 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.046 AVG Test Loss:1.481 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.133 AVG Test Loss:1.802 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.969 AVG Test Loss:2.819 AVG Training Acc 45.45 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.010 AVG Test Loss:0.658 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.155 AVG Test Loss:2.398 AVG Training Acc 48.48 % AVG Test Acc 20.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 20.0 %\n",
            " Average acc: 50.45454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.085 AVG Test Loss:1.782 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:2/20 AVG Training Loss:1.034 AVG Test Loss:1.322 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.181 AVG Test Loss:0.984 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.877 AVG Test Loss:1.381 AVG Training Acc 65.62 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.024 AVG Test Loss:0.730 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.952 AVG Test Loss:1.263 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.107 AVG Test Loss:1.508 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.058 AVG Test Loss:2.401 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.089 AVG Test Loss:1.173 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:0.917 AVG Test Loss:1.150 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.920 AVG Test Loss:1.188 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.115 AVG Test Loss:1.409 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.050 AVG Test Loss:0.944 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.088 AVG Test Loss:1.186 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.217 AVG Test Loss:1.341 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.998 AVG Test Loss:0.985 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.066 AVG Test Loss:1.459 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.248 AVG Test Loss:0.923 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.991 AVG Test Loss:1.123 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.101 AVG Test Loss:1.198 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.043 AVG Test Loss:1.465 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.947 AVG Test Loss:1.274 AVG Training Acc 51.52 % AVG Test Acc 20.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.026 AVG Test Loss:0.829 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.055 AVG Test Loss:0.709 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 44.31818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.967 AVG Test Loss:1.127 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.048 AVG Test Loss:1.305 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.062 AVG Test Loss:0.810 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.051 AVG Test Loss:1.624 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.070 AVG Test Loss:1.158 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.156 AVG Test Loss:0.979 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.061 AVG Test Loss:1.092 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.249 AVG Test Loss:0.994 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.993 AVG Test Loss:1.094 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.948 AVG Test Loss:0.975 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.117 AVG Test Loss:0.651 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.066 AVG Test Loss:1.773 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:0.937 AVG Test Loss:0.758 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.941 AVG Test Loss:0.463 AVG Training Acc 59.38 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.899 AVG Test Loss:0.523 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:1.077 AVG Test Loss:1.022 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:0.958 AVG Test Loss:1.287 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:0.934 AVG Test Loss:1.219 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.011 AVG Test Loss:1.730 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:14/20 AVG Training Loss:1.140 AVG Test Loss:1.181 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:1.182 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.106 AVG Test Loss:1.126 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.999 AVG Test Loss:1.011 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.128 AVG Test Loss:0.831 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.983 AVG Test Loss:0.748 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.909 AVG Test Loss:1.602 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.010 AVG Test Loss:0.842 AVG Training Acc 48.48 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.044 AVG Test Loss:0.867 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 48.63636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.968 AVG Test Loss:1.034 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.043 AVG Test Loss:0.737 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.075 AVG Test Loss:1.318 AVG Training Acc 59.38 % AVG Test Acc 18.18 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.993 AVG Test Loss:1.129 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.061 AVG Test Loss:0.750 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.043 AVG Test Loss:0.695 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.057 AVG Test Loss:0.757 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.956 AVG Test Loss:0.980 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.073 AVG Test Loss:2.432 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:7/20 AVG Training Loss:1.043 AVG Test Loss:0.823 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.053 AVG Test Loss:1.725 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.000 AVG Test Loss:1.209 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:10/20 AVG Training Loss:1.085 AVG Test Loss:0.856 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:1.116 AVG Test Loss:1.536 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.044 AVG Test Loss:1.038 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.104 AVG Test Loss:0.772 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.968 AVG Test Loss:0.962 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.074 AVG Test Loss:1.876 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.121 AVG Test Loss:1.885 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.238 AVG Test Loss:0.792 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.933 AVG Test Loss:1.296 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:1.456 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.061 AVG Test Loss:1.002 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 18.181818181818183 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 35.22727272727273 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.051 AVG Test Loss:1.225 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:0.968 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.108 AVG Test Loss:0.605 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.991 AVG Test Loss:0.806 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:0.997 AVG Test Loss:0.996 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.136 AVG Test Loss:0.965 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.065 AVG Test Loss:0.838 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.972 AVG Test Loss:0.994 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:1.053 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.927 AVG Test Loss:1.183 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.018 AVG Test Loss:1.049 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.117 AVG Test Loss:0.496 AVG Training Acc 62.50 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.074 AVG Test Loss:1.275 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.218 AVG Test Loss:1.024 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.133 AVG Test Loss:1.225 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.891 AVG Test Loss:0.631 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.031 AVG Test Loss:0.563 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:1.164 AVG Test Loss:0.930 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.110 AVG Test Loss:1.075 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.067 AVG Test Loss:0.754 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.981 AVG Test Loss:0.784 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.959 AVG Test Loss:0.890 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.119 AVG Test Loss:1.400 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.977 AVG Test Loss:1.391 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.120 AVG Test Loss:1.990 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.284 AVG Test Loss:1.608 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 62.727272727272734 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 30, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.981 AVG Test Loss:1.393 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.152 AVG Test Loss:0.908 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.052 AVG Test Loss:0.623 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.148 AVG Test Loss:0.598 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.162 AVG Test Loss:1.013 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.073 AVG Test Loss:1.345 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.029 AVG Test Loss:0.826 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.057 AVG Test Loss:1.446 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.039 AVG Test Loss:0.758 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.102 AVG Test Loss:0.972 AVG Training Acc 34.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.149 AVG Test Loss:1.617 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.989 AVG Test Loss:1.328 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.093 AVG Test Loss:0.869 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.985 AVG Test Loss:0.800 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.170 AVG Test Loss:1.361 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.141 AVG Test Loss:1.509 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.115 AVG Test Loss:1.154 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.068 AVG Test Loss:1.326 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.125 AVG Test Loss:1.003 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:0.954 AVG Test Loss:2.312 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.001 AVG Test Loss:2.389 AVG Training Acc 53.12 % AVG Test Acc 9.09 %\n",
            "Epoch:11/20 AVG Training Loss:1.038 AVG Test Loss:0.676 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.041 AVG Test Loss:1.199 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.147 AVG Test Loss:1.236 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.039 AVG Test Loss:1.060 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.960 AVG Test Loss:0.754 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.158 AVG Test Loss:1.233 AVG Training Acc 63.64 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.945 AVG Test Loss:1.535 AVG Training Acc 42.42 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.016 AVG Test Loss:1.730 AVG Training Acc 54.55 % AVG Test Acc 20.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.136 AVG Test Loss:0.840 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 51.13636363636363 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.901 AVG Test Loss:1.259 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.965 AVG Test Loss:1.262 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.013 AVG Test Loss:1.360 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.121 AVG Test Loss:1.019 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.225 AVG Test Loss:1.215 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.064 AVG Test Loss:1.081 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.294 AVG Test Loss:1.384 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.036 AVG Test Loss:0.753 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:0.920 AVG Test Loss:1.025 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.058 AVG Test Loss:1.125 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.912 AVG Test Loss:2.250 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:9/20 AVG Training Loss:0.959 AVG Test Loss:0.819 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.007 AVG Test Loss:2.013 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.146 AVG Test Loss:1.519 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.941 AVG Test Loss:1.212 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:0.650 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:0.960 AVG Test Loss:0.997 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.042 AVG Test Loss:1.196 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.981 AVG Test Loss:0.716 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:0.971 AVG Test Loss:1.057 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.025 AVG Test Loss:1.222 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.112 AVG Test Loss:2.342 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.004 AVG Test Loss:1.019 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.093 AVG Test Loss:0.958 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.092 AVG Test Loss:0.531 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.137 AVG Test Loss:0.732 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.973 AVG Test Loss:0.855 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.108 AVG Test Loss:1.220 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.106 AVG Test Loss:0.769 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.979 AVG Test Loss:0.812 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.070 AVG Test Loss:1.586 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.161 AVG Test Loss:1.026 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 51.36363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.189 AVG Test Loss:1.441 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.009 AVG Test Loss:1.120 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.130 AVG Test Loss:0.774 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.049 AVG Test Loss:0.745 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.090 AVG Test Loss:1.205 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.151 AVG Test Loss:0.485 AVG Training Acc 59.38 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.139 AVG Test Loss:1.155 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.975 AVG Test Loss:0.933 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.965 AVG Test Loss:0.860 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.915 AVG Test Loss:1.226 AVG Training Acc 56.25 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.165 AVG Test Loss:2.049 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.038 AVG Test Loss:1.021 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.087 AVG Test Loss:1.622 AVG Training Acc 43.75 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.123 AVG Test Loss:1.481 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.097 AVG Test Loss:1.326 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.050 AVG Test Loss:0.836 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.008 AVG Test Loss:1.163 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.084 AVG Test Loss:0.629 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.051 AVG Test Loss:1.129 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.994 AVG Test Loss:1.864 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.129 AVG Test Loss:1.374 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Epoch:8/20 AVG Training Loss:1.078 AVG Test Loss:0.936 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.033 AVG Test Loss:0.826 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.004 AVG Test Loss:1.454 AVG Training Acc 40.62 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.002 AVG Test Loss:1.280 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:12/20 AVG Training Loss:1.047 AVG Test Loss:1.285 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.192 AVG Test Loss:2.130 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.077 AVG Test Loss:1.152 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.029 AVG Test Loss:1.096 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.994 AVG Test Loss:0.913 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.146 AVG Test Loss:0.903 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.168 AVG Test Loss:0.892 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 81.81818181818183 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 18.181818181818183 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 56.13636363636364 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.200 AVG Test Loss:1.483 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.928 AVG Test Loss:0.780 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.019 AVG Test Loss:0.765 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.030 AVG Test Loss:1.467 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.036 AVG Test Loss:1.404 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.975 AVG Test Loss:1.087 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:1.011 AVG Test Loss:0.923 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.110 AVG Test Loss:1.532 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.137 AVG Test Loss:0.926 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.018 AVG Test Loss:0.691 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.122 AVG Test Loss:0.575 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.059 AVG Test Loss:1.302 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.071 AVG Test Loss:0.722 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:1.158 AVG Test Loss:2.178 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.940 AVG Test Loss:0.872 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.297 AVG Test Loss:0.801 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.989 AVG Test Loss:0.442 AVG Training Acc 48.48 % AVG Test Acc 90.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.031 AVG Test Loss:1.138 AVG Training Acc 51.52 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.090 AVG Test Loss:0.795 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 60.909090909090914 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.0, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.107 AVG Test Loss:1.697 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.032 AVG Test Loss:0.946 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.118 AVG Test Loss:0.960 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.004 AVG Test Loss:1.089 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.084 AVG Test Loss:1.171 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.101 AVG Test Loss:0.844 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.012 AVG Test Loss:0.959 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.045 AVG Test Loss:1.273 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.195 AVG Test Loss:1.122 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.933 AVG Test Loss:0.756 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.951 AVG Test Loss:0.485 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.105 AVG Test Loss:1.005 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.045 AVG Test Loss:0.966 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.195 AVG Test Loss:0.472 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.016 AVG Test Loss:1.194 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.030 AVG Test Loss:1.475 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.057 AVG Test Loss:0.485 AVG Training Acc 57.58 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 48.86363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.972 AVG Test Loss:1.367 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.948 AVG Test Loss:0.928 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:0.619 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.108 AVG Test Loss:1.170 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.935 AVG Test Loss:0.644 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.131 AVG Test Loss:1.024 AVG Training Acc 37.50 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.041 AVG Test Loss:0.731 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.939 AVG Test Loss:1.137 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.069 AVG Test Loss:1.513 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.996 AVG Test Loss:1.583 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.209 AVG Test Loss:1.437 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.997 AVG Test Loss:0.789 AVG Training Acc 40.62 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:0.963 AVG Test Loss:2.949 AVG Training Acc 53.12 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:0.989 AVG Test Loss:1.348 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.989 AVG Test Loss:1.198 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.038 AVG Test Loss:0.782 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.961 AVG Test Loss:1.475 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.111 AVG Test Loss:0.802 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.073 AVG Test Loss:0.429 AVG Training Acc 53.12 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.043 AVG Test Loss:1.622 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.072 AVG Test Loss:2.632 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:7/20 AVG Training Loss:1.057 AVG Test Loss:1.719 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:1.133 AVG Test Loss:1.504 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:0.901 AVG Test Loss:0.932 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.077 AVG Test Loss:1.070 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:1.028 AVG Test Loss:0.865 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.034 AVG Test Loss:1.355 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.171 AVG Test Loss:1.416 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.055 AVG Test Loss:1.148 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.925 AVG Test Loss:0.916 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.226 AVG Test Loss:0.838 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.023 AVG Test Loss:1.202 AVG Training Acc 54.55 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.110 AVG Test Loss:0.725 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.025 AVG Test Loss:1.239 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.923 AVG Test Loss:1.138 AVG Training Acc 54.55 % AVG Test Acc 30.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.988 AVG Test Loss:2.597 AVG Training Acc 57.58 % AVG Test Acc 20.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.085 AVG Test Loss:0.856 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 42.04545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.922 AVG Test Loss:1.744 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.018 AVG Test Loss:0.682 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.104 AVG Test Loss:0.977 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.934 AVG Test Loss:1.377 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.908 AVG Test Loss:0.978 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.047 AVG Test Loss:0.638 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.062 AVG Test Loss:0.670 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.997 AVG Test Loss:0.686 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.167 AVG Test Loss:1.216 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.010 AVG Test Loss:1.317 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:1.036 AVG Test Loss:1.370 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.969 AVG Test Loss:1.343 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.069 AVG Test Loss:1.115 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.230 AVG Test Loss:1.172 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.045 AVG Test Loss:0.730 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.101 AVG Test Loss:0.861 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.210 AVG Test Loss:0.711 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 63.63636363636363 %\n",
            "Fold 1 acc: 63.63636363636363 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 42.857142857142854 %\n",
            " Average acc: 53.896103896103895 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.066 AVG Test Loss:1.750 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.061 AVG Test Loss:0.858 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.889 AVG Test Loss:0.855 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.953 AVG Test Loss:0.530 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:0.990 AVG Test Loss:0.545 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.902 AVG Test Loss:1.135 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.118 AVG Test Loss:1.209 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:1.011 AVG Test Loss:1.281 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.118 AVG Test Loss:1.262 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.001 AVG Test Loss:2.485 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.118 AVG Test Loss:0.994 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.066 AVG Test Loss:1.631 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.096 AVG Test Loss:1.329 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:9/20 AVG Training Loss:1.084 AVG Test Loss:1.214 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.863 AVG Test Loss:0.822 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.062 AVG Test Loss:1.976 AVG Training Acc 46.88 % AVG Test Acc 18.18 %\n",
            "Epoch:12/20 AVG Training Loss:1.073 AVG Test Loss:1.584 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.018 AVG Test Loss:1.303 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.028 AVG Test Loss:1.071 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.091 AVG Test Loss:1.224 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.041 AVG Test Loss:1.144 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.963 AVG Test Loss:1.075 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.085 AVG Test Loss:0.592 AVG Training Acc 63.64 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.117 AVG Test Loss:1.383 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 81.81818181818183 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 50.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.1, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.016 AVG Test Loss:0.745 AVG Training Acc 37.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.053 AVG Test Loss:1.214 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:1.099 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.001 AVG Test Loss:1.612 AVG Training Acc 65.62 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.072 AVG Test Loss:0.714 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.124 AVG Test Loss:0.853 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.974 AVG Test Loss:0.854 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.025 AVG Test Loss:1.382 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.084 AVG Test Loss:1.031 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.204 AVG Test Loss:1.149 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.158 AVG Test Loss:0.834 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.016 AVG Test Loss:0.743 AVG Training Acc 45.45 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.126 AVG Test Loss:1.646 AVG Training Acc 45.45 % AVG Test Acc 0.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.041 AVG Test Loss:1.121 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.083 AVG Test Loss:1.658 AVG Training Acc 60.61 % AVG Test Acc 30.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.190 AVG Test Loss:0.496 AVG Training Acc 48.48 % AVG Test Acc 80.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 36.36363636363637 %\n",
            "Fold 3 acc: 80.0 %\n",
            " Average acc: 51.81818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.166 AVG Test Loss:0.897 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.011 AVG Test Loss:1.067 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.986 AVG Test Loss:0.741 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.066 AVG Test Loss:1.210 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:5/20 AVG Training Loss:1.124 AVG Test Loss:0.822 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.973 AVG Test Loss:2.004 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.993 AVG Test Loss:1.050 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.054 AVG Test Loss:1.252 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.123 AVG Test Loss:1.197 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.126 AVG Test Loss:0.743 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.056 AVG Test Loss:1.254 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:0.905 AVG Test Loss:0.996 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.995 AVG Test Loss:1.240 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.092 AVG Test Loss:1.079 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.021 AVG Test Loss:1.159 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.143 AVG Test Loss:1.365 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:0.970 AVG Test Loss:0.546 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.020 AVG Test Loss:0.984 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.103 AVG Test Loss:1.191 AVG Training Acc 48.48 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 43.86363636363637 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.138 AVG Test Loss:1.853 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.085 AVG Test Loss:1.307 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.984 AVG Test Loss:0.995 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.009 AVG Test Loss:0.797 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.063 AVG Test Loss:0.542 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.031 AVG Test Loss:1.101 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.099 AVG Test Loss:0.993 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.160 AVG Test Loss:1.536 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.055 AVG Test Loss:1.151 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.149 AVG Test Loss:0.489 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.151 AVG Test Loss:0.957 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.113 AVG Test Loss:1.124 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.100 AVG Test Loss:0.834 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.200 AVG Test Loss:0.876 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.997 AVG Test Loss:1.228 AVG Training Acc 36.36 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.034 AVG Test Loss:1.591 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.128 AVG Test Loss:0.930 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 72.72727272727273 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 55.90909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.966 AVG Test Loss:1.318 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.160 AVG Test Loss:1.101 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.114 AVG Test Loss:0.785 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.075 AVG Test Loss:0.515 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.962 AVG Test Loss:1.106 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.146 AVG Test Loss:0.960 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.208 AVG Test Loss:0.723 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.986 AVG Test Loss:1.199 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.187 AVG Test Loss:0.740 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.918 AVG Test Loss:1.041 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.067 AVG Test Loss:1.017 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.054 AVG Test Loss:1.634 AVG Training Acc 50.00 % AVG Test Acc 27.27 %\n",
            "Epoch:6/20 AVG Training Loss:1.046 AVG Test Loss:2.074 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.995 AVG Test Loss:1.567 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.954 AVG Test Loss:0.693 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.922 AVG Test Loss:1.682 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:10/20 AVG Training Loss:1.036 AVG Test Loss:2.754 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:11/20 AVG Training Loss:0.970 AVG Test Loss:1.293 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.111 AVG Test Loss:1.656 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.038 AVG Test Loss:0.770 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:0.987 AVG Test Loss:2.648 AVG Training Acc 59.38 % AVG Test Acc 18.18 %\n",
            "Epoch:15/20 AVG Training Loss:1.143 AVG Test Loss:0.704 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:1.082 AVG Test Loss:1.474 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:17/20 AVG Training Loss:0.923 AVG Test Loss:1.297 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.043 AVG Test Loss:2.189 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.044 AVG Test Loss:0.879 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.068 AVG Test Loss:0.988 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.101 AVG Test Loss:0.761 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:0.944 AVG Test Loss:1.462 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.884 AVG Test Loss:0.670 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.979 AVG Test Loss:0.637 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.012 AVG Test Loss:1.081 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.052 AVG Test Loss:0.943 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.117 AVG Test Loss:0.890 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.021 AVG Test Loss:0.784 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.047 AVG Test Loss:0.898 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.002 AVG Test Loss:1.415 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.226 AVG Test Loss:1.084 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.960 AVG Test Loss:0.468 AVG Training Acc 57.58 % AVG Test Acc 60.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.074 AVG Test Loss:1.023 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.085 AVG Test Loss:1.454 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 27.27272727272727 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 46.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.2, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.142 AVG Test Loss:1.937 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.103 AVG Test Loss:1.049 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.647 AVG Training Acc 56.25 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:1.025 AVG Test Loss:0.884 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:1.065 AVG Test Loss:0.972 AVG Training Acc 59.38 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:0.962 AVG Test Loss:1.067 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.056 AVG Test Loss:0.713 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:1.172 AVG Test Loss:1.744 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.024 AVG Test Loss:0.924 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:0.863 AVG Test Loss:1.645 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.107 AVG Test Loss:0.744 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.027 AVG Test Loss:1.652 AVG Training Acc 65.62 % AVG Test Acc 18.18 %\n",
            "Epoch:5/20 AVG Training Loss:0.988 AVG Test Loss:1.061 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.051 AVG Test Loss:1.504 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.041 AVG Test Loss:1.920 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:0.892 AVG Test Loss:1.018 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:1.014 AVG Test Loss:1.032 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:1.130 AVG Test Loss:1.564 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.943 AVG Test Loss:1.119 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.061 AVG Test Loss:0.882 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:1.165 AVG Test Loss:0.650 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.056 AVG Test Loss:0.804 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.094 AVG Test Loss:0.888 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.138 AVG Test Loss:1.010 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 36.36363636363637 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 37.04545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.204 AVG Test Loss:1.428 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.014 AVG Test Loss:1.237 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.973 AVG Test Loss:0.956 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.122 AVG Test Loss:0.665 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.148 AVG Test Loss:1.171 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.907 AVG Test Loss:1.698 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.192 AVG Test Loss:0.607 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:0.991 AVG Test Loss:1.092 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.104 AVG Test Loss:1.690 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.929 AVG Test Loss:1.357 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.048 AVG Test Loss:0.739 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:1.067 AVG Test Loss:1.675 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.022 AVG Test Loss:1.357 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:0.959 AVG Test Loss:1.133 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:0.967 AVG Test Loss:1.239 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:1.001 AVG Test Loss:1.550 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:0.932 AVG Test Loss:1.434 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.001 AVG Test Loss:1.369 AVG Training Acc 42.42 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.951 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 53.63636363636364 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.117 AVG Test Loss:1.426 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:1.022 AVG Test Loss:1.380 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.039 AVG Test Loss:0.832 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.106 AVG Test Loss:1.313 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.272 AVG Test Loss:1.042 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.058 AVG Test Loss:1.388 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.141 AVG Test Loss:1.168 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.996 AVG Test Loss:0.779 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.072 AVG Test Loss:1.701 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.098 AVG Test Loss:1.113 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.881 AVG Test Loss:0.945 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.025 AVG Test Loss:1.145 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.038 AVG Test Loss:1.094 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.063 AVG Test Loss:0.753 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.019 AVG Test Loss:0.568 AVG Training Acc 54.55 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.069 AVG Test Loss:0.751 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.905 AVG Test Loss:0.663 AVG Training Acc 54.55 % AVG Test Acc 80.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.003 AVG Test Loss:1.024 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.977 AVG Test Loss:1.509 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.054 AVG Test Loss:1.712 AVG Training Acc 57.58 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.060 AVG Test Loss:0.774 AVG Training Acc 42.42 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 72.72727272727273 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 62.95454545454545 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.108 AVG Test Loss:1.611 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.088 AVG Test Loss:1.073 AVG Training Acc 59.38 % AVG Test Acc 27.27 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.100 AVG Test Loss:0.828 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:0.996 AVG Test Loss:0.678 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:0.902 AVG Test Loss:0.804 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.018 AVG Test Loss:1.063 AVG Training Acc 40.62 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.993 AVG Test Loss:2.203 AVG Training Acc 62.50 % AVG Test Acc 36.36 %\n",
            "Epoch:8/20 AVG Training Loss:0.940 AVG Test Loss:0.962 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:1.026 AVG Test Loss:1.247 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:1.081 AVG Test Loss:1.427 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:1.278 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.066 AVG Test Loss:0.766 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.038 AVG Test Loss:1.171 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.058 AVG Test Loss:0.944 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:1.116 AVG Test Loss:1.575 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.199 AVG Test Loss:1.158 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.991 AVG Test Loss:0.834 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.071 AVG Test Loss:0.697 AVG Training Acc 59.38 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:0.961 AVG Test Loss:0.830 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.026 AVG Test Loss:1.399 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.969 AVG Test Loss:1.208 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.986 AVG Test Loss:1.336 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:0.985 AVG Test Loss:1.563 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.085 AVG Test Loss:2.520 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:1.182 AVG Test Loss:1.200 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.022 AVG Test Loss:1.216 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:0.992 AVG Test Loss:0.686 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.024 AVG Test Loss:1.001 AVG Training Acc 48.48 % AVG Test Acc 20.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.063 AVG Test Loss:1.226 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 54.54545454545454 %\n",
            "Fold 2 acc: 63.63636363636363 %\n",
            "Fold 3 acc: 50.0 %\n",
            " Average acc: 53.40909090909091 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.3, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.093 AVG Test Loss:1.494 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.000 AVG Test Loss:0.847 AVG Training Acc 65.62 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.042 AVG Test Loss:0.483 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:1.022 AVG Test Loss:1.118 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:0.977 AVG Test Loss:0.764 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.107 AVG Test Loss:0.754 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:1.122 AVG Test Loss:1.259 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.207 AVG Test Loss:1.249 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.978 AVG Test Loss:1.094 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.042 AVG Test Loss:1.499 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:0.998 AVG Test Loss:1.078 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.032 AVG Test Loss:1.238 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:0.988 AVG Test Loss:1.049 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:7/20 AVG Training Loss:1.046 AVG Test Loss:1.877 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:1.235 AVG Test Loss:1.067 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.130 AVG Test Loss:0.740 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.012 AVG Test Loss:1.265 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:0.961 AVG Test Loss:0.866 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:0.947 AVG Test Loss:0.581 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:0.912 AVG Test Loss:1.332 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:1.196 AVG Test Loss:1.546 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:1.115 AVG Test Loss:1.613 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Epoch:8/20 AVG Training Loss:1.167 AVG Test Loss:0.753 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.011 AVG Test Loss:1.582 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:10/20 AVG Training Loss:0.957 AVG Test Loss:0.539 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.942 AVG Test Loss:1.101 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.123 AVG Test Loss:1.150 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:1.049 AVG Test Loss:1.029 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:1.257 AVG Test Loss:1.292 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:1.016 AVG Test Loss:1.372 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:0.949 AVG Test Loss:0.960 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:17/20 AVG Training Loss:1.102 AVG Test Loss:0.754 AVG Training Acc 43.75 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:0.982 AVG Test Loss:1.262 AVG Training Acc 43.75 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:1.002 AVG Test Loss:1.710 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.058 AVG Test Loss:1.881 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.316 AVG Test Loss:0.932 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.204 AVG Test Loss:0.992 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.059 AVG Test Loss:0.698 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.902 AVG Test Loss:1.044 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.113 AVG Test Loss:1.240 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.979 AVG Test Loss:1.164 AVG Training Acc 45.45 % AVG Test Acc 70.00 %\n",
            "Epoch:7/20 AVG Training Loss:0.873 AVG Test Loss:1.817 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:1.096 AVG Test Loss:0.908 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:9/20 AVG Training Loss:1.121 AVG Test Loss:1.536 AVG Training Acc 45.45 % AVG Test Acc 40.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 40.0 %\n",
            " Average acc: 41.81818181818182 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.076 AVG Test Loss:1.671 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.013 AVG Test Loss:0.699 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.152 AVG Test Loss:0.659 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:0.980 AVG Test Loss:0.617 AVG Training Acc 46.88 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:1.204 AVG Test Loss:0.969 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:1.136 AVG Test Loss:3.099 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:7/20 AVG Training Loss:0.993 AVG Test Loss:0.474 AVG Training Acc 50.00 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:1.025 AVG Test Loss:0.992 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:1.016 AVG Test Loss:1.441 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:1.062 AVG Test Loss:0.448 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:0.947 AVG Test Loss:1.107 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:1.077 AVG Test Loss:1.060 AVG Training Acc 50.00 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:1.089 AVG Test Loss:2.232 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.049 AVG Test Loss:1.663 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:1.155 AVG Test Loss:0.776 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:0.974 AVG Test Loss:1.038 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.098 AVG Test Loss:0.537 AVG Training Acc 56.25 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:0.955 AVG Test Loss:1.686 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:6/20 AVG Training Loss:1.033 AVG Test Loss:1.829 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Epoch:7/20 AVG Training Loss:0.943 AVG Test Loss:0.946 AVG Training Acc 50.00 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:0.936 AVG Test Loss:1.180 AVG Training Acc 62.50 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:0.964 AVG Test Loss:2.362 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:10/20 AVG Training Loss:0.950 AVG Test Loss:1.047 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:1.149 AVG Test Loss:0.959 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:0.960 AVG Test Loss:1.489 AVG Training Acc 53.12 % AVG Test Acc 36.36 %\n",
            "Epoch:13/20 AVG Training Loss:1.105 AVG Test Loss:1.981 AVG Training Acc 56.25 % AVG Test Acc 18.18 %\n",
            "Epoch:14/20 AVG Training Loss:1.087 AVG Test Loss:1.984 AVG Training Acc 50.00 % AVG Test Acc 18.18 %\n",
            "Epoch:15/20 AVG Training Loss:0.978 AVG Test Loss:1.410 AVG Training Acc 53.12 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:1.034 AVG Test Loss:1.260 AVG Training Acc 46.88 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:1.023 AVG Test Loss:1.208 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:1.001 AVG Test Loss:1.323 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:19/20 AVG Training Loss:0.935 AVG Test Loss:1.153 AVG Training Acc 56.25 % AVG Test Acc 45.45 %\n",
            "Epoch:20/20 AVG Training Loss:1.076 AVG Test Loss:2.678 AVG Training Acc 53.12 % AVG Test Acc 27.27 %\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.988 AVG Test Loss:1.241 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.247 AVG Test Loss:1.022 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.021 AVG Test Loss:1.005 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:0.903 AVG Test Loss:1.071 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:5/20 AVG Training Loss:0.913 AVG Test Loss:1.256 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:1.074 AVG Test Loss:1.832 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.016 AVG Test Loss:1.563 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.074 AVG Test Loss:1.081 AVG Training Acc 60.61 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:0.534 AVG Training Acc 51.52 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.052 AVG Test Loss:1.148 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.057 AVG Test Loss:1.201 AVG Training Acc 54.55 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:1.081 AVG Test Loss:0.768 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 27.27272727272727 %\n",
            "Fold 2 acc: 45.45454545454545 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 44.54545454545455 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:1.112 AVG Test Loss:1.809 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.108 AVG Test Loss:1.125 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.997 AVG Test Loss:1.202 AVG Training Acc 43.75 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.200 AVG Test Loss:1.307 AVG Training Acc 46.88 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:1.227 AVG Test Loss:1.056 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.064 AVG Test Loss:0.907 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.997 AVG Test Loss:1.114 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.072 AVG Test Loss:1.021 AVG Training Acc 56.25 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.134 AVG Test Loss:1.406 AVG Training Acc 43.75 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.265 AVG Test Loss:0.926 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.004 AVG Test Loss:0.610 AVG Training Acc 53.12 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:1.067 AVG Test Loss:1.584 AVG Training Acc 50.00 % AVG Test Acc 9.09 %\n",
            "Epoch:4/20 AVG Training Loss:1.092 AVG Test Loss:0.968 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.200 AVG Test Loss:1.286 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.055 AVG Test Loss:1.182 AVG Training Acc 51.52 % AVG Test Acc 70.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.120 AVG Test Loss:0.934 AVG Training Acc 66.67 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:0.991 AVG Test Loss:0.629 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:0.905 AVG Test Loss:1.604 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.996 AVG Test Loss:1.711 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.102 AVG Test Loss:1.328 AVG Training Acc 51.52 % AVG Test Acc 30.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 30.0 %\n",
            " Average acc: 41.590909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.0}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.956 AVG Test Loss:1.137 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.041 AVG Test Loss:1.099 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:0.943 AVG Test Loss:1.106 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:1.045 AVG Test Loss:0.906 AVG Training Acc 56.25 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:1.075 AVG Test Loss:0.954 AVG Training Acc 62.50 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:1.062 AVG Test Loss:1.380 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:0.896 AVG Test Loss:1.014 AVG Training Acc 46.88 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:1.088 AVG Test Loss:0.538 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:1.019 AVG Test Loss:1.289 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:1.057 AVG Test Loss:1.484 AVG Training Acc 53.12 % AVG Test Acc 45.45 %\n",
            "Epoch:6/20 AVG Training Loss:0.985 AVG Test Loss:1.562 AVG Training Acc 46.88 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:0.890 AVG Test Loss:0.752 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:1.087 AVG Test Loss:1.495 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:9/20 AVG Training Loss:1.003 AVG Test Loss:1.262 AVG Training Acc 43.75 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:0.931 AVG Test Loss:0.908 AVG Training Acc 50.00 % AVG Test Acc 45.45 %\n",
            "Epoch:11/20 AVG Training Loss:0.975 AVG Test Loss:1.228 AVG Training Acc 50.00 % AVG Test Acc 36.36 %\n",
            "Epoch:12/20 AVG Training Loss:1.002 AVG Test Loss:1.725 AVG Training Acc 40.62 % AVG Test Acc 36.36 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:0.974 AVG Test Loss:1.193 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:0.949 AVG Test Loss:0.725 AVG Training Acc 59.38 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.107 AVG Test Loss:0.680 AVG Training Acc 59.38 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:1.253 AVG Test Loss:0.727 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.076 AVG Test Loss:0.985 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.029 AVG Test Loss:0.865 AVG Training Acc 42.42 % AVG Test Acc 60.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.011 AVG Test Loss:0.657 AVG Training Acc 48.48 % AVG Test Acc 60.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.039 AVG Test Loss:0.952 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.068 AVG Test Loss:1.117 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 45.45454545454545 %\n",
            "Fold 1 acc: 36.36363636363637 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 60.0 %\n",
            " Average acc: 49.090909090909086 %\n",
            "  current_agumentations: {'RandomHorizontalFlipProb': 0.5, 'RandomRotation': 90, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.5, 'RandomVerticalFlipProb': 0.5}\n",
            "Fold 1. train_idx:[ 0  1  3  4  5  6  8 11 12 15 16 17 18 19 20 21 22 23 25 26 27 29 31 33\n",
            " 35 36 37 38 39 40 41 42] val_idx:[ 2  7  9 10 13 14 24 28 30 32 34]\n",
            "Epoch:1/20 AVG Training Loss:0.985 AVG Test Loss:1.598 AVG Training Acc 59.38 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:1.073 AVG Test Loss:0.976 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3/20 AVG Training Loss:1.132 AVG Test Loss:0.956 AVG Training Acc 56.25 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 2. train_idx:[ 1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 21 22 24 25 28 29 30 32\n",
            " 34 35 36 38 39 40 41 42] val_idx:[ 0  4  5 19 20 23 26 27 31 33 37]\n",
            "Epoch:1/20 AVG Training Loss:0.992 AVG Test Loss:0.783 AVG Training Acc 62.50 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.045 AVG Test Loss:1.032 AVG Training Acc 40.62 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.088 AVG Test Loss:1.338 AVG Training Acc 59.38 % AVG Test Acc 45.45 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 3. train_idx:[ 0  2  3  4  5  7  8  9 10 13 14 15 17 18 19 20 22 23 24 26 27 28 30 31\n",
            " 32 33 34 36 37 38 40 41] val_idx:[ 1  6 11 12 16 21 25 29 35 39 42]\n",
            "Epoch:1/20 AVG Training Loss:1.053 AVG Test Loss:1.098 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:1.133 AVG Test Loss:0.962 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:1.147 AVG Test Loss:0.794 AVG Training Acc 50.00 % AVG Test Acc 54.55 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Fold 4. train_idx:[ 0  1  2  4  5  6  7  9 10 11 12 13 14 16 19 20 21 23 24 25 26 27 28 29\n",
            " 30 31 32 33 34 35 37 39 42] val_idx:[ 3  8 15 17 18 22 36 38 40 41]\n",
            "Epoch:1/20 AVG Training Loss:1.051 AVG Test Loss:0.914 AVG Training Acc 39.39 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:1.157 AVG Test Loss:1.034 AVG Training Acc 48.48 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:1.050 AVG Test Loss:0.970 AVG Training Acc 48.48 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:1.038 AVG Test Loss:0.925 AVG Training Acc 51.52 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:1.113 AVG Test Loss:1.242 AVG Training Acc 42.42 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:0.987 AVG Test Loss:0.551 AVG Training Acc 45.45 % AVG Test Acc 80.00 %\n",
            "Epoch:7/20 AVG Training Loss:1.126 AVG Test Loss:0.957 AVG Training Acc 54.55 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:0.984 AVG Test Loss:0.978 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:0.947 AVG Test Loss:0.454 AVG Training Acc 45.45 % AVG Test Acc 80.00 %\n",
            "Epoch:10/20 AVG Training Loss:1.130 AVG Test Loss:0.890 AVG Training Acc 51.52 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:0.968 AVG Test Loss:1.581 AVG Training Acc 45.45 % AVG Test Acc 60.00 %\n",
            "Epoch:12/20 AVG Training Loss:0.985 AVG Test Loss:1.165 AVG Training Acc 57.58 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:1.064 AVG Test Loss:0.641 AVG Training Acc 60.61 % AVG Test Acc 70.00 %\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 54.54545454545454 %\n",
            "Fold 1 acc: 45.45454545454545 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            "Fold 3 acc: 70.0 %\n",
            " Average acc: 56.136363636363626 %\n",
            "grid_param: {'RandomHorizontalFlipProb': [0.0, 0.5], 'RandomRotation': [0, 30, 90], 'RandomAffineScale': [0.0, 0.1, 0.2, 0.3, 0.4], 'GaussianBlurProb': [0.0, 0.5], 'RandomVerticalFlipProb': [0.0, 0.5]}  grid: [[[[[0.41590909 0.55909091]\n",
            "    [0.41590909 0.35454545]]\n",
            "\n",
            "   [[0.65454545 0.58598298]\n",
            "    [0.48636364 0.56159875]]\n",
            "\n",
            "   [[0.54090909 0.58181818]\n",
            "    [0.50243506 0.63181818]]\n",
            "\n",
            "   [[0.48636364 0.41206897]\n",
            "    [0.53863636 0.46253918]]\n",
            "\n",
            "   [[0.67727273 0.46661442]\n",
            "    [0.53636364 0.46590909]]]\n",
            "\n",
            "\n",
            "  [[[0.53409091 0.56136364]\n",
            "    [0.41152597 0.44545455]]\n",
            "\n",
            "   [[0.57045455 0.44090909]\n",
            "    [0.49318182 0.56159875]]\n",
            "\n",
            "   [[0.51136364 0.46363636]\n",
            "    [0.30227273 0.58181818]]\n",
            "\n",
            "   [[0.53409091 0.57727273]\n",
            "    [0.51363636 0.58409091]]\n",
            "\n",
            "   [[0.50681818 0.53461538]\n",
            "    [0.46818182 0.42045455]]]\n",
            "\n",
            "\n",
            "  [[[0.50909091 0.44161442]\n",
            "    [0.42272727 0.45454545]]\n",
            "\n",
            "   [[0.46136364 0.46434169]\n",
            "    [0.48863636 0.51590909]]\n",
            "\n",
            "   [[0.55681818 0.53863636]\n",
            "    [0.54545455 0.48636364]]\n",
            "\n",
            "   [[0.39772727 0.51136364]\n",
            "    [0.46590909 0.46590909]]\n",
            "\n",
            "   [[0.55909091 0.51206897]\n",
            "    [0.55681818 0.50681818]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[0.48863636 0.44318182]\n",
            "    [0.39772727 0.50909091]]\n",
            "\n",
            "   [[0.51136364 0.45454545]\n",
            "    [0.44318182 0.47523511]]\n",
            "\n",
            "   [[0.52703762 0.51136364]\n",
            "    [0.63181818 0.44545455]]\n",
            "\n",
            "   [[0.44318182 0.50909091]\n",
            "    [0.53863636 0.53479624]]\n",
            "\n",
            "   [[0.375      0.49756494]\n",
            "    [0.49568966 0.53409091]]]\n",
            "\n",
            "\n",
            "  [[[0.58181818 0.47045455]\n",
            "    [0.50681818 0.49090909]]\n",
            "\n",
            "   [[0.51363636 0.41136364]\n",
            "    [0.53409091 0.46434169]]\n",
            "\n",
            "   [[0.625      0.55909091]\n",
            "    [0.39318182 0.41818182]]\n",
            "\n",
            "   [[0.39545455 0.51623377]\n",
            "    [0.50454545 0.44318182]]\n",
            "\n",
            "   [[0.48636364 0.35227273]\n",
            "    [0.62727273 0.51136364]]]\n",
            "\n",
            "\n",
            "  [[[0.51363636 0.56136364]\n",
            "    [0.60909091 0.48863636]]\n",
            "\n",
            "   [[0.42045455 0.53896104]\n",
            "    [0.50909091 0.51818182]]\n",
            "\n",
            "   [[0.43863636 0.55909091]\n",
            "    [0.46590909 0.37045455]]\n",
            "\n",
            "   [[0.53636364 0.62954545]\n",
            "    [0.53409091 0.41818182]]\n",
            "\n",
            "   [[0.44545455 0.41590909]\n",
            "    [0.49090909 0.56136364]]]]]\n",
            "best: 0.6772727272727272 best_idx: (0, 0, 4, 0, 0)\n",
            "best params: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n",
            "best params: {'RandomHorizontalFlipProb': 0.0, 'RandomRotation': 0, 'RandomAffineScale': 0.4, 'GaussianBlurProb': 0.0, 'RandomVerticalFlipProb': 0.0}\n"
          ]
        }
      ],
      "source": [
        "#resnet, hearts\n",
        "\n",
        "resnet_model = prepare_resnet_model(False, 0.0)\n",
        "\n",
        "model_type = resnet_model\n",
        "dataset_type = HeartDataset\n",
        "\n",
        "grid_on_agumentations(model_type, dataset_type, grid_agumentations, grid_param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtLYeKIb0TR-"
      },
      "source": [
        "\n",
        "\n",
        "# GRADCAM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "8sbHV0U4WAOH",
        "outputId": "6ed21fb9-c3b3-4ef7-aff8-a19576e14702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(192, 192)\n",
            "float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#get one image and print it 4,15,1-3, 1-9\n",
        "img = dataset1.image_list[0]\n",
        "print(img.shape)\n",
        "print(img.dtype)\n",
        "plt.imshow(img/2500)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "DjbK_kuEP3r9",
        "outputId": "016c4775-b106-4345-8beb-81b6f7ca2ba6"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-362afa3572c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtarget_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Conv2d' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "#gradcam\n",
        "\n",
        "model = trained_models[0]\n",
        "last_conv_layer = list(model.children())[0][4]\n",
        "target_layers = [last_conv_layer]\n",
        "input_tensor = torch.from_numpy(img).float().unsqueeze(0)#.unsqueeze(0)\n",
        "#input_tensor = torch.from_numpy(img.reshape(1, 1, 192, 192)).float() # Create an input tensor image for your model..\n",
        "# Note: input_tensor can be a batch tensor with several images!\n",
        "print(\"input_tensor:\", input_tensor.shape)\n",
        "\n",
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
        "\n",
        "# You can also use it within a with statement, to make sure it is freed,\n",
        "# In case you need to re-create it inside an outer loop:\n",
        "# with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:\n",
        "#   ...\n",
        "\n",
        "# We have to specify the target we want to generate\n",
        "# the Class Activation Maps for.\n",
        "# If targets is None, the highest scoring category\n",
        "# will be used for every image in the batch.\n",
        "# Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
        "# That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
        "targets = [ClassifierOutputTarget(1)]\n",
        "\n",
        "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# In this example grayscale_cam has only one image in the batch:\n",
        "grayscale_cam = grayscale_cam[0, :]\n",
        "img2 = np.zeros((192,192))\n",
        "imgg = np.array([img2,img2,img2]).reshape(192, 192, 3)\n",
        "visualization = show_cam_on_image(imgg, grayscale_cam, use_rgb=True)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "Image.fromarray(visualization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccqm3FrwanRn"
      },
      "source": [
        "--- OLD ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxHLtuNyatSi"
      },
      "source": [
        "# --- OLD ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0MIBUh2hgcX"
      },
      "source": [
        "\n",
        "\n",
        "# [OLD]'Grid' search on agumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YttkWWRri2ha"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_params = {  \n",
        "    'learning_rate': [0.00000001],\n",
        "    'batch_size': [4], \n",
        "    'dropout': [0.0],\n",
        "    'num_epochs': [30],\n",
        "    'number_of_linear_layers': [2], \n",
        "    'l1_regularization_lambda': [0.0], \n",
        "    'l2_regularization_lambda': [0.0],  \n",
        "    'number_of_conv_layers': [2],\n",
        "    'number_of_filers' : [4], \n",
        "    'pooling': [True],\n",
        "    'batch_norm': [True],\n",
        "    'shape_info': [False]\n",
        "}\n",
        "\n",
        "k = 4\n",
        "\n",
        "seq = False\n",
        "rgb = False \n",
        "\n",
        "if rgb:\n",
        "  number_of_channels = 3\n",
        "else:\n",
        "  number_of_channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mfv7pQRiZ1y"
      },
      "outputs": [],
      "source": [
        "#more parms \n",
        "grid_agumentations = {\n",
        "    'RandomHorizontalFlipProb': [0.0, 0.2],\n",
        "    'RandomRotation': [0, 10, 15],\n",
        "    'RandomAffineScale': [0.0, 0.1, 0.2],\n",
        "    'GaussianBlurProb': [0.0, 0.2],\n",
        "    'RandomVerticalFlipProb': [0.0, 0.2]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MSvnqNekPwI"
      },
      "outputs": [],
      "source": [
        "keys = list(grid_agumentations.keys())\n",
        "shape = tuple(len(grid_agumentations[keys[i]]) for i in range(len(keys)))\n",
        "grid = np.zeros((shape))\n",
        "\n",
        "for idx in itertools.product(*[range(s) for s in shape]):\n",
        "  current_agumentations = {k: grid_agumentations[k][idx[e]] for e,k in enumerate(keys)}\n",
        "  print(\"  current_agumentations:\", current_agumentations)\n",
        "\n",
        "  train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                  \n",
        "    transforms.RandomHorizontalFlip(p=current_agumentations['RandomHorizontalFlipProb']),\n",
        "    transforms.RandomRotation(degrees=(-1*current_agumentations['RandomRotation'], current_agumentations['RandomRotation'])),\n",
        "    transforms.RandomAffine(degrees=0, scale=(1.0-current_agumentations['RandomAffineScale'], 1.0+current_agumentations['RandomAffineScale']), shear=0),\n",
        "    #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    transforms.RandomVerticalFlip(p=current_agumentations['RandomVerticalFlipProb']),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  dataset = PyTorchImageDataset(FAT_DIR0, FAT_DIR1, HEALTHY_DIR0, HEALTHY_DIR1, train_transform, rgb)\n",
        "\n",
        "  splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "  def model_getter():\n",
        "    return Net(best_params, 1, dataset.image_list[0].shape[0])\n",
        "  def model_getter_resnet():\n",
        "    return copy.deepcopy(finetune_model)\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "  grid[idx] = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL, current_agumentations)\n",
        "\n",
        "best_params = find_best_params_ndim(grid_agumentations, grid)\n",
        "print(\"best params:\", best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQw5k7SuWsoD"
      },
      "outputs": [],
      "source": [
        "#grid on agu on cutted - old\n",
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {\n",
        "    'learning_rate': [0.01],\n",
        "    'batch_size': [4], \n",
        "    'dropout': [0.0],\n",
        "    'num_epochs': [100],\n",
        "    'number_of_linear_layers': [2], \n",
        "    'l1_regularization_lambda': [0.0], \n",
        "    'l2_regularization_lambda': [0.0],\n",
        "    'number_of_conv_layers': [3], \n",
        "    'number_of_filers': [2], \n",
        "    'pooling': [False],\n",
        "    'batch_norm': [True],\n",
        "    'shape_info': [False] \n",
        "}\n",
        "\n",
        "k = 4\n",
        "\n",
        "seq = False #temp not supported  \n",
        "rgb = False \n",
        "\n",
        "\n",
        "grid_agumentations = {\n",
        "    'RandomHorizontalFlipProb': [0.0, 0.5],\n",
        "    'RandomRotation': [0, 30, 90],\n",
        "    'RandomAffineScale': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "    'GaussianBlurProb': [0.0, 0.5],\n",
        "    'RandomVerticalFlipProb': [0.0, 0.5]\n",
        "}\n",
        "\n",
        "keys = list(grid_agumentations.keys())\n",
        "shape = tuple(len(grid_agumentations[keys[i]]) for i in range(len(keys)))\n",
        "grid = np.zeros((shape))\n",
        "\n",
        "for idx in itertools.product(*[range(s) for s in shape]):\n",
        "  current_agumentations = {k: grid_agumentations[k][idx[e]] for e,k in enumerate(keys)}\n",
        "  print(\"  current_agumentations:\", current_agumentations)\n",
        "\n",
        "  train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                  \n",
        "    transforms.RandomHorizontalFlip(p=current_agumentations['RandomHorizontalFlipProb']),\n",
        "    transforms.RandomRotation(degrees=(-1*current_agumentations['RandomRotation'], current_agumentations['RandomRotation'])),\n",
        "    transforms.RandomAffine(degrees=0, scale=(1.0-current_agumentations['RandomAffineScale'], 1.0+current_agumentations['RandomAffineScale']), shear=0),\n",
        "    #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "    transforms.RandomVerticalFlip(p=current_agumentations['RandomVerticalFlipProb']),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  dataset = HeartDataset(HEART_FAT_DIR0, HEART_FAT_DIR1, HEART_HEALTHY_DIR0, HEART_HEALTHY_DIR1, train_transform, rgb)\n",
        "\n",
        "  splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "  splits = splitter.split(dataset, dataset.labels)\n",
        "\n",
        "  current_params = {k: grid_param[k][0] for k in list(grid_param.keys())}\n",
        "\n",
        "  def model_getter():\n",
        "    return Net(current_params, 1, dataset.image_list[0].shape[0])\n",
        "\n",
        "  results = folds_loop(model_getter, dataset, criterion, current_params, splits)\n",
        "  grid[idx] = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_FINAL, current_agumentations)\n",
        "\n",
        "best_params = find_best_params_ndim(grid_agumentations, grid)\n",
        "print(\"best params:\", best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpzJui_5LinG"
      },
      "source": [
        "# Resnet - old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNrOPl-OHAR6",
        "outputId": "d294357b-dc6e-4eba-c4d7-f28e21970e0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model_resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcLwofoM3B5N"
      },
      "outputs": [],
      "source": [
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "grid_param = {  \n",
        "    'learning_rate': [0.00001, 0.00001, 0.000001],\n",
        "    'batch_size': [2]  \n",
        "}\n",
        "\n",
        "num_epochs = 100\n",
        "k=4\n",
        "\n",
        "seq = False #parameter describing if we are learning on square at first or random\n",
        "\n",
        "regularization_lambda = 0.001 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iUUOu0g0mkY",
        "outputId": "a2267c5e-1cf4-40a8-9ef5-dda33377b3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 24 19\n",
            "item shape (192, 192, 3)  label 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "\n",
        "resnet_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    #transforms.Resize(256),\n",
        "    #transforms.CenterCrop(224),\n",
        "    #transforms.RandomHorizontalFlip(p=0.5),\n",
        "    #transforms.RandomAffine(degrees=0, scale=(.8, 1.2), shear=0),\n",
        "    #transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset0 = PyTorchImageDataset(FAT_DIR0, HEALTHY_DIR0, resnet_transform, rgb = True)\n",
        "dataset1 = PyTorchImageDataset(FAT_DIR1, HEALTHY_DIR1, resnet_transform, rgb = True)\n",
        "joined_dataset = torch.utils.data.ConcatDataset([dataset0, dataset1])\n",
        "print(\"Train dataset size:\", len(dataset0), len(dataset1))\n",
        "\n",
        "print(\"item shape\", dataset0.image_list[0].shape, \" label\", dataset0.labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY4l2zWp3ove",
        "outputId": "6502ef33-b6ee-42b3-ad38-57b7ccb3feb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1/100 AVG Training Loss:242.095 AVG Test Loss:6.602 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:2/100 AVG Training Loss:240.928 AVG Test Loss:6.459 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:3/100 AVG Training Loss:239.760 AVG Test Loss:6.488 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:4/100 AVG Training Loss:238.580 AVG Test Loss:6.423 AVG Training Acc 0.00 % AVG Test Acc 18.18 %\n",
            "Epoch:5/100 AVG Training Loss:237.379 AVG Test Loss:6.151 AVG Training Acc 40.62 % AVG Test Acc 18.18 %\n",
            "Epoch:6/100 AVG Training Loss:236.217 AVG Test Loss:5.928 AVG Training Acc 75.00 % AVG Test Acc 18.18 %\n",
            "Epoch:7/100 AVG Training Loss:235.077 AVG Test Loss:5.757 AVG Training Acc 84.38 % AVG Test Acc 27.27 %\n",
            "Epoch:8/100 AVG Training Loss:233.954 AVG Test Loss:5.612 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:9/100 AVG Training Loss:232.709 AVG Test Loss:5.491 AVG Training Acc 84.38 % AVG Test Acc 45.45 %\n",
            "Epoch:10/100 AVG Training Loss:231.706 AVG Test Loss:5.341 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:11/100 AVG Training Loss:230.678 AVG Test Loss:5.238 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:12/100 AVG Training Loss:229.191 AVG Test Loss:5.155 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:13/100 AVG Training Loss:228.324 AVG Test Loss:4.969 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:14/100 AVG Training Loss:226.957 AVG Test Loss:4.928 AVG Training Acc 84.38 % AVG Test Acc 36.36 %\n",
            "Epoch:15/100 AVG Training Loss:225.810 AVG Test Loss:4.791 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:16/100 AVG Training Loss:224.664 AVG Test Loss:4.713 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:17/100 AVG Training Loss:223.634 AVG Test Loss:4.623 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:18/100 AVG Training Loss:222.408 AVG Test Loss:4.557 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:19/100 AVG Training Loss:221.614 AVG Test Loss:4.418 AVG Training Acc 75.00 % AVG Test Acc 36.36 %\n",
            "Epoch:20/100 AVG Training Loss:220.747 AVG Test Loss:4.396 AVG Training Acc 71.88 % AVG Test Acc 36.36 %\n",
            "Epoch:21/100 AVG Training Loss:219.627 AVG Test Loss:4.257 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:22/100 AVG Training Loss:218.449 AVG Test Loss:4.182 AVG Training Acc 84.38 % AVG Test Acc 36.36 %\n",
            "Epoch:23/100 AVG Training Loss:217.367 AVG Test Loss:4.158 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:24/100 AVG Training Loss:216.005 AVG Test Loss:4.012 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:25/100 AVG Training Loss:215.544 AVG Test Loss:3.964 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:26/100 AVG Training Loss:214.517 AVG Test Loss:3.908 AVG Training Acc 81.25 % AVG Test Acc 36.36 %\n",
            "Epoch:27/100 AVG Training Loss:213.558 AVG Test Loss:3.912 AVG Training Acc 87.50 % AVG Test Acc 27.27 %\n",
            "Epoch:28/100 AVG Training Loss:211.655 AVG Test Loss:3.921 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:29/100 AVG Training Loss:211.267 AVG Test Loss:3.852 AVG Training Acc 84.38 % AVG Test Acc 36.36 %\n",
            "Epoch:30/100 AVG Training Loss:210.226 AVG Test Loss:3.886 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:31/100 AVG Training Loss:209.543 AVG Test Loss:3.670 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:32/100 AVG Training Loss:207.954 AVG Test Loss:3.718 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:33/100 AVG Training Loss:207.552 AVG Test Loss:3.618 AVG Training Acc 84.38 % AVG Test Acc 36.36 %\n",
            "Epoch:34/100 AVG Training Loss:205.975 AVG Test Loss:3.721 AVG Training Acc 96.88 % AVG Test Acc 27.27 %\n",
            "Epoch:35/100 AVG Training Loss:205.294 AVG Test Loss:3.655 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:36/100 AVG Training Loss:204.016 AVG Test Loss:3.636 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:37/100 AVG Training Loss:203.325 AVG Test Loss:3.611 AVG Training Acc 90.62 % AVG Test Acc 36.36 %\n",
            "Epoch:38/100 AVG Training Loss:201.759 AVG Test Loss:3.578 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:39/100 AVG Training Loss:201.343 AVG Test Loss:3.514 AVG Training Acc 90.62 % AVG Test Acc 36.36 %\n",
            "Epoch:40/100 AVG Training Loss:200.066 AVG Test Loss:3.596 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:41/100 AVG Training Loss:199.069 AVG Test Loss:3.497 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:42/100 AVG Training Loss:198.118 AVG Test Loss:3.521 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:43/100 AVG Training Loss:197.387 AVG Test Loss:3.445 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:44/100 AVG Training Loss:196.144 AVG Test Loss:3.370 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:45/100 AVG Training Loss:195.154 AVG Test Loss:3.373 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:46/100 AVG Training Loss:193.909 AVG Test Loss:3.444 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:47/100 AVG Training Loss:193.690 AVG Test Loss:3.326 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:48/100 AVG Training Loss:192.690 AVG Test Loss:3.287 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:49/100 AVG Training Loss:191.436 AVG Test Loss:3.269 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:50/100 AVG Training Loss:190.919 AVG Test Loss:3.247 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:51/100 AVG Training Loss:189.480 AVG Test Loss:3.107 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:52/100 AVG Training Loss:188.269 AVG Test Loss:3.191 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:53/100 AVG Training Loss:187.087 AVG Test Loss:3.190 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:54/100 AVG Training Loss:186.332 AVG Test Loss:3.178 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:55/100 AVG Training Loss:185.826 AVG Test Loss:3.144 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:56/100 AVG Training Loss:184.597 AVG Test Loss:3.122 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:57/100 AVG Training Loss:183.617 AVG Test Loss:2.979 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:58/100 AVG Training Loss:182.645 AVG Test Loss:3.008 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:59/100 AVG Training Loss:181.295 AVG Test Loss:3.037 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:60/100 AVG Training Loss:180.927 AVG Test Loss:2.917 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:61/100 AVG Training Loss:179.769 AVG Test Loss:2.959 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:62/100 AVG Training Loss:178.618 AVG Test Loss:2.896 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:63/100 AVG Training Loss:177.845 AVG Test Loss:2.966 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:64/100 AVG Training Loss:176.895 AVG Test Loss:2.834 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:65/100 AVG Training Loss:175.949 AVG Test Loss:2.832 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:66/100 AVG Training Loss:174.645 AVG Test Loss:2.904 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:67/100 AVG Training Loss:174.216 AVG Test Loss:2.835 AVG Training Acc 87.50 % AVG Test Acc 36.36 %\n",
            "Epoch:68/100 AVG Training Loss:172.942 AVG Test Loss:2.706 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:69/100 AVG Training Loss:172.332 AVG Test Loss:2.734 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:70/100 AVG Training Loss:171.235 AVG Test Loss:2.866 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:71/100 AVG Training Loss:170.471 AVG Test Loss:2.717 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:72/100 AVG Training Loss:169.378 AVG Test Loss:2.726 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:73/100 AVG Training Loss:168.301 AVG Test Loss:2.674 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:74/100 AVG Training Loss:167.378 AVG Test Loss:2.696 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:75/100 AVG Training Loss:166.622 AVG Test Loss:2.672 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:76/100 AVG Training Loss:165.271 AVG Test Loss:2.644 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:77/100 AVG Training Loss:164.955 AVG Test Loss:2.617 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:78/100 AVG Training Loss:163.747 AVG Test Loss:2.675 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:79/100 AVG Training Loss:162.853 AVG Test Loss:2.623 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:80/100 AVG Training Loss:161.819 AVG Test Loss:2.599 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:81/100 AVG Training Loss:161.369 AVG Test Loss:2.715 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:82/100 AVG Training Loss:160.600 AVG Test Loss:2.511 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:83/100 AVG Training Loss:159.320 AVG Test Loss:2.457 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:84/100 AVG Training Loss:158.683 AVG Test Loss:2.491 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:85/100 AVG Training Loss:157.538 AVG Test Loss:2.417 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:86/100 AVG Training Loss:156.798 AVG Test Loss:2.484 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:87/100 AVG Training Loss:156.033 AVG Test Loss:2.554 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:88/100 AVG Training Loss:155.073 AVG Test Loss:2.418 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:89/100 AVG Training Loss:154.318 AVG Test Loss:2.364 AVG Training Acc 93.75 % AVG Test Acc 36.36 %\n",
            "Epoch:90/100 AVG Training Loss:153.334 AVG Test Loss:2.323 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:91/100 AVG Training Loss:152.377 AVG Test Loss:2.354 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:92/100 AVG Training Loss:151.639 AVG Test Loss:2.319 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:93/100 AVG Training Loss:150.889 AVG Test Loss:2.242 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:94/100 AVG Training Loss:149.835 AVG Test Loss:2.282 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:95/100 AVG Training Loss:149.220 AVG Test Loss:2.397 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:96/100 AVG Training Loss:148.265 AVG Test Loss:2.299 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:97/100 AVG Training Loss:147.532 AVG Test Loss:2.245 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:98/100 AVG Training Loss:146.428 AVG Test Loss:2.221 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:99/100 AVG Training Loss:145.887 AVG Test Loss:2.206 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Epoch:100/100 AVG Training Loss:144.885 AVG Test Loss:2.198 AVG Training Acc 100.00 % AVG Test Acc 36.36 %\n",
            "Fold 2\n",
            "Epoch:1/100 AVG Training Loss:242.040 AVG Test Loss:6.622 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:2/100 AVG Training Loss:240.811 AVG Test Loss:6.483 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:3/100 AVG Training Loss:239.624 AVG Test Loss:6.485 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:4/100 AVG Training Loss:238.479 AVG Test Loss:6.394 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:5/100 AVG Training Loss:237.269 AVG Test Loss:6.129 AVG Training Acc 34.38 % AVG Test Acc 0.00 %\n",
            "Epoch:6/100 AVG Training Loss:236.167 AVG Test Loss:5.916 AVG Training Acc 46.88 % AVG Test Acc 27.27 %\n",
            "Epoch:7/100 AVG Training Loss:234.952 AVG Test Loss:5.781 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:8/100 AVG Training Loss:233.748 AVG Test Loss:5.555 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:9/100 AVG Training Loss:232.621 AVG Test Loss:5.406 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:10/100 AVG Training Loss:231.637 AVG Test Loss:5.311 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:11/100 AVG Training Loss:230.240 AVG Test Loss:5.116 AVG Training Acc 87.50 % AVG Test Acc 63.64 %\n",
            "Epoch:12/100 AVG Training Loss:229.093 AVG Test Loss:4.953 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:13/100 AVG Training Loss:227.977 AVG Test Loss:4.955 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:14/100 AVG Training Loss:226.770 AVG Test Loss:4.748 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:15/100 AVG Training Loss:225.685 AVG Test Loss:4.608 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:16/100 AVG Training Loss:224.395 AVG Test Loss:4.536 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:17/100 AVG Training Loss:223.374 AVG Test Loss:4.353 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:18/100 AVG Training Loss:222.289 AVG Test Loss:4.284 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:19/100 AVG Training Loss:220.963 AVG Test Loss:4.247 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:20/100 AVG Training Loss:220.107 AVG Test Loss:4.149 AVG Training Acc 84.38 % AVG Test Acc 45.45 %\n",
            "Epoch:21/100 AVG Training Loss:218.415 AVG Test Loss:4.071 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:22/100 AVG Training Loss:218.287 AVG Test Loss:4.001 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:23/100 AVG Training Loss:217.184 AVG Test Loss:3.924 AVG Training Acc 71.88 % AVG Test Acc 54.55 %\n",
            "Epoch:24/100 AVG Training Loss:216.175 AVG Test Loss:3.769 AVG Training Acc 75.00 % AVG Test Acc 54.55 %\n",
            "Epoch:25/100 AVG Training Loss:214.504 AVG Test Loss:3.845 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:26/100 AVG Training Loss:213.793 AVG Test Loss:3.801 AVG Training Acc 87.50 % AVG Test Acc 45.45 %\n",
            "Epoch:27/100 AVG Training Loss:212.489 AVG Test Loss:3.749 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:28/100 AVG Training Loss:211.742 AVG Test Loss:3.715 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:29/100 AVG Training Loss:210.743 AVG Test Loss:3.689 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:30/100 AVG Training Loss:209.094 AVG Test Loss:3.689 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:31/100 AVG Training Loss:208.105 AVG Test Loss:3.677 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:32/100 AVG Training Loss:207.405 AVG Test Loss:3.656 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:33/100 AVG Training Loss:207.016 AVG Test Loss:3.588 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:34/100 AVG Training Loss:205.704 AVG Test Loss:3.515 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:35/100 AVG Training Loss:204.103 AVG Test Loss:3.536 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:36/100 AVG Training Loss:203.683 AVG Test Loss:3.486 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:37/100 AVG Training Loss:202.671 AVG Test Loss:3.458 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:38/100 AVG Training Loss:201.688 AVG Test Loss:3.387 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:39/100 AVG Training Loss:200.959 AVG Test Loss:3.385 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:40/100 AVG Training Loss:199.938 AVG Test Loss:3.305 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:41/100 AVG Training Loss:198.912 AVG Test Loss:3.284 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:42/100 AVG Training Loss:197.903 AVG Test Loss:3.229 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:43/100 AVG Training Loss:196.880 AVG Test Loss:3.210 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:44/100 AVG Training Loss:195.155 AVG Test Loss:3.208 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:45/100 AVG Training Loss:194.652 AVG Test Loss:3.329 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:46/100 AVG Training Loss:193.412 AVG Test Loss:3.149 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:47/100 AVG Training Loss:192.658 AVG Test Loss:3.124 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:48/100 AVG Training Loss:191.432 AVG Test Loss:3.144 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:49/100 AVG Training Loss:190.923 AVG Test Loss:3.096 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:50/100 AVG Training Loss:189.921 AVG Test Loss:3.103 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:51/100 AVG Training Loss:188.472 AVG Test Loss:3.068 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:52/100 AVG Training Loss:187.931 AVG Test Loss:2.975 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:53/100 AVG Training Loss:186.716 AVG Test Loss:2.973 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:54/100 AVG Training Loss:186.151 AVG Test Loss:2.887 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:55/100 AVG Training Loss:184.752 AVG Test Loss:3.010 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:56/100 AVG Training Loss:183.755 AVG Test Loss:2.804 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:57/100 AVG Training Loss:182.611 AVG Test Loss:2.868 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:58/100 AVG Training Loss:181.820 AVG Test Loss:2.864 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:59/100 AVG Training Loss:181.042 AVG Test Loss:2.729 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:60/100 AVG Training Loss:179.879 AVG Test Loss:2.728 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:61/100 AVG Training Loss:178.746 AVG Test Loss:2.746 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:62/100 AVG Training Loss:177.775 AVG Test Loss:2.734 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:63/100 AVG Training Loss:176.811 AVG Test Loss:2.723 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:64/100 AVG Training Loss:175.871 AVG Test Loss:2.730 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:65/100 AVG Training Loss:174.915 AVG Test Loss:2.741 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:66/100 AVG Training Loss:173.936 AVG Test Loss:2.749 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:67/100 AVG Training Loss:173.161 AVG Test Loss:2.724 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:68/100 AVG Training Loss:172.383 AVG Test Loss:2.619 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:69/100 AVG Training Loss:171.604 AVG Test Loss:2.559 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:70/100 AVG Training Loss:170.184 AVG Test Loss:2.610 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:71/100 AVG Training Loss:169.531 AVG Test Loss:2.822 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:72/100 AVG Training Loss:168.755 AVG Test Loss:2.643 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:73/100 AVG Training Loss:167.532 AVG Test Loss:2.511 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:74/100 AVG Training Loss:166.293 AVG Test Loss:2.516 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:75/100 AVG Training Loss:165.529 AVG Test Loss:2.545 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:76/100 AVG Training Loss:164.609 AVG Test Loss:2.490 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:77/100 AVG Training Loss:163.706 AVG Test Loss:2.545 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:78/100 AVG Training Loss:162.917 AVG Test Loss:2.500 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:79/100 AVG Training Loss:161.858 AVG Test Loss:2.417 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:80/100 AVG Training Loss:161.126 AVG Test Loss:2.384 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:81/100 AVG Training Loss:160.070 AVG Test Loss:2.400 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:82/100 AVG Training Loss:159.189 AVG Test Loss:2.579 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:83/100 AVG Training Loss:158.553 AVG Test Loss:2.717 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:84/100 AVG Training Loss:157.407 AVG Test Loss:2.702 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:85/100 AVG Training Loss:156.775 AVG Test Loss:2.351 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:86/100 AVG Training Loss:155.646 AVG Test Loss:2.438 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:87/100 AVG Training Loss:154.788 AVG Test Loss:2.331 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:88/100 AVG Training Loss:154.131 AVG Test Loss:2.299 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:89/100 AVG Training Loss:153.042 AVG Test Loss:2.255 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:90/100 AVG Training Loss:152.314 AVG Test Loss:2.379 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:91/100 AVG Training Loss:151.639 AVG Test Loss:2.194 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:92/100 AVG Training Loss:150.673 AVG Test Loss:2.193 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:93/100 AVG Training Loss:149.511 AVG Test Loss:2.226 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:94/100 AVG Training Loss:148.761 AVG Test Loss:2.213 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:95/100 AVG Training Loss:148.127 AVG Test Loss:2.310 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:96/100 AVG Training Loss:147.197 AVG Test Loss:2.195 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:97/100 AVG Training Loss:146.455 AVG Test Loss:2.147 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:98/100 AVG Training Loss:145.426 AVG Test Loss:2.196 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:99/100 AVG Training Loss:144.698 AVG Test Loss:2.146 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:100/100 AVG Training Loss:143.952 AVG Test Loss:2.195 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Fold 3\n",
            "Epoch:1/100 AVG Training Loss:242.072 AVG Test Loss:6.614 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:2/100 AVG Training Loss:240.875 AVG Test Loss:6.490 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:3/100 AVG Training Loss:239.691 AVG Test Loss:6.458 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:4/100 AVG Training Loss:238.533 AVG Test Loss:6.367 AVG Training Acc 6.25 % AVG Test Acc 9.09 %\n",
            "Epoch:5/100 AVG Training Loss:237.366 AVG Test Loss:6.007 AVG Training Acc 34.38 % AVG Test Acc 18.18 %\n",
            "Epoch:6/100 AVG Training Loss:236.309 AVG Test Loss:5.776 AVG Training Acc 62.50 % AVG Test Acc 27.27 %\n",
            "Epoch:7/100 AVG Training Loss:235.125 AVG Test Loss:5.524 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:8/100 AVG Training Loss:233.996 AVG Test Loss:5.349 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:9/100 AVG Training Loss:232.854 AVG Test Loss:5.165 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:10/100 AVG Training Loss:231.687 AVG Test Loss:5.051 AVG Training Acc 84.38 % AVG Test Acc 54.55 %\n",
            "Epoch:11/100 AVG Training Loss:230.666 AVG Test Loss:4.828 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:12/100 AVG Training Loss:229.440 AVG Test Loss:4.694 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:13/100 AVG Training Loss:228.322 AVG Test Loss:4.462 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:14/100 AVG Training Loss:227.098 AVG Test Loss:4.385 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:15/100 AVG Training Loss:226.222 AVG Test Loss:4.152 AVG Training Acc 78.12 % AVG Test Acc 54.55 %\n",
            "Epoch:16/100 AVG Training Loss:224.870 AVG Test Loss:4.021 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:17/100 AVG Training Loss:223.691 AVG Test Loss:3.885 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:18/100 AVG Training Loss:222.907 AVG Test Loss:3.873 AVG Training Acc 75.00 % AVG Test Acc 63.64 %\n",
            "Epoch:19/100 AVG Training Loss:221.615 AVG Test Loss:3.763 AVG Training Acc 84.38 % AVG Test Acc 63.64 %\n",
            "Epoch:20/100 AVG Training Loss:220.464 AVG Test Loss:3.654 AVG Training Acc 84.38 % AVG Test Acc 63.64 %\n",
            "Epoch:21/100 AVG Training Loss:219.575 AVG Test Loss:3.628 AVG Training Acc 90.62 % AVG Test Acc 63.64 %\n",
            "Epoch:22/100 AVG Training Loss:218.742 AVG Test Loss:3.485 AVG Training Acc 81.25 % AVG Test Acc 45.45 %\n",
            "Epoch:23/100 AVG Training Loss:217.452 AVG Test Loss:3.385 AVG Training Acc 81.25 % AVG Test Acc 63.64 %\n",
            "Epoch:24/100 AVG Training Loss:216.678 AVG Test Loss:3.353 AVG Training Acc 87.50 % AVG Test Acc 63.64 %\n",
            "Epoch:25/100 AVG Training Loss:215.379 AVG Test Loss:3.275 AVG Training Acc 84.38 % AVG Test Acc 63.64 %\n",
            "Epoch:26/100 AVG Training Loss:214.376 AVG Test Loss:3.316 AVG Training Acc 81.25 % AVG Test Acc 63.64 %\n",
            "Epoch:27/100 AVG Training Loss:213.352 AVG Test Loss:3.208 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:28/100 AVG Training Loss:212.088 AVG Test Loss:3.267 AVG Training Acc 90.62 % AVG Test Acc 63.64 %\n",
            "Epoch:29/100 AVG Training Loss:211.396 AVG Test Loss:3.167 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:30/100 AVG Training Loss:210.677 AVG Test Loss:3.070 AVG Training Acc 81.25 % AVG Test Acc 54.55 %\n",
            "Epoch:31/100 AVG Training Loss:209.402 AVG Test Loss:3.006 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:32/100 AVG Training Loss:208.106 AVG Test Loss:3.089 AVG Training Acc 90.62 % AVG Test Acc 63.64 %\n",
            "Epoch:33/100 AVG Training Loss:207.113 AVG Test Loss:3.049 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:34/100 AVG Training Loss:206.407 AVG Test Loss:3.031 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:35/100 AVG Training Loss:205.154 AVG Test Loss:3.000 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:36/100 AVG Training Loss:204.160 AVG Test Loss:2.905 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:37/100 AVG Training Loss:203.746 AVG Test Loss:2.921 AVG Training Acc 90.62 % AVG Test Acc 63.64 %\n",
            "Epoch:38/100 AVG Training Loss:202.445 AVG Test Loss:2.915 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:39/100 AVG Training Loss:201.464 AVG Test Loss:2.870 AVG Training Acc 87.50 % AVG Test Acc 54.55 %\n",
            "Epoch:40/100 AVG Training Loss:200.194 AVG Test Loss:2.827 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:41/100 AVG Training Loss:199.493 AVG Test Loss:2.795 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:42/100 AVG Training Loss:198.757 AVG Test Loss:2.727 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:43/100 AVG Training Loss:197.543 AVG Test Loss:2.706 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:44/100 AVG Training Loss:196.536 AVG Test Loss:2.724 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:45/100 AVG Training Loss:195.056 AVG Test Loss:2.726 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:46/100 AVG Training Loss:194.567 AVG Test Loss:2.705 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:47/100 AVG Training Loss:193.327 AVG Test Loss:2.668 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:48/100 AVG Training Loss:193.085 AVG Test Loss:2.512 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:49/100 AVG Training Loss:191.147 AVG Test Loss:2.600 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:50/100 AVG Training Loss:190.624 AVG Test Loss:2.579 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:51/100 AVG Training Loss:189.437 AVG Test Loss:2.570 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:52/100 AVG Training Loss:188.886 AVG Test Loss:2.490 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:53/100 AVG Training Loss:187.711 AVG Test Loss:2.463 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:54/100 AVG Training Loss:187.128 AVG Test Loss:2.380 AVG Training Acc 90.62 % AVG Test Acc 54.55 %\n",
            "Epoch:55/100 AVG Training Loss:185.339 AVG Test Loss:2.447 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:56/100 AVG Training Loss:184.968 AVG Test Loss:2.367 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:57/100 AVG Training Loss:183.794 AVG Test Loss:2.377 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:58/100 AVG Training Loss:182.629 AVG Test Loss:2.402 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:59/100 AVG Training Loss:181.694 AVG Test Loss:2.365 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:60/100 AVG Training Loss:180.914 AVG Test Loss:2.288 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:61/100 AVG Training Loss:179.955 AVG Test Loss:2.258 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:62/100 AVG Training Loss:178.817 AVG Test Loss:2.300 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:63/100 AVG Training Loss:178.224 AVG Test Loss:2.270 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:64/100 AVG Training Loss:176.901 AVG Test Loss:2.271 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:65/100 AVG Training Loss:176.486 AVG Test Loss:2.172 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:66/100 AVG Training Loss:175.389 AVG Test Loss:2.142 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:67/100 AVG Training Loss:173.903 AVG Test Loss:2.176 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:68/100 AVG Training Loss:172.987 AVG Test Loss:2.171 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:69/100 AVG Training Loss:172.382 AVG Test Loss:2.136 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:70/100 AVG Training Loss:171.604 AVG Test Loss:2.088 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:71/100 AVG Training Loss:170.668 AVG Test Loss:2.121 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:72/100 AVG Training Loss:169.419 AVG Test Loss:2.107 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:73/100 AVG Training Loss:168.680 AVG Test Loss:2.083 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:74/100 AVG Training Loss:167.599 AVG Test Loss:2.021 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:75/100 AVG Training Loss:166.812 AVG Test Loss:1.986 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:76/100 AVG Training Loss:165.907 AVG Test Loss:1.994 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:77/100 AVG Training Loss:165.150 AVG Test Loss:1.959 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:78/100 AVG Training Loss:164.096 AVG Test Loss:1.965 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:79/100 AVG Training Loss:163.468 AVG Test Loss:1.904 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:80/100 AVG Training Loss:162.163 AVG Test Loss:1.954 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:81/100 AVG Training Loss:161.143 AVG Test Loss:1.927 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:82/100 AVG Training Loss:160.515 AVG Test Loss:1.892 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:83/100 AVG Training Loss:159.636 AVG Test Loss:1.929 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:84/100 AVG Training Loss:158.759 AVG Test Loss:1.869 AVG Training Acc 93.75 % AVG Test Acc 45.45 %\n",
            "Epoch:85/100 AVG Training Loss:157.754 AVG Test Loss:1.910 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:86/100 AVG Training Loss:156.858 AVG Test Loss:1.872 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:87/100 AVG Training Loss:156.135 AVG Test Loss:1.839 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:88/100 AVG Training Loss:155.268 AVG Test Loss:1.807 AVG Training Acc 93.75 % AVG Test Acc 54.55 %\n",
            "Epoch:89/100 AVG Training Loss:154.383 AVG Test Loss:1.806 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:90/100 AVG Training Loss:153.654 AVG Test Loss:1.807 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:91/100 AVG Training Loss:152.587 AVG Test Loss:1.871 AVG Training Acc 93.75 % AVG Test Acc 63.64 %\n",
            "Epoch:92/100 AVG Training Loss:151.844 AVG Test Loss:1.803 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:93/100 AVG Training Loss:150.780 AVG Test Loss:1.796 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:94/100 AVG Training Loss:150.250 AVG Test Loss:1.822 AVG Training Acc 96.88 % AVG Test Acc 63.64 %\n",
            "Epoch:95/100 AVG Training Loss:149.293 AVG Test Loss:1.793 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:96/100 AVG Training Loss:148.365 AVG Test Loss:1.784 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:97/100 AVG Training Loss:147.834 AVG Test Loss:1.651 AVG Training Acc 96.88 % AVG Test Acc 45.45 %\n",
            "Epoch:98/100 AVG Training Loss:146.993 AVG Test Loss:1.670 AVG Training Acc 96.88 % AVG Test Acc 54.55 %\n",
            "Epoch:99/100 AVG Training Loss:145.865 AVG Test Loss:1.708 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:100/100 AVG Training Loss:144.972 AVG Test Loss:1.748 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Fold 4\n",
            "Epoch:1/100 AVG Training Loss:242.045 AVG Test Loss:6.618 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:2/100 AVG Training Loss:240.806 AVG Test Loss:6.542 AVG Training Acc 0.00 % AVG Test Acc 0.00 %\n",
            "Epoch:3/100 AVG Training Loss:239.555 AVG Test Loss:6.519 AVG Training Acc 0.00 % AVG Test Acc 40.00 %\n",
            "Epoch:4/100 AVG Training Loss:238.373 AVG Test Loss:6.300 AVG Training Acc 3.03 % AVG Test Acc 20.00 %\n",
            "Epoch:5/100 AVG Training Loss:237.151 AVG Test Loss:5.875 AVG Training Acc 18.18 % AVG Test Acc 10.00 %\n",
            "Epoch:6/100 AVG Training Loss:235.826 AVG Test Loss:5.590 AVG Training Acc 81.82 % AVG Test Acc 40.00 %\n",
            "Epoch:7/100 AVG Training Loss:234.746 AVG Test Loss:5.498 AVG Training Acc 75.76 % AVG Test Acc 50.00 %\n",
            "Epoch:8/100 AVG Training Loss:233.542 AVG Test Loss:5.292 AVG Training Acc 84.85 % AVG Test Acc 60.00 %\n",
            "Epoch:9/100 AVG Training Loss:232.218 AVG Test Loss:4.991 AVG Training Acc 90.91 % AVG Test Acc 70.00 %\n",
            "Epoch:10/100 AVG Training Loss:231.133 AVG Test Loss:4.933 AVG Training Acc 84.85 % AVG Test Acc 60.00 %\n",
            "Epoch:11/100 AVG Training Loss:229.924 AVG Test Loss:4.687 AVG Training Acc 87.88 % AVG Test Acc 60.00 %\n",
            "Epoch:12/100 AVG Training Loss:228.721 AVG Test Loss:4.571 AVG Training Acc 87.88 % AVG Test Acc 60.00 %\n",
            "Epoch:13/100 AVG Training Loss:227.597 AVG Test Loss:4.262 AVG Training Acc 87.88 % AVG Test Acc 50.00 %\n",
            "Epoch:14/100 AVG Training Loss:226.396 AVG Test Loss:4.105 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:15/100 AVG Training Loss:225.218 AVG Test Loss:4.209 AVG Training Acc 75.76 % AVG Test Acc 50.00 %\n",
            "Epoch:16/100 AVG Training Loss:224.227 AVG Test Loss:3.802 AVG Training Acc 69.70 % AVG Test Acc 60.00 %\n",
            "Epoch:17/100 AVG Training Loss:222.997 AVG Test Loss:3.704 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:18/100 AVG Training Loss:221.842 AVG Test Loss:3.523 AVG Training Acc 81.82 % AVG Test Acc 50.00 %\n",
            "Epoch:19/100 AVG Training Loss:220.508 AVG Test Loss:3.636 AVG Training Acc 90.91 % AVG Test Acc 70.00 %\n",
            "Epoch:20/100 AVG Training Loss:219.490 AVG Test Loss:3.396 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:21/100 AVG Training Loss:218.705 AVG Test Loss:3.160 AVG Training Acc 81.82 % AVG Test Acc 60.00 %\n",
            "Epoch:22/100 AVG Training Loss:216.801 AVG Test Loss:3.196 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:23/100 AVG Training Loss:216.222 AVG Test Loss:3.291 AVG Training Acc 90.91 % AVG Test Acc 60.00 %\n",
            "Epoch:24/100 AVG Training Loss:214.736 AVG Test Loss:3.132 AVG Training Acc 87.88 % AVG Test Acc 60.00 %\n",
            "Epoch:25/100 AVG Training Loss:214.018 AVG Test Loss:3.027 AVG Training Acc 78.79 % AVG Test Acc 50.00 %\n",
            "Epoch:26/100 AVG Training Loss:213.043 AVG Test Loss:2.876 AVG Training Acc 90.91 % AVG Test Acc 60.00 %\n",
            "Epoch:27/100 AVG Training Loss:211.763 AVG Test Loss:2.980 AVG Training Acc 75.76 % AVG Test Acc 70.00 %\n",
            "Epoch:28/100 AVG Training Loss:210.533 AVG Test Loss:2.986 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:29/100 AVG Training Loss:209.891 AVG Test Loss:2.686 AVG Training Acc 87.88 % AVG Test Acc 40.00 %\n",
            "Epoch:30/100 AVG Training Loss:208.673 AVG Test Loss:2.548 AVG Training Acc 84.85 % AVG Test Acc 40.00 %\n",
            "Epoch:31/100 AVG Training Loss:207.988 AVG Test Loss:2.488 AVG Training Acc 90.91 % AVG Test Acc 70.00 %\n",
            "Epoch:32/100 AVG Training Loss:206.134 AVG Test Loss:2.800 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:33/100 AVG Training Loss:205.207 AVG Test Loss:2.629 AVG Training Acc 90.91 % AVG Test Acc 50.00 %\n",
            "Epoch:34/100 AVG Training Loss:204.511 AVG Test Loss:2.539 AVG Training Acc 87.88 % AVG Test Acc 70.00 %\n",
            "Epoch:35/100 AVG Training Loss:203.399 AVG Test Loss:2.468 AVG Training Acc 87.88 % AVG Test Acc 60.00 %\n",
            "Epoch:36/100 AVG Training Loss:202.110 AVG Test Loss:2.582 AVG Training Acc 93.94 % AVG Test Acc 50.00 %\n",
            "Epoch:37/100 AVG Training Loss:201.413 AVG Test Loss:2.485 AVG Training Acc 93.94 % AVG Test Acc 40.00 %\n",
            "Epoch:38/100 AVG Training Loss:200.385 AVG Test Loss:2.497 AVG Training Acc 93.94 % AVG Test Acc 70.00 %\n",
            "Epoch:39/100 AVG Training Loss:199.481 AVG Test Loss:2.547 AVG Training Acc 87.88 % AVG Test Acc 60.00 %\n",
            "Epoch:40/100 AVG Training Loss:198.097 AVG Test Loss:2.524 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:41/100 AVG Training Loss:197.279 AVG Test Loss:2.407 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:42/100 AVG Training Loss:196.046 AVG Test Loss:2.514 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:43/100 AVG Training Loss:195.011 AVG Test Loss:2.490 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:44/100 AVG Training Loss:194.009 AVG Test Loss:2.519 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:45/100 AVG Training Loss:193.071 AVG Test Loss:2.285 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:46/100 AVG Training Loss:192.262 AVG Test Loss:2.093 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:47/100 AVG Training Loss:191.118 AVG Test Loss:2.271 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:48/100 AVG Training Loss:190.008 AVG Test Loss:2.212 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:49/100 AVG Training Loss:188.884 AVG Test Loss:2.281 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:50/100 AVG Training Loss:187.976 AVG Test Loss:2.084 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:51/100 AVG Training Loss:186.962 AVG Test Loss:2.100 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:52/100 AVG Training Loss:185.585 AVG Test Loss:2.079 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:53/100 AVG Training Loss:185.199 AVG Test Loss:2.112 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:54/100 AVG Training Loss:183.841 AVG Test Loss:2.086 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:55/100 AVG Training Loss:183.024 AVG Test Loss:2.061 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:56/100 AVG Training Loss:181.831 AVG Test Loss:2.135 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:57/100 AVG Training Loss:180.668 AVG Test Loss:2.132 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:58/100 AVG Training Loss:179.903 AVG Test Loss:1.953 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:59/100 AVG Training Loss:178.754 AVG Test Loss:1.958 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:60/100 AVG Training Loss:177.750 AVG Test Loss:1.891 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:61/100 AVG Training Loss:176.851 AVG Test Loss:2.008 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:62/100 AVG Training Loss:175.693 AVG Test Loss:2.127 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:63/100 AVG Training Loss:174.861 AVG Test Loss:2.023 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:64/100 AVG Training Loss:173.734 AVG Test Loss:1.978 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:65/100 AVG Training Loss:173.426 AVG Test Loss:1.774 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:66/100 AVG Training Loss:172.117 AVG Test Loss:1.763 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:67/100 AVG Training Loss:170.654 AVG Test Loss:1.975 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:68/100 AVG Training Loss:170.060 AVG Test Loss:1.761 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:69/100 AVG Training Loss:168.990 AVG Test Loss:1.911 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:70/100 AVG Training Loss:168.026 AVG Test Loss:1.882 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:71/100 AVG Training Loss:167.067 AVG Test Loss:1.814 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:72/100 AVG Training Loss:165.908 AVG Test Loss:1.852 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:73/100 AVG Training Loss:165.363 AVG Test Loss:1.771 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:74/100 AVG Training Loss:164.198 AVG Test Loss:1.768 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:75/100 AVG Training Loss:163.373 AVG Test Loss:2.062 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:76/100 AVG Training Loss:162.314 AVG Test Loss:1.967 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:77/100 AVG Training Loss:161.312 AVG Test Loss:1.665 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:78/100 AVG Training Loss:160.622 AVG Test Loss:1.758 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:79/100 AVG Training Loss:159.512 AVG Test Loss:1.829 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:80/100 AVG Training Loss:158.945 AVG Test Loss:1.517 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:81/100 AVG Training Loss:157.671 AVG Test Loss:1.661 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:82/100 AVG Training Loss:156.540 AVG Test Loss:1.749 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:83/100 AVG Training Loss:155.946 AVG Test Loss:1.897 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:84/100 AVG Training Loss:154.953 AVG Test Loss:1.577 AVG Training Acc 93.94 % AVG Test Acc 60.00 %\n",
            "Epoch:85/100 AVG Training Loss:154.044 AVG Test Loss:1.945 AVG Training Acc 93.94 % AVG Test Acc 50.00 %\n",
            "Epoch:86/100 AVG Training Loss:153.126 AVG Test Loss:1.741 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:87/100 AVG Training Loss:152.038 AVG Test Loss:1.740 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:88/100 AVG Training Loss:151.366 AVG Test Loss:1.771 AVG Training Acc 96.97 % AVG Test Acc 50.00 %\n",
            "Epoch:89/100 AVG Training Loss:150.567 AVG Test Loss:1.686 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:90/100 AVG Training Loss:149.569 AVG Test Loss:1.630 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:91/100 AVG Training Loss:148.696 AVG Test Loss:1.783 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:92/100 AVG Training Loss:148.005 AVG Test Loss:1.614 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:93/100 AVG Training Loss:147.011 AVG Test Loss:1.419 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:94/100 AVG Training Loss:146.227 AVG Test Loss:1.464 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:95/100 AVG Training Loss:145.461 AVG Test Loss:1.447 AVG Training Acc 96.97 % AVG Test Acc 60.00 %\n",
            "Epoch:96/100 AVG Training Loss:144.619 AVG Test Loss:1.485 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:97/100 AVG Training Loss:143.476 AVG Test Loss:1.455 AVG Training Acc 100.00 % AVG Test Acc 70.00 %\n",
            "Epoch:98/100 AVG Training Loss:142.713 AVG Test Loss:1.445 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "Epoch:99/100 AVG Training Loss:141.951 AVG Test Loss:1.523 AVG Training Acc 100.00 % AVG Test Acc 40.00 %\n",
            "Epoch:100/100 AVG Training Loss:141.137 AVG Test Loss:1.388 AVG Training Acc 100.00 % AVG Test Acc 60.00 %\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 4 FOLDS\n",
            "Fold 0: 36.36363636363637 %\n",
            "Fold 1: 54.54545454545454 %\n",
            "Fold 2: 45.45454545454545 %\n",
            "Fold 3: 60.0 %\n",
            "Average: 49.09090909090909 %\n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "\n",
        "splits = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "results, results1 = {}, {}\n",
        "trained_models = {}\n",
        "\n",
        "splits0 = splits.split(dataset0, dataset0.labels)\n",
        "splits1 = splits.split(dataset1, dataset1.labels)\n",
        "\n",
        "for fold, ((train_idx, val_idx), (train_idx1, val_idx1)) in enumerate(zip(splits0, splits1)):\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = copy.deepcopy(model_resnet)\n",
        "    model.to(device)  \n",
        "    optimizer = Adam(model.parameters(), lr=grid_param['learning_rate'][0])\n",
        "\n",
        "    joined_ids = np.concatenate((val_idx, [x+(len(dataset0)) for x in val_idx1]))\n",
        "    shapes_test = np.concatenate((np.zeros((len(val_idx), 1)), np.ones((len(val_idx1), 1))))\n",
        "    test_loader = DataLoader(joined_dataset, batch_size=grid_param['batch_size'][0]) #, sampler=SubsetRandomSampler(joined_ids))\n",
        "\n",
        "    if seq:\n",
        "      train_loader = DataLoader(dataset0, batch_size=grid_param['batch_size'][0]) #, sampler=SubsetRandomSampler(train_idx))\n",
        "      shapes_train = np.zeros((len(train_idx), 1))\n",
        "      results[fold] = train_loop(model, device, num_epochs, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "      train_loader1 = DataLoader(dataset1, batch_size=grid_param['batch_size'][0]) #, sampler=SubsetRandomSampler(train_idx1))\n",
        "      shapes_train1 = np.ones((len(train_idx1), 1))\n",
        "      results1[fold] = train_loop(model, device, num_epochs, train_loader1, test_loader, criterion, optimizer, shapes_train1, shapes_test)\n",
        "    else:\n",
        "      joined_train_ids = np.concatenate((train_idx, [x+(len(dataset0)) for x in train_idx1]))\n",
        "      shapes_train = np.concatenate((np.zeros((len(train_idx), 1)), np.ones((len(train_idx1), 1))))\n",
        "      train_loader = DataLoader(joined_dataset, batch_size=grid_param['batch_size'][0]) #, sampler=SubsetRandomSampler(joined_train_ids))\n",
        "      results[fold] = train_loop(model, device, num_epochs, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "    \n",
        "    trained_models[fold] = model\n",
        "      \n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k} FOLDS')\n",
        "print_folds_results(results)\n",
        "if seq:\n",
        "  print_folds_results(results1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gduQP_iu6zkL"
      },
      "outputs": [],
      "source": [
        "#train - after refactor\n",
        "\n",
        "splits = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "results, results1 = {}, {}\n",
        "trained_models = {}\n",
        "\n",
        "splits0 = splits.split(dataset0, dataset0.labels)\n",
        "splits1 = splits.split(dataset1, dataset1.labels)\n",
        "\n",
        "for fold, ((train_idx, val_idx), (train_idx1, val_idx1)) in enumerate(zip(splits0, splits1)):\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = copy.deepcopy(model_resnet)\n",
        "    model.to(device)  \n",
        "    optimizer = Adam(model.parameters(), lr=grid_param['learning_rate'][0])\n",
        "\n",
        "    joined_ids = np.concatenate((val_idx, [x+(len(dataset0)) for x in val_idx1]))\n",
        "    shapes_test = np.concatenate((np.zeros((len(val_idx), 1)), np.ones((len(val_idx1), 1))))\n",
        "    test_loader = DataLoader(joined_dataset, batch_size=grid_param['batch_size'][0], sampler=SubsetRandomSampler(joined_ids))\n",
        "\n",
        "    if seq:\n",
        "      train_loader = DataLoader(dataset0, batch_size=grid_param['batch_size'][0], sampler=SubsetRandomSampler(train_idx))\n",
        "      shapes_train = np.zeros((len(train_idx), 1))\n",
        "      results[fold] = train_loop(model, device, num_epochs, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "      train_loader1 = DataLoader(dataset1, batch_size=grid_param['batch_size'][0], sampler=SubsetRandomSampler(train_idx1))\n",
        "      shapes_train1 = np.ones((len(train_idx1), 1))\n",
        "      results1[fold] = train_loop(model, device, num_epochs, train_loader1, test_loader, criterion, optimizer, shapes_train1, shapes_test)\n",
        "    else:\n",
        "      joined_train_ids = np.concatenate((train_idx, [x+(len(dataset0)) for x in train_idx1]))\n",
        "      shapes_train = np.concatenate((np.zeros((len(train_idx), 1)), np.ones((len(train_idx1), 1))))\n",
        "      train_loader = DataLoader(joined_dataset, batch_size=grid_param['batch_size'][0], sampler=SubsetRandomSampler(joined_train_ids))\n",
        "      results[fold] = train_loop(model, device, num_epochs, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "    \n",
        "    trained_models[fold] = model\n",
        "      \n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k} FOLDS')\n",
        "print_folds_results(results)\n",
        "if seq:\n",
        "  print_folds_results(results1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqV5whtGzg7D"
      },
      "source": [
        "# Basic net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypu8ByOjxQKl"
      },
      "outputs": [],
      "source": [
        "class MousesDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.samples = x \n",
        "        self.labels = y \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoegLSWN8Vdn"
      },
      "outputs": [],
      "source": [
        "fat = [load_image(os.path.join(FAT_DIR, filename), 1, False, True) for filename in os.listdir(FAT_DIR)]\n",
        "healthy = [load_image(os.path.join(HEALTHY_DIR, filename), 0, False, True) for filename in os.listdir(HEALTHY_DIR)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcs_vnjM1Go2",
        "outputId": "5a5b8c9f-519e-4773-b3d0-a3c3016c1d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train size: (39, 192, 192) (39,) float64\n",
            "test size: (4, 192, 192) (4,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "val_x = np.array([fat[0][0], fat[1][0], healthy[0][0], healthy[1][0]]).astype(np.double)\n",
        "val_y = np.array([fat[0][1], fat[1][1], healthy[0][1], healthy[1][1]]).astype(np.double)\n",
        "\n",
        "all = np.array(fat[2:] + healthy[2:])\n",
        "#all = np.array(fat_a + healthy_a)\n",
        "np.random.shuffle(all)\n",
        "\n",
        "train_x = np.array([x[0] for x in all]).astype(np.double)\n",
        "train_y = np.array([x[1] for x in all]).astype(np.double)\n",
        "\n",
        "print(\"train size:\", train_x.shape, train_y.shape, train_x.dtype)\n",
        "print(\"test size:\", val_x.shape, val_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "018ZSbB1y6rT"
      },
      "outputs": [],
      "source": [
        "# converting training images into torch format - for old only\n",
        "train_x, train_y = conver_into_toarch(train_x, train_y)\n",
        "val_x, val_y = conver_into_toarch(val_x, val_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ7AWy3spCaR",
        "outputId": "9e2722a4-ec7d-43c7-ba65-cebea1c3ab23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 39  test dataset size: 4\n"
          ]
        }
      ],
      "source": [
        "#prepare datasets\n",
        "\n",
        "train_dataset = MousesDataset(train_x, train_y)\n",
        "test_dataset = MousesDataset(val_x, val_y)\n",
        "print(\"Train dataset size:\", len(train_dataset), \" test dataset size:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BV3VslWI11R"
      },
      "outputs": [],
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    \n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFDdR6UtJFID"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
        "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
        "    # converting the data into GPU format\n",
        "    if torch.cuda.is_available():\n",
        "        x_train = x_train.cuda()\n",
        "        y_train = y_train.cuda()\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "\n",
        "    # clearing the Gradients of the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # prediction for training and validation set\n",
        "    output_train = model(x_train.float())\n",
        "    output_val = model(x_val.float())\n",
        "\n",
        "    # computing the training and validation loss\n",
        "    loss_train = criterion(output_train, y_train)\n",
        "    loss_val = criterion(output_val, y_val)\n",
        "    train_losses.append(loss_train)\n",
        "    val_losses.append(loss_val)\n",
        "\n",
        "    # computing the updated weights of all the model parameters\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    tr_loss = loss_train.item()\n",
        "    if epoch%2 == 0:\n",
        "        print('Epoch : ',epoch+1, '\\t', 'loss tr :', loss_train, 'loss val:', loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiFsyC8VJPGJ"
      },
      "outputs": [],
      "source": [
        "#normal train\n",
        "n_epochs = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzcBVrGBc30f",
        "outputId": "ed555c89-8c8c-41a9-c368-53f34e0bd2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction on test set: 0.568075117370892  prediction on val set: 0.5\n"
          ]
        }
      ],
      "source": [
        "# prediction for training and val set\n",
        "\n",
        "print(\"Prediction on test set:\", predict_function(train_x, train_y), \" prediction on val set:\", predict_function(val_x, val_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a96puGfTvxZB"
      },
      "source": [
        "Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leXJG3q3aySB"
      },
      "outputs": [],
      "source": [
        "LR = 0.01\n",
        "BATCH_SIZE = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-E1ovvi5qC"
      },
      "outputs": [],
      "source": [
        "def predict_function(x, y):\n",
        "  with torch.no_grad():\n",
        "    output = model(x.float())\n",
        "    \n",
        "  softmax = torch.nn.functional.softmax(output, 1)\n",
        "  prob = list(softmax.numpy())\n",
        "  predictions = np.argmax(prob, axis=1)\n",
        "\n",
        "  return accuracy_score(y, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "wU1_NJdIzHqA",
        "outputId": "48f0c100-5a1e-46d7-fb5e-75e090d52a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL shape: (192, 192, 3) min: 0.0  max: 2497.0985384544074\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AFTER CAST shape: (192, 192, 3) min: 0  max: 249\n",
            "AFTER TRANS shape: torch.Size([3, 192, 192]) min: 0.0  max: 0.9764706\n",
            "AFTER TRANS shape: torch.Size([3, 192, 192]) min: 0.0  max: 0.9764706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img shape: (192, 192, 3)\n",
            "img shape po transpozyjci: (3, 192, 192)\n",
            "AFTER TRANS shape: torch.Size([3, 192, 192]) min: 0.0  max: 249.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#get one image and print it 4,15,1-3, 1-9\n",
        "\n",
        "#image = self.image_list[i]    \n",
        "#image = np.array(image/10).astype(np.uint8) \n",
        "#image = self.transforms(image) \n",
        "#image = image/2500 \n",
        "#return (torch.tensor(image, dtype=torch.float), self.labels[i])\n",
        "model = trained_models[0]\n",
        "img = dataset1.image_list[0]\n",
        "print(\"NORMAL shape:\", img.shape, \"min:\", np.min(img), \" max:\", np.max(img))\n",
        "plt.imshow(img/2500)\n",
        "plt.show()\n",
        "\n",
        "#like in net\n",
        "img = np.array(img/10).astype(np.uint8)\n",
        "print(\"AFTER CAST shape:\", img.shape, \"min:\", np.min(img), \" max:\", np.max(img)) \n",
        "img = resnet_transform(img)\n",
        "print(\"AFTER TRANS shape:\", img.shape, \"min:\", np.min(img.numpy()), \" max:\", np.max(img.numpy())) \n",
        "img = torch.tensor(img, dtype=torch.float)\n",
        "print(\"AFTER TRANS shape:\", img.shape, \"min:\", np.min(img.numpy()), \" max:\", np.max(img.numpy())) \n",
        "plt.imshow(img.numpy()[1])\n",
        "plt.show()\n",
        "\n",
        "#transformed\n",
        "img = dataset1.image_list[0]\n",
        "img = np.array(img/10).astype(np.uint8)\n",
        "print(\"img shape:\", img.shape)\n",
        "img = img.transpose((-1, 0, 1))\n",
        "print(\"img shape po transpozyjci:\", img.shape)\n",
        "#img = resnet_transform(img)\n",
        "img = torch.tensor(img, dtype=torch.float)\n",
        "print(\"AFTER TRANS shape:\", img.shape, \"min:\", np.min(img.numpy()), \" max:\", np.max(img.numpy())) \n",
        "plt.imshow(img.numpy()[1])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zs8VPEalsuX"
      },
      "outputs": [],
      "source": [
        "print(\"LAYER4: \", model.layer4)\n",
        "\n",
        "print(\"MODEL:\", list(model.modules()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "kqf8WshD7u6h",
        "outputId": "689df6e4-658a-4948-b33b-cf35bdef03c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label: 1\n",
            "input_tensor shape: torch.Size([1, 3, 192, 192])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=192x192 at 0x7FD1BC28C6D0>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#gradcam\n",
        "i = 1\n",
        "image = dataset1.image_list[i]\n",
        "label = dataset1.labels[i]\n",
        "print(\"label:\", label)\n",
        "\n",
        "last_conv_layer = list(model.children())[1]\n",
        "target_layers = [model.layer4[0]]\n",
        "input_tensor = torch.from_numpy(image.transpose((-1, 0, 1))).float().unsqueeze(0) #.unsqueeze(0)\n",
        "print(\"input_tensor shape:\", input_tensor.shape)\n",
        "\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
        "targets = [ClassifierOutputTarget(1)]\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# In this example grayscale_cam has only one image in the batch:\n",
        "grayscale_cam = grayscale_cam[0, :]\n",
        "img = np.zeros((192,192))\n",
        "#background_image = np.array([img,img,img]).reshape(192, 192, 3)\n",
        "background_image = image/2500\n",
        "visualization = show_cam_on_image(background_image, grayscale_cam, use_rgb=True)\n",
        "\n",
        "plt.imshow(image/2500)\n",
        "plt.show()\n",
        "Image.fromarray(visualization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GlCRkSNx84J"
      },
      "source": [
        "# olds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bnA6ZUwfweZq",
        "outputId": "b0b3cca0-b756-4232-f646-0ec9d121a065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------\n",
            "Fold 1. train_idx:[ 0  1  4  5  6  9 10 11 13 14 15 16 17 18 19 20 22 23] val_idx:[ 2  3  7  8 12 21] train_idx1:[ 0  2  3  6  7  8  9 11 13 14 15 16 17 18] val_idx1:[ 1  4  5 10 12]\n",
            "Epoch:1/20 AVG Training Loss:10.440 AVG Test Loss:0.692 AVG Training Acc 85.19 % AVG Test Acc 45.45 %\n",
            "Epoch:2/20 AVG Training Loss:10.450 AVG Test Loss:0.689 AVG Training Acc 66.67 % AVG Test Acc 36.36 %\n",
            "Epoch:3/20 AVG Training Loss:10.454 AVG Test Loss:0.685 AVG Training Acc 70.37 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:10.404 AVG Test Loss:0.677 AVG Training Acc 70.37 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:10.420 AVG Test Loss:0.667 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:6/20 AVG Training Loss:10.410 AVG Test Loss:0.654 AVG Training Acc 62.96 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:10.379 AVG Test Loss:0.644 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:10.387 AVG Test Loss:0.638 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:10.375 AVG Test Loss:0.634 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:10.375 AVG Test Loss:0.631 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:10.356 AVG Test Loss:0.629 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:10.365 AVG Test Loss:0.627 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:10.337 AVG Test Loss:0.625 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:10.330 AVG Test Loss:0.623 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:15/20 AVG Training Loss:10.332 AVG Test Loss:0.620 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:10.322 AVG Test Loss:0.618 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:10.309 AVG Test Loss:0.616 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:10.304 AVG Test Loss:0.614 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:19/20 AVG Training Loss:10.319 AVG Test Loss:0.611 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:20/20 AVG Training Loss:10.305 AVG Test Loss:0.609 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:10.549 AVG Test Loss:0.689 AVG Training Acc 59.26 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:10.538 AVG Test Loss:0.681 AVG Training Acc 55.56 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:10.576 AVG Test Loss:0.661 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:10.476 AVG Test Loss:0.636 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:10.525 AVG Test Loss:0.614 AVG Training Acc 48.15 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:10.511 AVG Test Loss:0.600 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:10.476 AVG Test Loss:0.592 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:10.467 AVG Test Loss:0.587 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:10.507 AVG Test Loss:0.584 AVG Training Acc 48.15 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:10.448 AVG Test Loss:0.582 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:10.446 AVG Test Loss:0.584 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:10.427 AVG Test Loss:0.583 AVG Training Acc 55.56 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:10.391 AVG Test Loss:0.581 AVG Training Acc 62.96 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:10.425 AVG Test Loss:0.578 AVG Training Acc 62.96 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:10.403 AVG Test Loss:0.571 AVG Training Acc 55.56 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:10.393 AVG Test Loss:0.568 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:10.362 AVG Test Loss:0.564 AVG Training Acc 62.96 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:10.347 AVG Test Loss:0.563 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:10.352 AVG Test Loss:0.562 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:10.371 AVG Test Loss:0.559 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:1/20 AVG Training Loss:10.560 AVG Test Loss:0.695 AVG Training Acc 57.14 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:10.548 AVG Test Loss:0.697 AVG Training Acc 53.57 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:10.538 AVG Test Loss:0.705 AVG Training Acc 53.57 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:10.481 AVG Test Loss:0.714 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:10.530 AVG Test Loss:0.724 AVG Training Acc 53.57 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:10.439 AVG Test Loss:0.732 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:10.439 AVG Test Loss:0.732 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:10.413 AVG Test Loss:0.728 AVG Training Acc 64.29 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:10.415 AVG Test Loss:0.719 AVG Training Acc 60.71 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:10.426 AVG Test Loss:0.711 AVG Training Acc 60.71 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:10.397 AVG Test Loss:0.702 AVG Training Acc 71.43 % AVG Test Acc 70.00 %\n",
            "Epoch:12/20 AVG Training Loss:10.381 AVG Test Loss:0.694 AVG Training Acc 67.86 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:10.386 AVG Test Loss:0.686 AVG Training Acc 67.86 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:10.380 AVG Test Loss:0.679 AVG Training Acc 75.00 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:10.335 AVG Test Loss:0.671 AVG Training Acc 75.00 % AVG Test Acc 70.00 %\n",
            "Epoch:16/20 AVG Training Loss:10.336 AVG Test Loss:0.664 AVG Training Acc 75.00 % AVG Test Acc 80.00 %\n",
            "Epoch:17/20 AVG Training Loss:10.338 AVG Test Loss:0.655 AVG Training Acc 75.00 % AVG Test Acc 80.00 %\n",
            "Epoch:18/20 AVG Training Loss:10.293 AVG Test Loss:0.647 AVG Training Acc 78.57 % AVG Test Acc 70.00 %\n",
            "Epoch:19/20 AVG Training Loss:10.264 AVG Test Loss:0.640 AVG Training Acc 82.14 % AVG Test Acc 80.00 %\n",
            "Epoch:20/20 AVG Training Loss:10.284 AVG Test Loss:0.635 AVG Training Acc 78.57 % AVG Test Acc 80.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 58.82352941176471 %\n",
            "Fold 1 acc: 70.58823529411765 %\n",
            "Fold 2 acc: 69.23076923076923 %\n",
            " Average acc: 66.21417797888385 %\n",
            "Epoch:1/20 AVG Training Loss:28.367 AVG Test Loss:0.680 AVG Training Acc 51.85 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:28.316 AVG Test Loss:0.674 AVG Training Acc 51.85 % AVG Test Acc 54.55 %\n",
            "Epoch:3/20 AVG Training Loss:28.286 AVG Test Loss:0.665 AVG Training Acc 55.56 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:28.290 AVG Test Loss:0.652 AVG Training Acc 55.56 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:28.205 AVG Test Loss:0.641 AVG Training Acc 70.37 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:28.200 AVG Test Loss:0.635 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:28.185 AVG Test Loss:0.629 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:28.172 AVG Test Loss:0.620 AVG Training Acc 70.37 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:28.119 AVG Test Loss:0.615 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:28.104 AVG Test Loss:0.606 AVG Training Acc 74.07 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:28.063 AVG Test Loss:0.601 AVG Training Acc 74.07 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:28.034 AVG Test Loss:0.595 AVG Training Acc 77.78 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:28.006 AVG Test Loss:0.589 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:27.979 AVG Test Loss:0.582 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:27.932 AVG Test Loss:0.577 AVG Training Acc 88.89 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:27.943 AVG Test Loss:0.572 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:27.906 AVG Test Loss:0.568 AVG Training Acc 85.19 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:27.847 AVG Test Loss:0.562 AVG Training Acc 88.89 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:27.824 AVG Test Loss:0.556 AVG Training Acc 88.89 % AVG Test Acc 81.82 %\n",
            "Epoch:20/20 AVG Training Loss:27.797 AVG Test Loss:0.550 AVG Training Acc 88.89 % AVG Test Acc 90.91 %\n",
            "Epoch:1/20 AVG Training Loss:28.379 AVG Test Loss:0.674 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:28.367 AVG Test Loss:0.641 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:28.310 AVG Test Loss:0.628 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:28.316 AVG Test Loss:0.610 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:28.282 AVG Test Loss:0.598 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:28.267 AVG Test Loss:0.596 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:28.211 AVG Test Loss:0.594 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:28.191 AVG Test Loss:0.587 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:28.179 AVG Test Loss:0.589 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:28.167 AVG Test Loss:0.575 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:28.131 AVG Test Loss:0.575 AVG Training Acc 74.07 % AVG Test Acc 90.91 %\n",
            "Epoch:12/20 AVG Training Loss:28.117 AVG Test Loss:0.583 AVG Training Acc 66.67 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:28.093 AVG Test Loss:0.575 AVG Training Acc 70.37 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:28.063 AVG Test Loss:0.568 AVG Training Acc 77.78 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:28.054 AVG Test Loss:0.571 AVG Training Acc 77.78 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:28.017 AVG Test Loss:0.567 AVG Training Acc 74.07 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:27.986 AVG Test Loss:0.564 AVG Training Acc 81.48 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:27.953 AVG Test Loss:0.557 AVG Training Acc 85.19 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:27.940 AVG Test Loss:0.559 AVG Training Acc 77.78 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:27.908 AVG Test Loss:0.549 AVG Training Acc 81.48 % AVG Test Acc 90.91 %\n",
            "Epoch:1/20 AVG Training Loss:28.428 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:28.400 AVG Test Loss:0.694 AVG Training Acc 53.57 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:28.343 AVG Test Loss:0.692 AVG Training Acc 57.14 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:28.328 AVG Test Loss:0.686 AVG Training Acc 53.57 % AVG Test Acc 60.00 %\n",
            "Epoch:5/20 AVG Training Loss:28.259 AVG Test Loss:0.676 AVG Training Acc 53.57 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:28.243 AVG Test Loss:0.664 AVG Training Acc 64.29 % AVG Test Acc 60.00 %\n",
            "Epoch:7/20 AVG Training Loss:28.200 AVG Test Loss:0.649 AVG Training Acc 64.29 % AVG Test Acc 70.00 %\n",
            "Epoch:8/20 AVG Training Loss:28.142 AVG Test Loss:0.634 AVG Training Acc 71.43 % AVG Test Acc 70.00 %\n",
            "Epoch:9/20 AVG Training Loss:28.129 AVG Test Loss:0.618 AVG Training Acc 75.00 % AVG Test Acc 70.00 %\n",
            "Epoch:10/20 AVG Training Loss:28.084 AVG Test Loss:0.608 AVG Training Acc 71.43 % AVG Test Acc 70.00 %\n",
            "Epoch:11/20 AVG Training Loss:28.018 AVG Test Loss:0.598 AVG Training Acc 85.71 % AVG Test Acc 70.00 %\n",
            "Epoch:12/20 AVG Training Loss:28.025 AVG Test Loss:0.587 AVG Training Acc 82.14 % AVG Test Acc 70.00 %\n",
            "Epoch:13/20 AVG Training Loss:27.978 AVG Test Loss:0.574 AVG Training Acc 92.86 % AVG Test Acc 70.00 %\n",
            "Epoch:14/20 AVG Training Loss:27.945 AVG Test Loss:0.566 AVG Training Acc 82.14 % AVG Test Acc 70.00 %\n",
            "Epoch:15/20 AVG Training Loss:27.921 AVG Test Loss:0.549 AVG Training Acc 89.29 % AVG Test Acc 80.00 %\n",
            "Epoch:16/20 AVG Training Loss:27.898 AVG Test Loss:0.539 AVG Training Acc 89.29 % AVG Test Acc 80.00 %\n",
            "Epoch:17/20 AVG Training Loss:27.848 AVG Test Loss:0.527 AVG Training Acc 92.86 % AVG Test Acc 80.00 %\n",
            "Epoch:18/20 AVG Training Loss:27.816 AVG Test Loss:0.516 AVG Training Acc 92.86 % AVG Test Acc 80.00 %\n",
            "Epoch:19/20 AVG Training Loss:27.776 AVG Test Loss:0.508 AVG Training Acc 96.43 % AVG Test Acc 80.00 %\n",
            "Epoch:20/20 AVG Training Loss:27.762 AVG Test Loss:0.504 AVG Training Acc 96.43 % AVG Test Acc 80.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 65.0 %\n",
            "Fold 1 acc: 55.172413793103445 %\n",
            "Fold 2 acc: 69.23076923076923 %\n",
            " Average acc: 63.1343943412909 %\n",
            "Epoch:1/20 AVG Training Loss:626.045 AVG Test Loss:0.678 AVG Training Acc 48.15 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:624.054 AVG Test Loss:0.648 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:622.086 AVG Test Loss:0.588 AVG Training Acc 96.30 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:620.133 AVG Test Loss:0.503 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:5/20 AVG Training Loss:618.146 AVG Test Loss:0.419 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:6/20 AVG Training Loss:616.159 AVG Test Loss:0.352 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:7/20 AVG Training Loss:614.093 AVG Test Loss:0.329 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:8/20 AVG Training Loss:612.008 AVG Test Loss:0.314 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:9/20 AVG Training Loss:609.892 AVG Test Loss:0.306 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:607.742 AVG Test Loss:0.299 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:11/20 AVG Training Loss:605.573 AVG Test Loss:0.280 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:12/20 AVG Training Loss:603.380 AVG Test Loss:0.287 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:601.167 AVG Test Loss:0.288 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:598.935 AVG Test Loss:0.293 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:596.692 AVG Test Loss:0.302 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:594.426 AVG Test Loss:0.280 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:17/20 AVG Training Loss:592.151 AVG Test Loss:0.299 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:589.867 AVG Test Loss:0.288 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:587.568 AVG Test Loss:0.285 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:585.260 AVG Test Loss:0.283 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:1/20 AVG Training Loss:626.228 AVG Test Loss:0.748 AVG Training Acc 55.56 % AVG Test Acc 27.27 %\n",
            "Epoch:2/20 AVG Training Loss:624.452 AVG Test Loss:0.644 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:622.467 AVG Test Loss:0.610 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:620.596 AVG Test Loss:0.644 AVG Training Acc 96.30 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:618.748 AVG Test Loss:0.446 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:616.856 AVG Test Loss:0.347 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:7/20 AVG Training Loss:614.918 AVG Test Loss:0.355 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:612.946 AVG Test Loss:0.308 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:9/20 AVG Training Loss:610.942 AVG Test Loss:0.297 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:608.902 AVG Test Loss:0.318 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:606.833 AVG Test Loss:0.264 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:12/20 AVG Training Loss:604.740 AVG Test Loss:0.306 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:602.616 AVG Test Loss:0.267 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:600.478 AVG Test Loss:0.270 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:15/20 AVG Training Loss:598.323 AVG Test Loss:0.301 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:16/20 AVG Training Loss:596.145 AVG Test Loss:0.289 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:17/20 AVG Training Loss:593.953 AVG Test Loss:0.276 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:18/20 AVG Training Loss:591.748 AVG Test Loss:0.275 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:589.532 AVG Test Loss:0.303 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:20/20 AVG Training Loss:587.298 AVG Test Loss:0.278 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:1/20 AVG Training Loss:626.246 AVG Test Loss:0.694 AVG Training Acc 50.00 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:624.136 AVG Test Loss:0.666 AVG Training Acc 46.43 % AVG Test Acc 90.00 %\n",
            "Epoch:3/20 AVG Training Loss:622.068 AVG Test Loss:0.612 AVG Training Acc 100.00 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:620.271 AVG Test Loss:0.494 AVG Training Acc 67.86 % AVG Test Acc 100.00 %\n",
            "Epoch:5/20 AVG Training Loss:618.237 AVG Test Loss:0.392 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:6/20 AVG Training Loss:616.206 AVG Test Loss:0.318 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:7/20 AVG Training Loss:614.171 AVG Test Loss:0.282 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:8/20 AVG Training Loss:612.096 AVG Test Loss:0.260 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:9/20 AVG Training Loss:610.002 AVG Test Loss:0.234 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:10/20 AVG Training Loss:607.859 AVG Test Loss:0.222 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:11/20 AVG Training Loss:605.684 AVG Test Loss:0.216 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:12/20 AVG Training Loss:603.482 AVG Test Loss:0.212 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:13/20 AVG Training Loss:601.253 AVG Test Loss:0.205 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:14/20 AVG Training Loss:599.004 AVG Test Loss:0.209 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:15/20 AVG Training Loss:596.738 AVG Test Loss:0.201 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:16/20 AVG Training Loss:594.442 AVG Test Loss:0.200 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:17/20 AVG Training Loss:592.128 AVG Test Loss:0.200 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:18/20 AVG Training Loss:589.810 AVG Test Loss:0.195 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:19/20 AVG Training Loss:587.472 AVG Test Loss:0.204 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "Epoch:20/20 AVG Training Loss:585.114 AVG Test Loss:0.200 AVG Training Acc 100.00 % AVG Test Acc 90.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 70.58823529411765 %\n",
            "Fold 1 acc: 60.0 %\n",
            "Fold 2 acc: 76.92307692307693 %\n",
            " Average acc: 69.17043740573153 %\n",
            "grid_param: {'learning_rate': [1e-06], 'batch_size': [3], 'dropout': [0.1], 'num_epochs': [20], 'l1_regularization_lambda': [0.001], 'l2_regularization_lambda': [0.0], 'number_of_filers': [2, 4, 32]}  grid: [[[[[[[0.66214178 0.63134394 0.69170437]]]]]]]\n",
            "best: 0.6917043740573153 best_idx: (0, 0, 0, 0, 0, 0, 2)\n",
            "best params: {'learning_rate': 1e-06, 'batch_size': 3, 'dropout': 0.1, 'num_epochs': 20, 'l1_regularization_lambda': 0.001, 'l2_regularization_lambda': 0.0, 'number_of_filers': 32}\n",
            "Epoch:1/20 AVG Training Loss:625.843 AVG Test Loss:0.691 AVG Training Acc 46.88 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:623.405 AVG Test Loss:0.647 AVG Training Acc 75.00 % AVG Test Acc 90.91 %\n",
            "Epoch:3/20 AVG Training Loss:621.067 AVG Test Loss:0.684 AVG Training Acc 96.88 % AVG Test Acc 36.36 %\n",
            "Epoch:4/20 AVG Training Loss:618.756 AVG Test Loss:0.525 AVG Training Acc 96.88 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:616.381 AVG Test Loss:0.527 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:6/20 AVG Training Loss:614.012 AVG Test Loss:0.470 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:611.557 AVG Test Loss:0.453 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:8/20 AVG Training Loss:609.076 AVG Test Loss:0.482 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:606.579 AVG Test Loss:0.464 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:604.029 AVG Test Loss:0.460 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:601.457 AVG Test Loss:0.457 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:598.856 AVG Test Loss:0.448 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:596.233 AVG Test Loss:0.453 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:593.594 AVG Test Loss:0.455 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:590.928 AVG Test Loss:0.454 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:16/20 AVG Training Loss:588.246 AVG Test Loss:0.456 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:17/20 AVG Training Loss:585.550 AVG Test Loss:0.440 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:582.833 AVG Test Loss:0.440 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:580.110 AVG Test Loss:0.448 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:577.372 AVG Test Loss:0.451 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Fold 2. train_idx:[ 0  1  2  3  4  6  7  8  9 10 12 13 15 18 19 20 21 23] val_idx:[ 5 11 14 16 17 22] train_idx1:[ 1  2  3  4  5  6  7  9 10 11 12 16 17 18] val_idx1:[ 0  8 13 14 15]\n",
            "Epoch:1/20 AVG Training Loss:10.530 AVG Test Loss:0.682 AVG Training Acc 44.44 % AVG Test Acc 63.64 %\n",
            "Epoch:2/20 AVG Training Loss:10.518 AVG Test Loss:0.675 AVG Training Acc 44.44 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:10.507 AVG Test Loss:0.665 AVG Training Acc 48.15 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:10.491 AVG Test Loss:0.662 AVG Training Acc 51.85 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:10.474 AVG Test Loss:0.662 AVG Training Acc 59.26 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:10.461 AVG Test Loss:0.667 AVG Training Acc 51.85 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:10.425 AVG Test Loss:0.670 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:8/20 AVG Training Loss:10.450 AVG Test Loss:0.664 AVG Training Acc 66.67 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:10.441 AVG Test Loss:0.659 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:10.424 AVG Test Loss:0.656 AVG Training Acc 59.26 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:10.425 AVG Test Loss:0.649 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:10.393 AVG Test Loss:0.645 AVG Training Acc 66.67 % AVG Test Acc 54.55 %\n",
            "Epoch:13/20 AVG Training Loss:10.380 AVG Test Loss:0.639 AVG Training Acc 70.37 % AVG Test Acc 54.55 %\n",
            "Epoch:14/20 AVG Training Loss:10.392 AVG Test Loss:0.634 AVG Training Acc 62.96 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:10.359 AVG Test Loss:0.629 AVG Training Acc 62.96 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:10.363 AVG Test Loss:0.625 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:10.375 AVG Test Loss:0.621 AVG Training Acc 62.96 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:10.348 AVG Test Loss:0.615 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:19/20 AVG Training Loss:10.345 AVG Test Loss:0.613 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:20/20 AVG Training Loss:10.328 AVG Test Loss:0.608 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:10.516 AVG Test Loss:0.673 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:2/20 AVG Training Loss:10.495 AVG Test Loss:0.657 AVG Training Acc 55.56 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:10.475 AVG Test Loss:0.641 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:4/20 AVG Training Loss:10.477 AVG Test Loss:0.628 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:10.433 AVG Test Loss:0.619 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:10.458 AVG Test Loss:0.609 AVG Training Acc 55.56 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:10.439 AVG Test Loss:0.607 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:10.424 AVG Test Loss:0.606 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:10.426 AVG Test Loss:0.604 AVG Training Acc 55.56 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:10.391 AVG Test Loss:0.601 AVG Training Acc 66.67 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:10.381 AVG Test Loss:0.601 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:10.391 AVG Test Loss:0.597 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:10.340 AVG Test Loss:0.590 AVG Training Acc 70.37 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:10.364 AVG Test Loss:0.588 AVG Training Acc 70.37 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:10.366 AVG Test Loss:0.587 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:10.313 AVG Test Loss:0.582 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:10.320 AVG Test Loss:0.584 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:10.307 AVG Test Loss:0.580 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:19/20 AVG Training Loss:10.303 AVG Test Loss:0.576 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:20/20 AVG Training Loss:10.291 AVG Test Loss:0.568 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:10.485 AVG Test Loss:0.700 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:10.494 AVG Test Loss:0.704 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:10.455 AVG Test Loss:0.718 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:10.459 AVG Test Loss:0.751 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:10.475 AVG Test Loss:0.784 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:10.456 AVG Test Loss:0.795 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:10.394 AVG Test Loss:0.794 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:10.383 AVG Test Loss:0.786 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:10.405 AVG Test Loss:0.778 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:10.391 AVG Test Loss:0.767 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:10.361 AVG Test Loss:0.755 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:12/20 AVG Training Loss:10.338 AVG Test Loss:0.749 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:13/20 AVG Training Loss:10.356 AVG Test Loss:0.737 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:14/20 AVG Training Loss:10.338 AVG Test Loss:0.727 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:15/20 AVG Training Loss:10.318 AVG Test Loss:0.719 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:16/20 AVG Training Loss:10.304 AVG Test Loss:0.708 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:17/20 AVG Training Loss:10.299 AVG Test Loss:0.694 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:18/20 AVG Training Loss:10.274 AVG Test Loss:0.678 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:19/20 AVG Training Loss:10.258 AVG Test Loss:0.668 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:10.257 AVG Test Loss:0.662 AVG Training Acc 64.29 % AVG Test Acc 60.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 58.82352941176471 %\n",
            "Fold 1 acc: 58.82352941176471 %\n",
            "Fold 2 acc: 60.0 %\n",
            " Average acc: 59.21568627450981 %\n",
            "Epoch:1/20 AVG Training Loss:28.472 AVG Test Loss:0.701 AVG Training Acc 44.44 % AVG Test Acc 27.27 %\n",
            "Epoch:2/20 AVG Training Loss:28.387 AVG Test Loss:0.697 AVG Training Acc 51.85 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:28.312 AVG Test Loss:0.689 AVG Training Acc 59.26 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:28.291 AVG Test Loss:0.675 AVG Training Acc 55.56 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:28.244 AVG Test Loss:0.656 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:28.201 AVG Test Loss:0.639 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:28.173 AVG Test Loss:0.614 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:28.137 AVG Test Loss:0.594 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:28.107 AVG Test Loss:0.578 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:28.071 AVG Test Loss:0.565 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:28.013 AVG Test Loss:0.557 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:28.040 AVG Test Loss:0.547 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:13/20 AVG Training Loss:28.001 AVG Test Loss:0.537 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:14/20 AVG Training Loss:27.964 AVG Test Loss:0.529 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:15/20 AVG Training Loss:27.939 AVG Test Loss:0.521 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:16/20 AVG Training Loss:27.879 AVG Test Loss:0.513 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:17/20 AVG Training Loss:27.877 AVG Test Loss:0.505 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:18/20 AVG Training Loss:27.843 AVG Test Loss:0.499 AVG Training Acc 77.78 % AVG Test Acc 72.73 %\n",
            "Epoch:19/20 AVG Training Loss:27.821 AVG Test Loss:0.491 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:20/20 AVG Training Loss:27.771 AVG Test Loss:0.483 AVG Training Acc 85.19 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:28.422 AVG Test Loss:0.723 AVG Training Acc 51.85 % AVG Test Acc 27.27 %\n",
            "Epoch:2/20 AVG Training Loss:28.398 AVG Test Loss:0.730 AVG Training Acc 40.74 % AVG Test Acc 27.27 %\n",
            "Epoch:3/20 AVG Training Loss:28.351 AVG Test Loss:0.717 AVG Training Acc 59.26 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:28.286 AVG Test Loss:0.704 AVG Training Acc 55.56 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:28.233 AVG Test Loss:0.672 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:28.222 AVG Test Loss:0.635 AVG Training Acc 55.56 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:28.194 AVG Test Loss:0.610 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:28.168 AVG Test Loss:0.589 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:28.120 AVG Test Loss:0.579 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:28.091 AVG Test Loss:0.561 AVG Training Acc 74.07 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:28.044 AVG Test Loss:0.556 AVG Training Acc 85.19 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:28.033 AVG Test Loss:0.548 AVG Training Acc 81.48 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:27.969 AVG Test Loss:0.539 AVG Training Acc 88.89 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:27.940 AVG Test Loss:0.531 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:27.929 AVG Test Loss:0.516 AVG Training Acc 88.89 % AVG Test Acc 81.82 %\n",
            "Epoch:16/20 AVG Training Loss:27.900 AVG Test Loss:0.518 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:17/20 AVG Training Loss:27.867 AVG Test Loss:0.508 AVG Training Acc 88.89 % AVG Test Acc 81.82 %\n",
            "Epoch:18/20 AVG Training Loss:27.804 AVG Test Loss:0.501 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:27.784 AVG Test Loss:0.492 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:20/20 AVG Training Loss:27.773 AVG Test Loss:0.483 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:1/20 AVG Training Loss:28.515 AVG Test Loss:0.699 AVG Training Acc 35.71 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:28.438 AVG Test Loss:0.718 AVG Training Acc 35.71 % AVG Test Acc 40.00 %\n",
            "Epoch:3/20 AVG Training Loss:28.378 AVG Test Loss:0.745 AVG Training Acc 53.57 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:28.342 AVG Test Loss:0.748 AVG Training Acc 46.43 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:28.310 AVG Test Loss:0.744 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:28.257 AVG Test Loss:0.732 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:7/20 AVG Training Loss:28.233 AVG Test Loss:0.711 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:8/20 AVG Training Loss:28.179 AVG Test Loss:0.704 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:9/20 AVG Training Loss:28.182 AVG Test Loss:0.689 AVG Training Acc 64.29 % AVG Test Acc 40.00 %\n",
            "Epoch:10/20 AVG Training Loss:28.149 AVG Test Loss:0.670 AVG Training Acc 60.71 % AVG Test Acc 40.00 %\n",
            "Epoch:11/20 AVG Training Loss:28.115 AVG Test Loss:0.645 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:28.074 AVG Test Loss:0.642 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:28.058 AVG Test Loss:0.627 AVG Training Acc 71.43 % AVG Test Acc 60.00 %\n",
            "Epoch:14/20 AVG Training Loss:28.056 AVG Test Loss:0.623 AVG Training Acc 71.43 % AVG Test Acc 60.00 %\n",
            "Epoch:15/20 AVG Training Loss:28.013 AVG Test Loss:0.608 AVG Training Acc 75.00 % AVG Test Acc 60.00 %\n",
            "Epoch:16/20 AVG Training Loss:27.987 AVG Test Loss:0.586 AVG Training Acc 75.00 % AVG Test Acc 60.00 %\n",
            "Epoch:17/20 AVG Training Loss:27.946 AVG Test Loss:0.575 AVG Training Acc 78.57 % AVG Test Acc 70.00 %\n",
            "Epoch:18/20 AVG Training Loss:27.905 AVG Test Loss:0.559 AVG Training Acc 82.14 % AVG Test Acc 90.00 %\n",
            "Epoch:19/20 AVG Training Loss:27.899 AVG Test Loss:0.550 AVG Training Acc 85.71 % AVG Test Acc 90.00 %\n",
            "Epoch:20/20 AVG Training Loss:27.861 AVG Test Loss:0.546 AVG Training Acc 82.14 % AVG Test Acc 90.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 58.82352941176471 %\n",
            "Fold 1 acc: 81.81818181818183 %\n",
            "Fold 2 acc: 63.1578947368421 %\n",
            " Average acc: 67.93320198892955 %\n",
            "Epoch:1/20 AVG Training Loss:625.913 AVG Test Loss:0.703 AVG Training Acc 55.56 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:623.734 AVG Test Loss:0.676 AVG Training Acc 92.59 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:621.759 AVG Test Loss:0.602 AVG Training Acc 92.59 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:619.732 AVG Test Loss:0.606 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:617.637 AVG Test Loss:0.386 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:6/20 AVG Training Loss:615.582 AVG Test Loss:0.318 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:7/20 AVG Training Loss:613.458 AVG Test Loss:0.299 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:8/20 AVG Training Loss:611.285 AVG Test Loss:0.253 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:9/20 AVG Training Loss:609.101 AVG Test Loss:0.245 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:10/20 AVG Training Loss:606.883 AVG Test Loss:0.236 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:604.643 AVG Test Loss:0.224 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:12/20 AVG Training Loss:602.380 AVG Test Loss:0.221 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:13/20 AVG Training Loss:600.092 AVG Test Loss:0.222 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:14/20 AVG Training Loss:597.794 AVG Test Loss:0.219 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:595.479 AVG Test Loss:0.216 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:16/20 AVG Training Loss:593.149 AVG Test Loss:0.215 AVG Training Acc 100.00 % AVG Test Acc 81.82 %\n",
            "Epoch:17/20 AVG Training Loss:590.799 AVG Test Loss:0.211 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:18/20 AVG Training Loss:588.445 AVG Test Loss:0.209 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:19/20 AVG Training Loss:586.080 AVG Test Loss:0.206 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:20/20 AVG Training Loss:583.704 AVG Test Loss:0.205 AVG Training Acc 100.00 % AVG Test Acc 90.91 %\n",
            "Epoch:1/20 AVG Training Loss:625.999 AVG Test Loss:0.709 AVG Training Acc 48.15 % AVG Test Acc 27.27 %\n",
            "Epoch:2/20 AVG Training Loss:623.892 AVG Test Loss:0.617 AVG Training Acc 81.48 % AVG Test Acc 100.00 %\n",
            "Epoch:3/20 AVG Training Loss:621.952 AVG Test Loss:0.686 AVG Training Acc 92.59 % AVG Test Acc 27.27 %\n",
            "Epoch:4/20 AVG Training Loss:619.973 AVG Test Loss:0.400 AVG Training Acc 96.30 % AVG Test Acc 100.00 %\n",
            "Epoch:5/20 AVG Training Loss:617.991 AVG Test Loss:0.406 AVG Training Acc 96.30 % AVG Test Acc 100.00 %\n",
            "Epoch:6/20 AVG Training Loss:615.908 AVG Test Loss:0.229 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:7/20 AVG Training Loss:613.836 AVG Test Loss:0.217 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:8/20 AVG Training Loss:611.732 AVG Test Loss:0.207 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:9/20 AVG Training Loss:609.581 AVG Test Loss:0.165 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:10/20 AVG Training Loss:607.411 AVG Test Loss:0.179 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:11/20 AVG Training Loss:605.216 AVG Test Loss:0.186 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:12/20 AVG Training Loss:602.988 AVG Test Loss:0.147 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:13/20 AVG Training Loss:600.753 AVG Test Loss:0.167 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:14/20 AVG Training Loss:598.493 AVG Test Loss:0.175 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:15/20 AVG Training Loss:596.215 AVG Test Loss:0.163 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:16/20 AVG Training Loss:593.925 AVG Test Loss:0.154 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:17/20 AVG Training Loss:591.625 AVG Test Loss:0.150 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:18/20 AVG Training Loss:589.309 AVG Test Loss:0.145 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:19/20 AVG Training Loss:586.980 AVG Test Loss:0.164 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:20/20 AVG Training Loss:584.642 AVG Test Loss:0.152 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:1/20 AVG Training Loss:626.193 AVG Test Loss:0.664 AVG Training Acc 50.00 % AVG Test Acc 60.00 %\n",
            "Epoch:2/20 AVG Training Loss:623.890 AVG Test Loss:0.661 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:621.766 AVG Test Loss:0.531 AVG Training Acc 92.86 % AVG Test Acc 80.00 %\n",
            "Epoch:4/20 AVG Training Loss:619.730 AVG Test Loss:0.428 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:5/20 AVG Training Loss:617.640 AVG Test Loss:0.337 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:6/20 AVG Training Loss:615.500 AVG Test Loss:0.229 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:7/20 AVG Training Loss:613.317 AVG Test Loss:0.174 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:8/20 AVG Training Loss:611.099 AVG Test Loss:0.167 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:9/20 AVG Training Loss:608.828 AVG Test Loss:0.138 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:10/20 AVG Training Loss:606.543 AVG Test Loss:0.132 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:11/20 AVG Training Loss:604.217 AVG Test Loss:0.122 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:12/20 AVG Training Loss:601.868 AVG Test Loss:0.123 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:13/20 AVG Training Loss:599.494 AVG Test Loss:0.115 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:14/20 AVG Training Loss:597.104 AVG Test Loss:0.114 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:15/20 AVG Training Loss:594.687 AVG Test Loss:0.108 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:16/20 AVG Training Loss:592.260 AVG Test Loss:0.111 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:17/20 AVG Training Loss:589.811 AVG Test Loss:0.101 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:18/20 AVG Training Loss:587.357 AVG Test Loss:0.105 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:19/20 AVG Training Loss:584.887 AVG Test Loss:0.108 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "Epoch:20/20 AVG Training Loss:582.402 AVG Test Loss:0.098 AVG Training Acc 100.00 % AVG Test Acc 100.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 70.58823529411765 %\n",
            "Fold 1 acc: 76.47058823529412 %\n",
            "Fold 2 acc: 84.61538461538461 %\n",
            " Average acc: 77.22473604826547 %\n",
            "grid_param: {'learning_rate': [1e-06], 'batch_size': [3], 'dropout': [0.1], 'num_epochs': [20], 'l1_regularization_lambda': [0.001], 'l2_regularization_lambda': [0.0], 'number_of_filers': [2, 4, 32]}  grid: [[[[[[[0.59215686 0.67933202 0.77224736]]]]]]]\n",
            "best: 0.7722473604826546 best_idx: (0, 0, 0, 0, 0, 0, 2)\n",
            "best params: {'learning_rate': 1e-06, 'batch_size': 3, 'dropout': 0.1, 'num_epochs': 20, 'l1_regularization_lambda': 0.001, 'l2_regularization_lambda': 0.0, 'number_of_filers': 32}\n",
            "Epoch:1/20 AVG Training Loss:625.952 AVG Test Loss:0.688 AVG Training Acc 53.12 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:623.519 AVG Test Loss:0.670 AVG Training Acc 75.00 % AVG Test Acc 72.73 %\n",
            "Epoch:3/20 AVG Training Loss:621.185 AVG Test Loss:0.644 AVG Training Acc 90.62 % AVG Test Acc 45.45 %\n",
            "Epoch:4/20 AVG Training Loss:618.857 AVG Test Loss:0.639 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:5/20 AVG Training Loss:616.460 AVG Test Loss:0.692 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:614.031 AVG Test Loss:0.742 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:7/20 AVG Training Loss:611.548 AVG Test Loss:0.741 AVG Training Acc 100.00 % AVG Test Acc 45.45 %\n",
            "Epoch:8/20 AVG Training Loss:609.015 AVG Test Loss:0.820 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:9/20 AVG Training Loss:606.452 AVG Test Loss:0.793 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:10/20 AVG Training Loss:603.859 AVG Test Loss:0.714 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:11/20 AVG Training Loss:601.230 AVG Test Loss:0.789 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:12/20 AVG Training Loss:598.579 AVG Test Loss:0.757 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:595.897 AVG Test Loss:0.766 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:593.197 AVG Test Loss:0.821 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:590.478 AVG Test Loss:0.750 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:587.741 AVG Test Loss:0.806 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:584.998 AVG Test Loss:0.826 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:18/20 AVG Training Loss:582.228 AVG Test Loss:0.765 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:579.450 AVG Test Loss:0.836 AVG Training Acc 100.00 % AVG Test Acc 54.55 %\n",
            "Epoch:20/20 AVG Training Loss:576.665 AVG Test Loss:0.815 AVG Training Acc 100.00 % AVG Test Acc 63.64 %\n",
            "Fold 3. train_idx:[ 0  2  3  5  6  7  8 10 11 12 13 14 16 17 19 20 21 22] val_idx:[ 1  4  9 15 18 23] train_idx1:[ 0  1  2  3  4  5  6  8 10 12 13 14 15 18] val_idx1:[ 7  9 11 16 17]\n",
            "Epoch:1/20 AVG Training Loss:10.520 AVG Test Loss:0.731 AVG Training Acc 51.85 % AVG Test Acc 18.18 %\n",
            "Epoch:2/20 AVG Training Loss:10.492 AVG Test Loss:0.728 AVG Training Acc 51.85 % AVG Test Acc 18.18 %\n",
            "Epoch:3/20 AVG Training Loss:10.480 AVG Test Loss:0.720 AVG Training Acc 44.44 % AVG Test Acc 18.18 %\n",
            "Epoch:4/20 AVG Training Loss:10.460 AVG Test Loss:0.698 AVG Training Acc 62.96 % AVG Test Acc 36.36 %\n",
            "Epoch:5/20 AVG Training Loss:10.468 AVG Test Loss:0.666 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:10.449 AVG Test Loss:0.640 AVG Training Acc 51.85 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:10.450 AVG Test Loss:0.620 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:10.439 AVG Test Loss:0.612 AVG Training Acc 62.96 % AVG Test Acc 81.82 %\n",
            "Epoch:9/20 AVG Training Loss:10.410 AVG Test Loss:0.599 AVG Training Acc 81.48 % AVG Test Acc 81.82 %\n",
            "Epoch:10/20 AVG Training Loss:10.379 AVG Test Loss:0.587 AVG Training Acc 74.07 % AVG Test Acc 81.82 %\n",
            "Epoch:11/20 AVG Training Loss:10.371 AVG Test Loss:0.575 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:12/20 AVG Training Loss:10.334 AVG Test Loss:0.568 AVG Training Acc 81.48 % AVG Test Acc 81.82 %\n",
            "Epoch:13/20 AVG Training Loss:10.377 AVG Test Loss:0.571 AVG Training Acc 70.37 % AVG Test Acc 81.82 %\n",
            "Epoch:14/20 AVG Training Loss:10.374 AVG Test Loss:0.566 AVG Training Acc 74.07 % AVG Test Acc 81.82 %\n",
            "Epoch:15/20 AVG Training Loss:10.359 AVG Test Loss:0.561 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:16/20 AVG Training Loss:10.327 AVG Test Loss:0.552 AVG Training Acc 85.19 % AVG Test Acc 81.82 %\n",
            "Epoch:17/20 AVG Training Loss:10.320 AVG Test Loss:0.544 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:18/20 AVG Training Loss:10.311 AVG Test Loss:0.538 AVG Training Acc 77.78 % AVG Test Acc 81.82 %\n",
            "Epoch:19/20 AVG Training Loss:10.313 AVG Test Loss:0.535 AVG Training Acc 81.48 % AVG Test Acc 81.82 %\n",
            "Epoch:20/20 AVG Training Loss:10.295 AVG Test Loss:0.526 AVG Training Acc 85.19 % AVG Test Acc 81.82 %\n",
            "Epoch:1/20 AVG Training Loss:10.504 AVG Test Loss:0.693 AVG Training Acc 59.26 % AVG Test Acc 54.55 %\n",
            "Epoch:2/20 AVG Training Loss:10.492 AVG Test Loss:0.692 AVG Training Acc 51.85 % AVG Test Acc 63.64 %\n",
            "Epoch:3/20 AVG Training Loss:10.465 AVG Test Loss:0.689 AVG Training Acc 62.96 % AVG Test Acc 63.64 %\n",
            "Epoch:4/20 AVG Training Loss:10.439 AVG Test Loss:0.681 AVG Training Acc 55.56 % AVG Test Acc 72.73 %\n",
            "Epoch:5/20 AVG Training Loss:10.461 AVG Test Loss:0.671 AVG Training Acc 59.26 % AVG Test Acc 72.73 %\n",
            "Epoch:6/20 AVG Training Loss:10.428 AVG Test Loss:0.657 AVG Training Acc 62.96 % AVG Test Acc 72.73 %\n",
            "Epoch:7/20 AVG Training Loss:10.410 AVG Test Loss:0.644 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:8/20 AVG Training Loss:10.392 AVG Test Loss:0.632 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:9/20 AVG Training Loss:10.376 AVG Test Loss:0.628 AVG Training Acc 74.07 % AVG Test Acc 72.73 %\n",
            "Epoch:10/20 AVG Training Loss:10.371 AVG Test Loss:0.624 AVG Training Acc 70.37 % AVG Test Acc 72.73 %\n",
            "Epoch:11/20 AVG Training Loss:10.376 AVG Test Loss:0.621 AVG Training Acc 66.67 % AVG Test Acc 72.73 %\n",
            "Epoch:12/20 AVG Training Loss:10.355 AVG Test Loss:0.620 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:10.349 AVG Test Loss:0.619 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:10.341 AVG Test Loss:0.619 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:10.312 AVG Test Loss:0.619 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:10.308 AVG Test Loss:0.615 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:10.325 AVG Test Loss:0.614 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:10.309 AVG Test Loss:0.612 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:10.275 AVG Test Loss:0.611 AVG Training Acc 66.67 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:10.267 AVG Test Loss:0.609 AVG Training Acc 77.78 % AVG Test Acc 63.64 %\n",
            "Epoch:1/20 AVG Training Loss:10.448 AVG Test Loss:0.692 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:2/20 AVG Training Loss:10.438 AVG Test Loss:0.691 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:10.430 AVG Test Loss:0.690 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:4/20 AVG Training Loss:10.418 AVG Test Loss:0.684 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:5/20 AVG Training Loss:10.397 AVG Test Loss:0.680 AVG Training Acc 71.43 % AVG Test Acc 60.00 %\n",
            "Epoch:6/20 AVG Training Loss:10.395 AVG Test Loss:0.679 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:10.390 AVG Test Loss:0.679 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:10.377 AVG Test Loss:0.678 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:10.371 AVG Test Loss:0.679 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:10.367 AVG Test Loss:0.676 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:10.374 AVG Test Loss:0.676 AVG Training Acc 64.29 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:10.368 AVG Test Loss:0.675 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:10.351 AVG Test Loss:0.675 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:10.341 AVG Test Loss:0.672 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:10.349 AVG Test Loss:0.672 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:10.318 AVG Test Loss:0.665 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:10.326 AVG Test Loss:0.663 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:10.313 AVG Test Loss:0.659 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:10.318 AVG Test Loss:0.659 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:20/20 AVG Training Loss:10.312 AVG Test Loss:0.660 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 81.81818181818183 %\n",
            "Fold 1 acc: 50.0 %\n",
            "Fold 2 acc: 50.0 %\n",
            " Average acc: 60.60606060606061 %\n",
            "Epoch:1/20 AVG Training Loss:28.332 AVG Test Loss:0.655 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:2/20 AVG Training Loss:28.323 AVG Test Loss:0.641 AVG Training Acc 59.26 % AVG Test Acc 81.82 %\n",
            "Epoch:3/20 AVG Training Loss:28.266 AVG Test Loss:0.639 AVG Training Acc 66.67 % AVG Test Acc 81.82 %\n",
            "Epoch:4/20 AVG Training Loss:28.247 AVG Test Loss:0.621 AVG Training Acc 70.37 % AVG Test Acc 81.82 %\n",
            "Epoch:5/20 AVG Training Loss:28.194 AVG Test Loss:0.580 AVG Training Acc 70.37 % AVG Test Acc 90.91 %\n",
            "Epoch:6/20 AVG Training Loss:28.157 AVG Test Loss:0.536 AVG Training Acc 81.48 % AVG Test Acc 100.00 %\n",
            "Epoch:7/20 AVG Training Loss:28.115 AVG Test Loss:0.499 AVG Training Acc 81.48 % AVG Test Acc 100.00 %\n",
            "Epoch:8/20 AVG Training Loss:28.087 AVG Test Loss:0.468 AVG Training Acc 81.48 % AVG Test Acc 100.00 %\n",
            "Epoch:9/20 AVG Training Loss:28.052 AVG Test Loss:0.453 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:10/20 AVG Training Loss:28.021 AVG Test Loss:0.436 AVG Training Acc 88.89 % AVG Test Acc 100.00 %\n",
            "Epoch:11/20 AVG Training Loss:27.984 AVG Test Loss:0.425 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:12/20 AVG Training Loss:27.951 AVG Test Loss:0.417 AVG Training Acc 96.30 % AVG Test Acc 100.00 %\n",
            "Epoch:13/20 AVG Training Loss:27.909 AVG Test Loss:0.410 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:14/20 AVG Training Loss:27.892 AVG Test Loss:0.408 AVG Training Acc 88.89 % AVG Test Acc 100.00 %\n",
            "Epoch:15/20 AVG Training Loss:27.879 AVG Test Loss:0.409 AVG Training Acc 88.89 % AVG Test Acc 100.00 %\n",
            "Epoch:16/20 AVG Training Loss:27.848 AVG Test Loss:0.409 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:17/20 AVG Training Loss:27.818 AVG Test Loss:0.393 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:18/20 AVG Training Loss:27.788 AVG Test Loss:0.396 AVG Training Acc 88.89 % AVG Test Acc 100.00 %\n",
            "Epoch:19/20 AVG Training Loss:27.748 AVG Test Loss:0.382 AVG Training Acc 96.30 % AVG Test Acc 100.00 %\n",
            "Epoch:20/20 AVG Training Loss:27.719 AVG Test Loss:0.373 AVG Training Acc 92.59 % AVG Test Acc 100.00 %\n",
            "Epoch:1/20 AVG Training Loss:28.375 AVG Test Loss:0.698 AVG Training Acc 59.26 % AVG Test Acc 36.36 %\n",
            "Epoch:2/20 AVG Training Loss:28.346 AVG Test Loss:0.699 AVG Training Acc 62.96 % AVG Test Acc 45.45 %\n",
            "Epoch:3/20 AVG Training Loss:28.308 AVG Test Loss:0.697 AVG Training Acc 62.96 % AVG Test Acc 54.55 %\n",
            "Epoch:4/20 AVG Training Loss:28.249 AVG Test Loss:0.691 AVG Training Acc 66.67 % AVG Test Acc 54.55 %\n",
            "Epoch:5/20 AVG Training Loss:28.229 AVG Test Loss:0.683 AVG Training Acc 74.07 % AVG Test Acc 54.55 %\n",
            "Epoch:6/20 AVG Training Loss:28.181 AVG Test Loss:0.675 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:7/20 AVG Training Loss:28.156 AVG Test Loss:0.672 AVG Training Acc 70.37 % AVG Test Acc 63.64 %\n",
            "Epoch:8/20 AVG Training Loss:28.139 AVG Test Loss:0.667 AVG Training Acc 77.78 % AVG Test Acc 63.64 %\n",
            "Epoch:9/20 AVG Training Loss:28.104 AVG Test Loss:0.665 AVG Training Acc 74.07 % AVG Test Acc 63.64 %\n",
            "Epoch:10/20 AVG Training Loss:28.075 AVG Test Loss:0.658 AVG Training Acc 77.78 % AVG Test Acc 63.64 %\n",
            "Epoch:11/20 AVG Training Loss:28.085 AVG Test Loss:0.654 AVG Training Acc 77.78 % AVG Test Acc 63.64 %\n",
            "Epoch:12/20 AVG Training Loss:28.017 AVG Test Loss:0.639 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:13/20 AVG Training Loss:27.990 AVG Test Loss:0.642 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:14/20 AVG Training Loss:27.945 AVG Test Loss:0.633 AVG Training Acc 85.19 % AVG Test Acc 63.64 %\n",
            "Epoch:15/20 AVG Training Loss:27.953 AVG Test Loss:0.628 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:16/20 AVG Training Loss:27.911 AVG Test Loss:0.625 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:17/20 AVG Training Loss:27.900 AVG Test Loss:0.622 AVG Training Acc 77.78 % AVG Test Acc 63.64 %\n",
            "Epoch:18/20 AVG Training Loss:27.868 AVG Test Loss:0.617 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:19/20 AVG Training Loss:27.835 AVG Test Loss:0.615 AVG Training Acc 81.48 % AVG Test Acc 63.64 %\n",
            "Epoch:20/20 AVG Training Loss:27.803 AVG Test Loss:0.601 AVG Training Acc 81.48 % AVG Test Acc 72.73 %\n",
            "Epoch:1/20 AVG Training Loss:28.410 AVG Test Loss:0.696 AVG Training Acc 57.14 % AVG Test Acc 40.00 %\n",
            "Epoch:2/20 AVG Training Loss:28.304 AVG Test Loss:0.695 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:3/20 AVG Training Loss:28.255 AVG Test Loss:0.694 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:4/20 AVG Training Loss:28.258 AVG Test Loss:0.696 AVG Training Acc 67.86 % AVG Test Acc 40.00 %\n",
            "Epoch:5/20 AVG Training Loss:28.143 AVG Test Loss:0.698 AVG Training Acc 71.43 % AVG Test Acc 40.00 %\n",
            "Epoch:6/20 AVG Training Loss:28.127 AVG Test Loss:0.700 AVG Training Acc 67.86 % AVG Test Acc 50.00 %\n",
            "Epoch:7/20 AVG Training Loss:28.085 AVG Test Loss:0.691 AVG Training Acc 71.43 % AVG Test Acc 50.00 %\n",
            "Epoch:8/20 AVG Training Loss:28.073 AVG Test Loss:0.690 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:9/20 AVG Training Loss:28.026 AVG Test Loss:0.669 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:10/20 AVG Training Loss:27.989 AVG Test Loss:0.639 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:11/20 AVG Training Loss:27.961 AVG Test Loss:0.621 AVG Training Acc 78.57 % AVG Test Acc 50.00 %\n",
            "Epoch:12/20 AVG Training Loss:27.929 AVG Test Loss:0.606 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:13/20 AVG Training Loss:27.892 AVG Test Loss:0.599 AVG Training Acc 75.00 % AVG Test Acc 50.00 %\n",
            "Epoch:14/20 AVG Training Loss:27.836 AVG Test Loss:0.592 AVG Training Acc 85.71 % AVG Test Acc 50.00 %\n",
            "Epoch:15/20 AVG Training Loss:27.803 AVG Test Loss:0.573 AVG Training Acc 92.86 % AVG Test Acc 50.00 %\n",
            "Epoch:16/20 AVG Training Loss:27.788 AVG Test Loss:0.556 AVG Training Acc 89.29 % AVG Test Acc 50.00 %\n",
            "Epoch:17/20 AVG Training Loss:27.770 AVG Test Loss:0.552 AVG Training Acc 92.86 % AVG Test Acc 50.00 %\n",
            "Epoch:18/20 AVG Training Loss:27.736 AVG Test Loss:0.535 AVG Training Acc 85.71 % AVG Test Acc 50.00 %\n",
            "Epoch:19/20 AVG Training Loss:27.703 AVG Test Loss:0.518 AVG Training Acc 89.29 % AVG Test Acc 80.00 %\n",
            "Epoch:20/20 AVG Training Loss:27.634 AVG Test Loss:0.512 AVG Training Acc 92.86 % AVG Test Acc 80.00 %\n",
            "--- FOLDS RESULTS ---\n",
            "Fold 0 acc: 61.53846153846154 %\n",
            "Fold 1 acc: 72.72727272727273 %\n",
            "Fold 2 acc: 54.54545454545454 %\n",
            " Average acc: 62.93706293706294 %\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2ef555cbd7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mout_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_best_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds_loop_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mprint_and_save_folds_results2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_best_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPREEDSHEET_NAME_FINAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final best params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_best_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-2ef555cbd7df>\u001b[0m in \u001b[0;36mfolds_loop_double\u001b[0;34m(criterion, grid_param, splits0, splits1)\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mshapes_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSubsetRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_train_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minner_fold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mgread\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_and_save_folds_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPREEDSHEET_NAME_INT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-76ad91926e99>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, device, net_params, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-caebe56d8ccb>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, dataloader, loss_fn, optimizer, net_params, shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.27 GiB (GPU 0; 14.76 GiB total capacity; 12.72 GiB already allocated; 721.75 MiB free; 12.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "#[old] grid search (double cross validation)\n",
        "\n",
        "splits = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "splits0, splits1 = splits.split(dataset_square, dataset_square.labels), splits.split(dataset_rectangle, dataset_rectangle.labels)\n",
        "\n",
        "\n",
        "\n",
        "def folds_loop_double(criterion, grid_param, splits0, splits1):\n",
        "  out_results = {}\n",
        "  out_best_params = {}\n",
        "  trained_models = {}\n",
        "  keys = list(grid_param.keys())\n",
        "  shape = tuple(len(grid_param[keys[i]]) for i in range(len(keys)))\n",
        "  for fold, ((train_idx, val_idx), (train_idx1, val_idx1)) in enumerate(zip(splits0, splits1)):\n",
        "      print('Fold {}. train_idx:{} val_idx:{} train_idx1:{} val_idx1:{}'.format(fold + 1, train_idx, val_idx, train_idx1, val_idx1))\n",
        "\n",
        "      inner_splits = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "      grid = np.zeros((shape))\n",
        "\n",
        "      for idx in itertools.product(*[range(s) for s in shape]):\n",
        "        current_params = {k: grid_param[k][idx[e]] for e,k in enumerate(keys)}\n",
        "\n",
        "        def model_getter():\n",
        "          return prepare_train_model(current_params)\n",
        "\n",
        "        inner_splits0 = inner_splits.split(train_idx, np.array(dataset0.labels)[train_idx])\n",
        "        inner_splits1 = inner_splits.split(train_idx1, np.array(dataset1.labels)[train_idx1])\n",
        "\n",
        "        results = {}\n",
        "        for inner_fold, ((inner_train_idxx, inner_val_idxx), (inner_train_idxx1, inner_val_idxx1)) in enumerate(zip(inner_splits0, inner_splits1)):\n",
        "          inner_train_idx = train_idx[inner_train_idxx]\n",
        "          inner_val_idx = train_idx[inner_val_idxx]\n",
        "          inner_train_idx1 = train_idx1[inner_train_idxx1]\n",
        "          inner_val_idx1 = train_idx1[inner_val_idxx1]\n",
        "          #print('  Inner Fold {}. inner_train_idxx:{} inner_val_idxx:{} inner_train_idxx1:{} inner_val_idxx1:{}'.format(inner_fold + 1, inner_train_idxx, inner_val_idxx, inner_train_idxx1, inner_val_idxx1))\n",
        "          #print('   inner_train_idx:{} inner_val_idx:{} inner_train_idx1:{} inner_val_idx1:{}'.format(inner_fold + 1, inner_train_idx, inner_val_idx, inner_train_idx1, inner_val_idx1))\n",
        "\n",
        "          model, optimizer, device = prepare_model(model_getter, current_params['learning_rate'])\n",
        "          test_loader, shapes_test = prepare_test_loader(inner_val_idx, inner_val_idx1, current_params['batch_size'], len(train_idx), joined_dataset)\n",
        "\n",
        "          joined_train_ids = np.concatenate((train_idx, [x+(len(train_idx)) for x in inner_train_idx1]))\n",
        "          shapes_train = np.concatenate((np.zeros((len(train_idx), 1)), np.ones((len(train_idx1), 1))))\n",
        "          train_loader = DataLoader(joined_dataset, batch_size=current_params['batch_size']) #, sampler=SubsetRandomSampler(joined_train_ids))\n",
        "          results[inner_fold] = train_loop(model, device, current_params, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)  \n",
        "\n",
        "        grid[idx] = print_and_save_folds_results(results, current_params, SPREEDSHEET_NAME_INT)\n",
        "      best_params = find_best_params_ndim(grid_param, grid)\n",
        "\n",
        "      def model_getter():\n",
        "        return prepare_train_model(best_params)\n",
        "      model, optimizer, device = prepare_model(model_getter, best_params['learning_rate'])\n",
        "      test_loader, shapes_test = prepare_test_loader(val_idx, val_idx1, best_params['batch_size'], len(dataset0), joined_dataset)\n",
        "\n",
        "      joined_train_ids = np.concatenate((train_idx, [x+(len(dataset0)) for x in train_idx1]))\n",
        "      shapes_train = np.concatenate((np.zeros((len(train_idx), 1)), np.ones((len(train_idx1), 1))))\n",
        "      train_loader = DataLoader(joined_dataset, batch_size=best_params['batch_size']) #, sampler=SubsetRandomSampler(joined_train_ids))\n",
        "      out_results[fold] = train_loop(model, device, current_params, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "      out_best_params[fold] = best_params\n",
        "      trained_models[fold] = model\n",
        "      #print(\"Out results for outer fold:\", fold, \" \", out_results[fold])\n",
        "  return out_results, out_best_params, trained_models\n",
        "\n",
        "print(\"---------\")\n",
        "out_results, out_best_params, trained_models = folds_loop_double(criterion, grid_param, splits0, splits1)\n",
        "print_and_save_folds_results2(out_results, out_best_params, SPREEDSHEET_NAME_FINAL)\n",
        "print(\"Final best params:\", out_best_params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1pS6HjupAyg"
      },
      "outputs": [],
      "source": [
        "#depricated should be removed\n",
        "def prepare_test_loader(val_idx, val_idx1, batch_size, len_dataset0, dataset):\n",
        "  joined_ids = np.concatenate((val_idx, [x+(len_dataset0) for x in val_idx1]))\n",
        "  shapes_test = np.concatenate((np.zeros((len(val_idx), 1)), np.ones((len(val_idx1), 1))))\n",
        "  #test_loader = DataLoader(dataset, batch_size=batch_size, sampler=SubsetRandomSampler(joined_ids))\n",
        "  test_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "  return test_loader, shapes_test\n",
        "\n",
        "#depricated should be removed\n",
        "# def folds_loop_old(get_model, criterion, net_params, splits0, splits1):\n",
        "#   results = {}\n",
        "#   for fold, ((train_idx, val_idx), (train_idx1, val_idx1)) in enumerate(zip(splits0, splits1)):\n",
        "#       print('Fold {}. train_idx:{} val_idx:{} train_idx1:{} val_idx1:{}'.format(fold + 1, train_idx, val_idx, train_idx1, val_idx1))\n",
        "\n",
        "#       model, optimizer, device = prepare_model(get_model, net_params['learning_rate'])\n",
        "#       test_loader, shapes_test = prepare_test_loader(val_idx, val_idx1, net_params['batch_size'], len(train_idx)+len(val_idx), joined_dataset)\n",
        "\n",
        "#       joined_train_ids = np.concatenate((train_idx, [x+(len(train_idx)+len(val_idx)) for x in train_idx1]))\n",
        "      \n",
        "#       shapes_train = np.concatenate((np.zeros((len(train_idx), 1)), np.ones((len(train_idx1), 1))))\n",
        "#       train_loader = DataLoader(joined_dataset, batch_size=net_params['batch_size'])#, sampler=SubsetRandomSampler(joined_train_ids))\n",
        "#       results[fold] = train_loop(model, device, net_params, train_loader, test_loader, criterion, optimizer, shapes_train, shapes_test)\n",
        "#   return results\n",
        "\n",
        "  # def print_folds_results(conf_matrixes): #depricated\n",
        "#   sum = 0.0\n",
        "#   for key, conf_matrix in conf_matrixes.items():\n",
        "#     print(\"key:\", key, \" conf_matrix:\", conf_matrix)\n",
        "#     v = (conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "#     print(f'Fold {key} acc: {v} %')\n",
        "#     sum += v\n",
        "#   result = sum/len(conf_matrixes.items())\n",
        "#   print(f' Average acc: {result} %')\n",
        "#   return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAMocD1J58Hr"
      },
      "outputs": [],
      "source": [
        "def conver_into_toarch(x, y):\n",
        "  # converting training images into torch format\n",
        "  x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
        "  x  = torch.from_numpy(x)\n",
        "\n",
        "  # converting the target into torch format\n",
        "  y = y.astype(int);\n",
        "  y = torch.from_numpy(y)\n",
        "\n",
        "  # shape of training data\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "  return (x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTnIbAuZ1Wo8",
        "outputId": "7696547f-07cd-4d94-979c-50bab614ff3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FINAL DATASET] Test acc: 20.0  for model with index: 0\n",
            "[FINAL DATASET] Test acc: 20.0  for model with index: 1\n",
            "[FINAL DATASET] Test acc: 20.0  for model with index: 2\n",
            "[FINAL DATASET] Test acc: 60.0  for model with index: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "#load data and evaluate on existing models\n",
        "\n",
        "test_dataset_square = PyTorchImageDataset(TEST_FAT_DIR_SQUARE, TEST_HEALTHY_DIR_SQUARE, test_transform, rgb)\n",
        "test_dataset_rectangle = PyTorchImageDataset(TEST_FAT_DIR_RECTANGLE, TEST_HEALTHY_DIR_RECTANGLE, test_transform, rgb)\n",
        "test_joined_dataset = torch.utils.data.ConcatDataset([test_dataset_square, test_dataset_rectangle])\n",
        "print(\"Test dataset size:\", len(test_dataset_square), len(test_dataset_rectangle))\n",
        "\n",
        "print(\"item shape\", test_dataset_rectangle.image_list[0].shape, \" label\", test_dataset_rectangle.labels[0])\n",
        "\n",
        "for i in range(len(trained_models)):\n",
        "  model = trained_models[i]\n",
        "  bs = out_best_params[i]['batch_size']\n",
        "\n",
        "  test_loader, shapes_test = prepare_test_loader(list(range(len(test_dataset_square))), list(range(len(test_dataset_rectangle))), bs, len(test_dataset_square), test_joined_dataset)\n",
        "\n",
        "  test_loss, test_correct, cf_matrix = valid_epoch(model, device, test_loader, criterion, shapes_test, bs)\n",
        "\n",
        "  test_loss = test_loss / len(test_loader.sampler)\n",
        "  test_acc = test_correct / len(test_loader.sampler) * 100\n",
        "\n",
        "  print(\"[FINAL DATASET] Test acc:\", test_acc, \" for model with index:\", i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7m-5t_ezIqp"
      },
      "outputs": [],
      "source": [
        "#old \n",
        "splits = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
        "foldperf = {}\n",
        "results = {}\n",
        "\n",
        "dataset = dataset0\n",
        "\n",
        "#for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "for fold, (train_idx, val_idx) in enumerate(splits.split(dataset, [d[1] for d in dataset])):\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = Net()\n",
        "    model.to(device)  \n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_correct = train_epoch(model, device, train_loader, criterion, optimizer)\n",
        "        test_loss, test_correct, cf_matrix = valid_epoch(model, device, test_loader, criterion)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
        "\n",
        "        if True: #epoch+1 == num_epochs:\n",
        "          print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
        "                                                                                                             num_epochs,\n",
        "                                                                                                             train_loss,\n",
        "                                                                                                             test_loss,\n",
        "                                                                                                             train_acc,\n",
        "                                                                                                             test_acc))\n",
        "          results[fold] = test_acc\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_acc'].append(test_acc)\n",
        "\n",
        "    foldperf['fold{}'.format(fold+1)] = history  \n",
        "\n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k} FOLDS')\n",
        "sum = 0.0\n",
        "for key, value in results.items():\n",
        "  print(f'Fold {key}: {value} %')\n",
        "  sum += value\n",
        "print(f'Average: {sum/len(results.items())} %')\n",
        "\n",
        "torch.save(model,'k_cross_CNN.pt') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYfeNaOmv0WM",
        "outputId": "17ae49ab-4931-4748-8ec2-4c56f121397b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([323, 1, 192, 192]) torch.Size([107, 1, 192, 192])\n",
            "torch.Size([430, 1, 192, 192])\n",
            "Epoch :  1 \t loss tr : tensor(0.8066, grad_fn=<NllLossBackward0>) loss val: tensor(0.7530, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  3 \t loss tr : tensor(0.7729, grad_fn=<NllLossBackward0>) loss val: tensor(0.7687, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  5 \t loss tr : tensor(0.7016, grad_fn=<NllLossBackward0>) loss val: tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  7 \t loss tr : tensor(0.6795, grad_fn=<NllLossBackward0>) loss val: tensor(0.6748, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  9 \t loss tr : tensor(0.6268, grad_fn=<NllLossBackward0>) loss val: tensor(0.6455, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  1 \t loss tr : tensor(0.6230, grad_fn=<NllLossBackward0>) loss val: tensor(0.5658, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  3 \t loss tr : tensor(0.5814, grad_fn=<NllLossBackward0>) loss val: tensor(0.5402, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  5 \t loss tr : tensor(0.5481, grad_fn=<NllLossBackward0>) loss val: tensor(0.5402, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  7 \t loss tr : tensor(0.5232, grad_fn=<NllLossBackward0>) loss val: tensor(0.5323, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  9 \t loss tr : tensor(0.4871, grad_fn=<NllLossBackward0>) loss val: tensor(0.4936, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  1 \t loss tr : tensor(0.4684, grad_fn=<NllLossBackward0>) loss val: tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  3 \t loss tr : tensor(0.4461, grad_fn=<NllLossBackward0>) loss val: tensor(0.4351, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  5 \t loss tr : tensor(0.4206, grad_fn=<NllLossBackward0>) loss val: tensor(0.4181, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  7 \t loss tr : tensor(0.3997, grad_fn=<NllLossBackward0>) loss val: tensor(0.4074, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  9 \t loss tr : tensor(0.3788, grad_fn=<NllLossBackward0>) loss val: tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  1 \t loss tr : tensor(0.3747, grad_fn=<NllLossBackward0>) loss val: tensor(0.3401, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  3 \t loss tr : tensor(0.3590, grad_fn=<NllLossBackward0>) loss val: tensor(0.3276, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  5 \t loss tr : tensor(0.3422, grad_fn=<NllLossBackward0>) loss val: tensor(0.3130, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  7 \t loss tr : tensor(0.3240, grad_fn=<NllLossBackward0>) loss val: tensor(0.2963, grad_fn=<NllLossBackward0>)\n",
            "Epoch :  9 \t loss tr : tensor(0.3073, grad_fn=<NllLossBackward0>) loss val: tensor(0.2832, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#old cross val\n",
        "\n",
        "# Configuration options\n",
        "k_folds = 5\n",
        "num_epochs = 10\n",
        "LR = 0.0001\n",
        "\n",
        "# defining the model\n",
        "model = Net()\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "print(train_x.shape, val_x.shape) \n",
        "print(torch.cat((train_x, val_x), 0).shape)\n",
        "X = torch.cat((train_x, val_x), 0)\n",
        "y = torch.cat((train_y, val_y), 0)\n",
        "\n",
        "kf = KFold(n_splits=4, shuffle=True)\n",
        "for train_index, test_index in kf.split(X):\n",
        "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  train_x, val_x = X[train_index], X[test_index]\n",
        "  train_y, val_y = y[train_index], y[test_index]\n",
        "\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      train(epoch)\n",
        "\n",
        "#podwojna walidacja krzyzowa\n",
        "#agumentacja częścią treningu\n",
        "#sprawdzic po kolei kazda agumentacje o ile poprawia wynik\n",
        "#zbierać wyniki w tabeli\n",
        "#seed ustalony zeby zbior byl tak samo dzielony\n",
        "#stratify kflod \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv_NN5Wq47zN"
      },
      "source": [
        "Random staff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma0svoC7rC7d"
      },
      "source": [
        "ile obrazkow do validacji? (wszystkich 43)\n",
        "\n",
        "wyniki:\n",
        "\n",
        "post - 1.0 0.5/0.75 prze 100 epokach i lr 0.01\n",
        "\n",
        "pre - 1.0 0.25 -''-\n",
        "\n",
        "zwiekszenie lr nie\n",
        "\n",
        "zwiekszenie batcha 1 -> 5 cos chyba daje bo na pre 0.75\n",
        "\n",
        "zmniejszenie lr do 0.001 chyba pomaga -> trzeba zrobic greed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMcXUc_tcpwY"
      },
      "outputs": [],
      "source": [
        "# plotting the training and validation loss\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "qihpzTSw4-Mt",
        "outputId": "7e98b7ea-efea-48a1-a6e6-29c60a15a279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#test agumentation\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "img = fat[0][0]\n",
        "print(img)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "     tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "     tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)])\n",
        "\n",
        "image = tf.expand_dims(img, 0)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "IOSlXqK0rdpa",
        "outputId": "56fcd88d-3390-4fd0-86b2-0c513fe8a27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "false_positive_rate: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  true_positive_rate: [0.         0.58823529 0.69747899 0.7394958  0.76470588 0.78151261\n",
            " 0.78571429 0.79411765 0.79831933 0.80672269 0.81092437 0.82773109\n",
            " 0.84453782 0.86134454 1.         1.        ]  thresholds: [2.0000000e+00 1.0000000e+00 9.9999988e-01 9.9999976e-01 9.9999964e-01\n",
            " 9.9999952e-01 9.9999940e-01 9.9999928e-01 9.9999917e-01 9.9999905e-01\n",
            " 9.9999893e-01 9.9999857e-01 9.9999774e-01 9.9999714e-01 9.9853837e-01\n",
            " 1.0158911e-15]\n",
            "1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(predictions, [x[1] for x in prob])\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "print(\"false_positive_rate:\", false_positive_rate, \" true_positive_rate:\", true_positive_rate, \" thresholds:\", thresholds)\n",
        "print(roc_auc)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(false_positive_rate, true_positive_rate, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-Hu6tWwHiL_"
      },
      "outputs": [],
      "source": [
        "# define pytorch transforms\n",
        "transform = transforms.Compose([\n",
        "     transforms.ToPILImage(),\n",
        "     transforms.Resize((300, 300)),\n",
        "     transforms.CenterCrop((100, 100)),\n",
        "     transforms.RandomCrop((80, 80)),\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.RandomRotation(degrees=(-90, 90)),\n",
        "     transforms.RandomVerticalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYB6VW3NMofr"
      },
      "outputs": [],
      "source": [
        "#old static but working\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "     tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "     tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "     ])\n",
        "\n",
        "fat_a = fat[2:]\n",
        "healthy_a = healthy[2:]\n",
        "\n",
        "for f in fat[2:]:\n",
        "  for i in range(9):\n",
        "    image = tf.expand_dims(f[0], 0)\n",
        "    new = data_augmentation(image)[0]\n",
        "    fat_a.append((new, f[1]))\n",
        "\n",
        "for h in healthy[2:]:\n",
        "  for i in range(9):\n",
        "    imagee = tf.expand_dims(h[0], 0)\n",
        "    new = data_augmentation(imagee)[0]\n",
        "    healthy_a.append((new, h[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "ueld45VjJuCL",
        "outputId": "26a0f82c-6ebb-42c5-c4e5-3f1d5d3bd9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'postT1map', 'preT1map'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img shape: (192, 192, 3)  min: 0.0  max: 0.9994574952752239\n"
          ]
        }
      ],
      "source": [
        "#temp\n",
        "\n",
        "def toRGB(image):\n",
        "  dim = np.zeros((image.shape[0], image.shape[1]))\n",
        "  rgb_image = np.stack((image/2500, image/2500, image/2500), axis=2)\n",
        "  return rgb_image\n",
        "\n",
        "filename = os.listdir(FAT_DIR)[0]\n",
        "filepath = os.path.join(FAT_DIR, filename)\n",
        "maps = scipy.io.loadmat(filepath)\n",
        "print(maps.keys())\n",
        "img_pre = np.array(maps['preT1map'], np.double)\n",
        "img_pre = fix_image(img_pre)\n",
        "plt.imshow(img_pre)\n",
        "plt.show()\n",
        "img_pree = Image.fromarray(img_pre).convert('RGB')\n",
        "plt.imshow(img_pree)\n",
        "plt.show()\n",
        "img_pre = toRGB(img_pre)\n",
        "plt.imshow(img_pre)\n",
        "plt.show()\n",
        "print(\"img shape:\", img_pre.shape, \" min:\", np.min(img_pre), \" max:\", np.max(img_pre))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "stlitZO26SAt",
        "A0mDYnMp6JZ7",
        "oOYjQdp75_Z8",
        "FtLYeKIb0TR-",
        "k0MIBUh2hgcX",
        "GpzJui_5LinG",
        "TqV5whtGzg7D",
        "1GlCRkSNx84J"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}